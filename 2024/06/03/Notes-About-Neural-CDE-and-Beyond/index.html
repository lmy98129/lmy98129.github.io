<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.4">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.4" color="#222">







<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Gemini',
    version: '6.0.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  
  <meta name="keywords" content="experience," />


<meta name="description" content="We are not the stuff that abides,but patterns that perpetuate themselves.by Norbert Wiener  本文是关于神经受控微分方程Neural Controlled Differential Equations的学习笔记主要是Neural CDE对于Neural ODE的反思与改进，以及其与符号回归Symbolic">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes About Neural CDE and Beyond">
<meta property="og:url" content="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/index.html">
<meta property="og:site_name" content="NeXT">
<meta property="og:description" content="We are not the stuff that abides,but patterns that perpetuate themselves.by Norbert Wiener  本文是关于神经受控微分方程Neural Controlled Differential Equations的学习笔记主要是Neural CDE对于Neural ODE的反思与改进，以及其与符号回归Symbolic">
<meta property="og:locale">
<meta property="og:image" content="http://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/latent-ode.png">
<meta property="og:image" content="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/Bilibili-NCDE.png">
<meta property="og:image" content="https://www.elprocus.com/wp-content/uploads/Closed-Loop-Control-System-Block-Diagram.jpg">
<meta property="og:image" content="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/SINDy.png">
<meta property="og:image" content="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/KAN.png">
<meta property="article:published_time" content="2024-06-03T07:17:12.000Z">
<meta property="article:modified_time" content="2024-06-04T04:52:14.575Z">
<meta property="article:author" content="Mengyin Liu">
<meta property="article:tag" content="experience">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/latent-ode.png">






  <link rel="canonical" href="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>Notes About Neural CDE and Beyond | NeXT</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

<meta name="generator" content="Hexo 5.4.2"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">NeXT</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
        </li>
      
        
        <li class="menu-item menu-item-academic">
          <a href="/academic/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-flask"></i> <br />学术</a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
        </li>
      

      
    </ul>
  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mengyin Liu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NeXT">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Notes About Neural CDE and Beyond</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-06-03T15:17:12+08:00">2024-06-03</time>
            

            
            
              
                
              
            

            
              
              <span class="post-meta-divider">|</span>
              

              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2024-06-04T12:52:14+08:00">2024-06-04</time>
            
          </span>

          

          
            
          

          
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>We are not the stuff that abides,<br>but patterns that perpetuate themselves.<br>by Norbert Wiener</p>
</blockquote>
<p>本文是关于神经受控微分方程Neural Controlled Differential Equations的学习笔记<br>主要是Neural CDE对于Neural ODE的反思与改进，以及其与符号回归Symbolic Regression的内在联系。</p>
<span id="more"></span>
<h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>维纳的这句名言，中文意思是：“我们并非静止不变的物品，而是能够自我延续的模式”。</p>
<p>训练结束后，推理阶段的神经网络模型一般会固定其可学习参数$\theta$，这些参数代表了输入数据、中间特征对于特征计算、最终输出的贡献度。因此，我们将其称为权重$W$，当然，还有调整数值总体偏移的偏置$b$。</p>
<p>然而，在复杂多变的实际应用场景中，对于静止不变的神经网络，其泛化性总是有限的。总有那么一个时刻，推理数据与训练数据不再是独立同分布的（i.i.d., independent and identically distributed）。我们需要模型能够根据当下的工况，按照某种模式，调整输入数据的贡献度，从而实现模型的自我延续。</p>
<p>根据特定模式进行有序的反馈调整，能够让自我的稳态保持得更加长久，正是控制理论的核心哲学之一。这便是我引用控制论创始人维纳名言的原因，这也是为什么我要单独讨论神经受控微分方程Neural CDE的原因。这不只是一个简单的Neural ODE分支，而是一套简洁有效的方法论。</p>
<h2 id="初值问题-Initial-Value-Problem"><a href="#初值问题-Initial-Value-Problem" class="headerlink" title="初值问题 Initial Value Problem"></a>初值问题 Initial Value Problem</h2><p>回顾<a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2">之前的笔记</a>，无论是显式的状态$y$、还是隐式的特征$z$，常微分方程都意味着自变量只能有一个，那就是时间$t$，而因变量$y$则随着时间$t$变化：</p>
<p>$$<br>\begin{equation}<br>\frac{dy}{dt} = f(y_t) ~~\Leftrightarrow~~ dy = f(y_t)dt<br>\end{equation}<br>$$</p>
<p>为了得到某个时刻$y_\mathrm{T}$的值，需要对常微分方程进行积分。若方程已知，则有且仅有的额外输入是初值$y_0$：</p>
<p>$$<br>\begin{equation}<br>y_\mathrm{T} = y_0 + \int_0^\mathrm{T} dy = y_0 + \int_0^\mathrm{T} f(y_t)dt<br>\end{equation}<br>$$</p>
<p>对于Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[1]</a></sup>，为了得到隐式特征$z$的初值$z_0$，需要将已知的时间序列数据$\mathrm{X}$输入到特定的编码器（这里是ODE-RNN）。给定固定的Neural ODE解码器，得到的$z_0$作为唯一的输入，直接决定了之后所有输出的隐式特征$z_\mathrm{T}$。虽然$z_0$也可以通过采样$\mathcal{N}(\mu, \sigma)$多次得到，但是$\mu, \sigma$确定了之后，同样也能确定后续$z_\mathrm{T}$的平均值范围作为输出。</p>
<p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/../../../../2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/latent-ode.png" alt="latent-ode"></p>
<p>这便是初值问题（IVP，Initial Value Problem）：一旦初值决定，结果也就决定了。那么，在时间层面上静止不变的初值输入$z_0$、以及神经网络参数$\theta$，如何应对实时变化、长度$\mathrm{T}$不断增长的时间序列数据$\mathrm{X}$呢？一个最简单的方式，就是当$\mathrm{X}$变长到$\mathrm{T}+\Delta\mathrm{T}$时，重新输入到编码器得到$z_0$、积分得到隐式特征$z_\mathrm{T}$、乃至将$z_\mathrm{T}$映射到显式的预测结果上。</p>
<p>考虑到除了用于解码预测的Neural ODE是一个神经网络，编码器本身也是一个神经网络，为了一个微小的长度增长$\Delta\mathrm{T}$，反复跑完整个pipeline的计算代价十分高昂。显然有一种最简单的方式，将当前时刻$t$的数据$\mathrm{X}_t$也纳入到Neural ODE的神经网络输入中，从而无需对整个$\mathrm{X}$预先编码（其中，z_0只需对$\mathrm{X}_0$进行编码得到）：</p>
<p>$$<br>\begin{equation}<br>z_\mathrm{T} = z_0 + \int_0^\mathrm{T} f_\theta(z_t)dt = z_0 + \int_0^\mathrm{T} h_\theta(z_t, \mathrm{X}_t)dt<br>\end{equation}<br>$$</p>
<p>显然，这种形式等价于直接使用编码器ODE-RNN，也即当存在$\mathrm{X}_t$的时候，$z_t$与$\mathrm{X}_t$同时输入神经网络$h_\theta$，得到$z_{t+\Delta t}$的更新，反之则和经典Neural ODE一样只有$z_t$作为输入。若对于连续型时间序列，则任意时间$t$都有$\mathrm{X}_t$作为输入，则等价于纯Neural ODE模型。对于离散型时间序列进行插值（例如，B-样条插值），同样能够实现这个效果。</p>
<h2 id="受控微分方程-Controlled-Differential-Equations"><a href="#受控微分方程-Controlled-Differential-Equations" class="headerlink" title="受控微分方程 Controlled Differential Equations"></a>受控微分方程 Controlled Differential Equations</h2><p>与式子（3）不同的是，Neural CDE论文<sup class="refplus-num"><a href="#ref-Neural-CDE">[2]</a></sup>引入了受控微分方程（CDE，Controlled Differential Equations）的概念，也就是直接将Neural ODE的神经网络$f’_\theta(z_t)$的输出，作为控制变量、也就是时间序列数据$\mathrm{X}_t$的“系数”：</p>
<p>$$<br>\begin{equation}<br>dz_t = f’_\theta(z_t)d\mathrm{X}_t<br>\end{equation}<br>$$</p>
<p>需要注意的是，由于$dz_t$应当与$z_t$的形状相同，而$\mathrm{X}_t \in \mathbb{R}^\mathrm{D’}$可能与$z_t \in \mathbb{R}^\mathrm{D}$形状不同，也即隐式特征的维度与显式时间序列数据的维度不同。因此，神经网络$f’_\theta(z_t)$的输出形状不再是与$z_t$一样的向量，而是形状为$\mathrm{D} \times\mathrm{D’}$的线性映射矩阵。</p>
<p>$$<br>\begin{equation}<br>z_\mathrm{T} = z_0 + \int_0^\mathrm{T} dz_t = z_0 + \int_0^\mathrm{T} f’_\theta(z_t) d\mathrm{X}_t<br>\end{equation}<br>$$</p>
<p>其中，$d\mathrm{X}_t$为时间序列数据$\mathrm{X}$的瞬时变化量（不是导数）；则$\frac{d\mathrm{X}_t}{dt}$为时间序列数据的瞬时变化率，也就是一阶导数。那么显然，可以通过$\frac{d\mathrm{X}_t}{dt}$，使得式子（5）的积分也能够用以$t$为变量的常微分方程$g_{\theta, X}(z_t)$表示：</p>
<p>$$<br>\begin{equation}<br>\int_0^\mathrm{T} f’_\theta(z_t)\frac{d\mathrm{X}_t}{dt}dt = \int_0^\mathrm{T} g_{\theta, X}(z_t)dt<br>\end{equation}<br>$$</p>
<p>Neural CDE证明了式子（5）能够表示任意式子（3），但反过来存在式子（3）无法表示的式子（5），证明过程非常复杂，但是B站上的视频提供了一个形象的例子。定义$y_t$（论文及图片中为$y_s$）为一维的显式状态，Neural CDE的神经网络$f’_\theta(y_t)$输出则从矩阵变成了形状为$\mathrm{D} \times 1$的向量。如果给时间序列数据加一个常量维度1，假设$f’_\theta(y_t)$学到了需要一直输出one-hot的向量，则该积分结果可以表示为初值加上时间序列长度：</p>
<p>$$<br>\begin{equation}<br>y_\mathrm{T} = y_0 + \int_0^\mathrm{T} dt = y_0 + \mathrm{T}<br>\end{equation}<br>$$</p>
<p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/Bilibili-NCDE.png" alt="Bilibili-NCDE"></p>
<center>通过新增常量维度1，Neural CDE能够显式学习到时间序列的长度，<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1F44y1X7o6?t=461.8">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-NDEF">[3]</a></sup></center>

<p><br></p>
<p>反之，如果$f’_\theta(y_t)$学到的不是一直输出one-hot向量，则是对输入数据——也就是常量维度1、时间序列数据维度$\frac{d\mathrm{X}_t}{dt}$——的加权权重，随着输入$y_t$的变化而变化的。其中常量维度1乘上对应权重向量后，可以看做偏置，即:</p>
<p>$$<br>\begin{equation}<br>\frac{dy}{dt} = f’_\theta(z_t)[1, \frac{d\mathrm{X}_t}{dt}]^\top = W_t^\top \frac{d\mathrm{X}_t}{dt} + b_t<br>\end{equation}<br>$$</p>
<p>但是，在推理过程中，式子（3）Neural ODE的输入层参数$\{W_1, b_1\} \in \theta$是固定不变的，不随着输入$y_t$的变化而变化，这等价于在Neural CDE中，$f’_\theta(y_t)$输出的$\{W_t, b_t\}$一直是定值$\{W_1, b_1\} $。因此，Neural CDE具有更强大的表达能力。</p>
<h2 id="反馈控制参数-Feedback-Controlled-Parameters"><a href="#反馈控制参数-Feedback-Controlled-Parameters" class="headerlink" title="反馈控制参数 Feedback-Controlled Parameters"></a>反馈控制参数 Feedback-Controlled Parameters</h2><p>然而，正是这个形象的例子，启发了笔者对Neural CDE的进一步思考：真的只有时间序列数据$\mathrm{X}_t$是“控制变量”吗？</p>
<p>我们似乎忽略了一个事实：什么能动态改变作用在$\mathrm{X}_t$上的权重$\{W_t, b_t\}$呢？是式子（5）的神经网络$f’_\theta(y_t)$。在式子（3）的Neural ODE中，上一个时刻的积分结果$y_t$单纯只是输入，无法改变作用在输入上的模型参数$\{W_1, b_1\}$。但是在Neural CDE中，$y_t$能够通过$f’_\theta(y_t)$改变神经网络的输出，也正是作用在输入上的参数$\{W_t, b_t\}$。</p>
<p>而这个$y_t$，正是由再上一个时刻$t-1$的积分结果$y_{t-1}$得到的$\{W_{t-1}, b_{t-1}\}$、以及输入的时间序列数据$X_{t-1}$共同作用得到的。这是一个不断通过历史结果$y_t$的实时反馈，控制、调整下一个时刻作用在输入$X_t$的权重，进行“闭环控制”的过程。这是自动化控制中最基本的理论模型。反过来，Neural ODE虽然也输入$y_t$，但无法控制作用在输入$X_t$的权重。</p>
<p><img src="https://www.elprocus.com/wp-content/uploads/Closed-Loop-Control-System-Block-Diagram.jpg" alt="closeloop"></p>
<center>闭环控制示意图，将$f’_\theta(y_t)$看做“Feedback Elements”，通过乘号$\otimes$作用在输入“Input”的时间序列数据$\mathrm{X}_t$上<br>图片来自<a target="_blank" rel="noopener" href="https://www.elprocus.com/what-is-a-closed-loop-control-system-its-working/">Elprocus.com</a></center>

<p><br></p>
<p>如上图所示，甚至在闭环控制模型中，反馈调整的方式就是通过对输入乘以权重（乘号$\otimes$）实现的；生成这一权重的输入，也正是“Output”历史结果$y_t$。因此，笔者个人认为，Neural CDE<sup class="refplus-num"><a href="#ref-Neural-ODE">[1]</a></sup>原文第二页底部，对于受控微分方程“Controlled Differential Equations”的注解“Not to be confused with the similarly-named but separate field of control theory”其实并不准确，这并不仅仅是名字像，而是在内在方法论上的共通，简洁而有效。</p>
<h2 id="符号回归-Symbolic-Regression"><a href="#符号回归-Symbolic-Regression" class="headerlink" title="符号回归 Symbolic Regression"></a>符号回归 Symbolic Regression</h2><p>显然，式子（8）中的反馈控制参数$\{W_t, b_t\}$和输入$\mathrm{X}_t$的关系是一个线性多项式，既没有任何的非线性项、也没有函数的嵌套关系。所以，Neural CDE描述复杂现实场景的能力其实仍然有限。当然，神经网络$f’_\theta(y_t)$本身是一个非线性函数，应当能够间接地学习到每个时刻如何精确地调整$\{W_t, b_t\}$，但单纯调整线性权重明显是不够的。</p>
<p>那么，怎样能学习到更高阶的函数关系呢？符号回归（Symbolic Regression）显然是一个值得考虑的选项，顺带还有一个诱人的赠品，就是拟合到的模型本身就是一个可解释的、显式的函数表达式，而不是神经网络参数这样的黑箱。</p>
<p>这里介绍两个比较热门的符号回归流派：基于预定义函数库的SINDy<sup class="refplus-num"><a href="#ref-SINDy">[4]</a></sup>（Sparse Identification of Nonlinear Dynamical Systems）、以及近期提出并大火的基于可学习激活函数KAN<sup class="refplus-num"><a href="#ref-KAN">[5]</a></sup>（Kolmogorov-Arnold Networks）。</p>
<p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/SINDy.png" alt="SINDy"></p>
<center>SINDy方法示意图，$\dot{\mathbf{X}}$为拟合目标真值，$\mathbf{\Theta}(\mathbf{X})$为输入数据代入候选函数，$\Xi$表示稀疏向量。图片来自论文原文<sup class="refplus-num"><a href="#ref-SINDy">[4]</a></sup></center>

<p><br></p>
<p>SINDy需要预先定义一系列候选函数算子$\Theta$，一般包括多次项组合（例如，$x, y, x^2, y^2, xy, x^2y, xy^2 \cdots$）、三角函数、对数函数、自然指数函数等常见函数。将输入数据的各个维度代入这些函数，得到一系列函数值。学习目标就是找到一个稀疏的向量$\Xi$，用尽可能少的函数，正确回归拟合出对应输入的真值。</p>
<p>对于非深度学习的原始版本SINDy，拟合是通过多元回归等数值方法进行的，需要约束$\Xi$的稀疏性。对于基于深度学习的SINDy，可以将$\Xi$作为神经网络参数，进行梯度下降优化，例如结合Neural ODE得到Neural SINDy <sup class="refplus-num"><a href="#ref-Neural-SINDy">[6]</a></sup>、多层嵌套的Nested-SINDy等<sup class="refplus-num"><a href="#ref-Nested-SINDy">[7]</a></sup>。学到$\mathbf{\Theta}(\mathbf{X})\Xi$即为多项式相加表达式，无法表示、或者只能表示预设的<sup class="refplus-num"><a href="#ref-Nested-SINDy">[7]</a></sup>函数嵌套高阶关系。</p>
<p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/KAN.png" alt="KAN"></p>
<center>KAN方法示意图，通过步骤3~6，将学习到的激活函数逐个设定为已知函数，解析出显式、可嵌套的表达式<br>图片来自论文原文<sup class="refplus-num"><a href="#ref-KAN">[5]</a></sup></center>

<p><br></p>
<p>不同于可学习连接权重的传统神经网络，KAN将所有连接权重设置为1，同时将之前固定不可学习的激活函数转变为可学习的。学习目标是通过学习激活函数的B-样条曲线，得到若干个任意形状激活函数的嵌套组合，同时逐步删去无激活函数的权重，从而回归出对应输入的真值。同时，在学习结束后通过对曲线的特定解析方法，可以得到这些曲线组合后的显式表达式，这种解析方法支持生成函数的嵌套关系，具有更高的可解释性和实用价值。</p>
<p>值得注意的是，这些符号回归方法的表达式参数，在训练结束之后仍然是固定的、与输入数据无关的。近期工作DeepOKAN<sup class="refplus-num"><a href="#ref-DeepOKAN">[8]</a></sup>从DeepONet<sup class="refplus-num"><a href="#ref-DeepONet">[9]</a></sup>的角度实现了这个思路。所以，这个方向上还有更多的可能性，等待着大家的不断探索。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Neural-ODE" data-num="1">[1]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-Neural-CDE" data-num="2">[2]  Kidger P, Morrill J, Foster J, et al. Neural controlled differential equations for irregular time series[J]. Advances in Neural Information Processing Systems, 2020, 33: 6696-6707.</li><li id="ref-Bilibili-NDEF" data-num="3">[3]  yyxzhj. Neural ODE, CDE... 神经微分方程大家族. https://www.bilibili.com/video/BV1F44y1X7o6</li><li id="ref-SINDy" data-num="4">[4]  Brunton S L, Proctor J L, Kutz J N. Discovering governing equations from data by sparse identification of nonlinear dynamical systems[J]. Proceedings of the national academy of sciences, 2016, 113(15): 3932-3937.</li><li id="ref-KAN" data-num="5">[5]  Liu Z, Wang Y, Vaidya S, et al. Kan: Kolmogorov-arnold networks[J]. arXiv preprint arXiv:2404.19756, 2024.</li><li id="ref-Neural-SINDy" data-num="6">[6]  Lee K, Trask N, Stinis P. Structure-preserving sparse identification of nonlinear dynamics for data-driven modeling[C]//Mathematical and Scientific Machine Learning. PMLR, 2022: 65-80.</li><li id="ref-Nested-SINDy" data-num="7">[7]  Fiorini C, Flint C, Fostier L, et al. Generalizing the SINDy approach with nested neural networks[J]. arXiv preprint arXiv:2404.15742, 2024.</li><li id="ref-DeepOKAN" data-num="8">[8]  Abueidda D W, Pantidis P, Mobasher M E. DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems[J]. arXiv preprint arXiv:2405.19143, 2024.</li><li id="ref-DeepONet" data-num="9">[9]  Lu L, Jin P, Pang G, et al. Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators[J]. Nature machine intelligence, 2021, 3(3): 218-229.</li></ul>
    <style>
    #refplus, #refplus li{ 
        padding:0;
        margin:0;
        list-style:none;
    }；
    </style>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script>
    document.querySelectorAll(".refplus-num").forEach((ref) => {
        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');
        let refel = document.querySelector(refid);
        let refnum = refel.dataset.num;
        let ref_content = refel.innerText.replace(`[${refnum}]`,'');
        tippy(ref, {
            content: ref_content,
        });
    });
    </script>
    
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/experience/" rel="tag"><i class="fa fa-tag"></i> experience</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2024/01/18/Notes-About-Operator-Learning/" rel="next" title="Notes About Operator Learning">
                <i class="fa fa-chevron-left"></i> Notes About Operator Learning
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Mengyin Liu" />
            
              <p class="site-author-name" itemprop="name">Mengyin Liu</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, stay foolish</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/lmy98129" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:blean@live.cn" target="_blank" title="Mail"><i class="fa fa-fw fa-envelope"></i>Mail</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://scholar.google.com/citations?user=hN7koAYAAAAJ&hl=zh-CN" target="_blank" title="Scholar"><i class="fa fa-fw fa-google"></i>Scholar</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/liu-meng-yin-68/" target="_blank" title="知乎"><i class="fa fa-fw fa-comment"></i>知乎</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80-Introduction"><span class="nav-number">1.</span> <span class="nav-text">前言 Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9D%E5%80%BC%E9%97%AE%E9%A2%98-Initial-Value-Problem"><span class="nav-number">2.</span> <span class="nav-text">初值问题 Initial Value Problem</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%97%E6%8E%A7%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B-Controlled-Differential-Equations"><span class="nav-number">3.</span> <span class="nav-text">受控微分方程 Controlled Differential Equations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8D%E9%A6%88%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0-Feedback-Controlled-Parameters"><span class="nav-number">4.</span> <span class="nav-text">反馈控制参数 Feedback-Controlled Parameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%A6%E5%8F%B7%E5%9B%9E%E5%BD%92-Symbolic-Regression"><span class="nav-number">5.</span> <span class="nav-text">符号回归 Symbolic Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">6.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mengyin Liu</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>








<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共77.7k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      本站访客数<span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      总访问量<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.4"></script>



  



	





  





  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  
  <script type="text/javascript" src="/js/src/exturl.js?v=6.0.4"></script>


  

</body>
</html>
