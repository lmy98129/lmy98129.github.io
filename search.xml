<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Notes About Deep Q-Learning</title>
      <link href="/2024/07/02/Notes-About-Deep-Q-Learning/"/>
      <url>/2024/07/02/Notes-About-Deep-Q-Learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p>A reinforcement process is one in which some aspects of the behavior of<br>a system are caused to become more (or less) prominent in the future<br>as a consequence of the application of a “reinforcement operator”.<br>in <em>Steps Toward Artificial Intelligence</em>, Marvin Minsky</p></blockquote><p>本文是关于深度Q强化学习Deep Q-Learning的学习笔记<br>主要包括前置知识、策略梯度PG、近端策略优化PPO、深度Q网络DQN、深度确定性策略梯度DDPG和相关扩展知识</p><span id="more"></span><h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>作为著名的人工智能“达特茅斯会议”主要发起人、1969年图灵奖获得者，马尔文·明斯基在1961年发表了论文《迈向人工智能》，并首次定义了强化学习Reinforcement Learning的基本概念：“通过应用强化操作，使得系统行为的某些方面在未来更加（或更不）显著，这一过程叫做强化过程”。这里的“强化操作”，指的是系统与环境交互、获得奖励反馈并学习之后，这个系统的行为在未来交互中，发生了向着潜在奖励更高方向的、定向的变化，也即“强化”。</p><p><img src="/2024/07/02/Notes-About-Deep-Q-Learning/RL.png" alt="RL"></p><p><center>基于操作强化（Operant Reinforcement）的学习系统，图片来自《迈向人工智能》论文原文<sup class="refplus-num"><a href="#ref-Toward">[1]</a></sup></center><br></p><p>结合论文原图，可以看到从1961年至今，强化学习的基本框架是万变不离其宗的。在很长一段时间里，强化学习往往被诟病其应用范围过窄，除了游戏、博弈等仿真成本较低的领域，更复杂的自动驾驶、工业控制等领域仍然是非强化学习为主的。随着OpenAI提出了全新的大语言模型方案，人类反馈的强化学习RLHF（Reinforcement Learning from Human-Feedback）以及其背后的近端策略优化PPO（Proximal Policy Optimization）将强化学习带到了聚光灯下。更进一步地，<strong>OpenAI在各种场合暗示了下一代模型Q*，同样是基于深度Q强化学习的搜索采样</strong>。</p><p>需要强调的是，强化学习已经有若干优质教程在前，包括李宏毅老师的《深度强化学习》系列课程<sup class="refplus-num"><a href="#ref-Hung-yi-Lee">[2]</a></sup>、Sutton教程英文实体书<sup class="refplus-num"><a href="#ref-Sutton">[3]</a></sup>、以及EasyRL教程中文实体书+<a href="https://datawhalechina.github.io/easy-rl/#/">在线教程</a>“蘑菇书”<sup class="refplus-num"><a href="#ref-Easy-RL">[4]</a></sup>。本文参考了前述教程，仅摘录个人认为需要重点学习的内容，并加入了若干个人理解。<strong>如需更深入地学习，请优先参考前述更加系统完备的课程和书籍</strong>。</p><h2 id="预备知识-Preliminaries"><a href="#预备知识-Preliminaries" class="headerlink" title="预备知识 Preliminaries"></a>预备知识 Preliminaries</h2><p>从提出这一任务开始，强化学习的关键要素就是与环境Environment的交互。交互过程中，强化学习模型（也叫智能体Agent）本身可以是黑箱，但仍然需要这3个重要组成部分：</p><ol><li><strong>策略Policy</strong>：根据当前状态State，决定应该采取哪些行为Action；</li><li><strong>奖励Reward</strong>：根据当前状态State，决定采取特定的行为Action，环境反馈给模型的奖励（还有新的状态）；</li><li><strong>价值函数Value Function</strong>：基于采取行为后将获得的奖励Reward，衡量当前状态State好坏（是否需要改变）。</li></ol><h3 id="策略-Policy"><a href="#策略-Policy" class="headerlink" title="策略 Policy"></a>策略 Policy</h3><p>首先，策略可以分为两种，随机性策略和确定性策略。随机性策略Stochastic Policy，是按照特定概率$p$选择采取某一种行动$a^*$，这种选择的行为可以定义为一个$\pi$函数，可以写成在一个概率分布$p$中采样的形式：</p><p>$$<br>\begin{equation}<br>a^* \sim \pi(a|s) = p(a_t=a|s_t=s)<br>\label{sto-policy}<br>\end{equation}<br>$$</p><p>例如，有2种状态，随机选择到的概率分别为$p$和$1-p$。确定性策略Deterministic Policy，则是直接采取最有可能的动作，所以可以直接写作在状态s的情况下的一种查表操作$\pi(s)$：</p><p>$$<br>\begin{equation}<br>a^* = \pi(s) = \arg\max_a \pi(a|s)<br>\label{det-policy}<br>\end{equation}<br>$$</p><p>虽然很多教程都在强调，引入随机性能够通过多次采样$a^* \sim \pi$，从而采取多样化的行动，更好地探索环境。但是，<strong>环境并不总是可以完美仿真的</strong>。在一些真实环境下，<strong>多次采样是有代价的</strong>。</p><p><img src="/2024/07/02/Notes-About-Deep-Q-Learning/beam-search.png" alt="beam-search"></p><p><center>集束搜索Beam Search，是自回归文本生成（Image Captioning、大语言模型问答等）常用的一种采样方法<br>相比使用Top-1的贪婪方法，更容易找到全局最优</center><br></p><p>类比集束搜索Beam Search，即使是在成本较低的仿真环境中，如果行为本身是高维度的（例如有很多关节的机器人），在每一步采样后，会分叉出庞大的行为轨迹树，采样成本也是巨大的；在采样之后，也需要对每条采样到的行为轨迹，计算相应的奖励，这个计算开销同样是巨大的。因此，<strong>确定性策略反而具有了样本需求小的优势</strong>。</p><h3 id="奖励-Reward"><a href="#奖励-Reward" class="headerlink" title="奖励 Reward"></a>奖励 Reward</h3><p>在状态$s$下，当智能体Agent做出了行为$a$，则相应的能够从环境得到反馈的奖励$R(s, a)$。为了兼容随机性策略的“在概率分布中多次采样”的情况，将$R(s, a)$写成条件期望的形式，也就是给定概率密度函数$g(r_{t+1} | s_t=s, a_t=a)$的积分：</p><p>$$<br>\begin{equation}<br>R(s, a) = \mathbb{E}[r_{t+1} | s_t=s, a_t=a] = \int_{R_{t+1}} r \cdot g(r_{t+1} | s_t=s, a_t=a) dr<br>\end{equation}<br>$$</p><p>其中，$R_{t+1}$是此时所有可能的奖励，可以看做所有可能奖励构成的空间，在该空间按概率$g$积分，就是多次采样后的总体奖励。但是，<strong>如果只考虑眼前的奖励$R(s, a)$，容易陷入贪婪方法的局部最优</strong>。因此，即使只采取了当下的行为$a$，也必须长远考虑从$t+1$到$t+\infty$的奖励，从而尽可能逼近全局最优，也就是价值函数Value Function。</p><h3 id="价值函数-Value-Function"><a href="#价值函数-Value-Function" class="headerlink" title="价值函数 Value Function"></a>价值函数 Value Function</h3><p>虽然确实需要考虑从$t+1$到$t+\infty$的奖励，但最好能够用尽可能短的时间，获得尽可能多的奖励。因此，对于时间段$k \in (0, \infty)$，设置一个折扣因子$\gamma^k$（Discount Factor），在更近的时间值更大，反之则更小。</p><p>价值函数也分为两种：V函数和Q函数。V函数就是简单的折扣因子$\gamma^k$乘以未来奖励$r_{t+k+1}$。还是因为随机性策略需要“在概率分布中多次采样”，对于当前状态$s$下的策略$\pi$（所以有一个下标，并不是对$\pi$求期望），需要计算条件期望：</p><p>$$<br>\begin{equation}<br>V_\pi(s) = \mathbb{E}_\pi[G_t | s_t = s] = \mathbb{E}_\pi\left[ \sum_{k=0}^{\infty} \gamma^k r_{t+k+1} | s_t = s\right]<br>\label{v-function}<br>\end{equation}<br>$$<br>Q函数额外引入了动作变量$a$，从而能够在后续的深度Q学习中，通过Q函数得到进入某个状态需要采取的最优动作。</p><p>$$<br>\begin{equation}<br>Q_\pi(s, a) = \mathbb{E}_\pi[G_t | s_t = s, a_t = a] = \mathbb{E}_\pi\left[ \sum_{k=0}^{\infty} \gamma^k r_{t+k+1} | s_t = s, a_t = a\right]<br>\label{q-function}<br>\end{equation}<br>$$<br>那么，为什么要用价值函数Q函数得到最优动作$a^*$，而不是直接像式子$\eqref{sto-policy}$和$\eqref{det-policy}$，通过策略$\pi(\cdot)$得到呢？这就涉及到强化学习中对于智能体类型的划分问题：“基于价值的智能体”和“基于策略的智能体”。</p><h3 id="智能体的类型-Variants-of-Agents"><a href="#智能体的类型-Variants-of-Agents" class="headerlink" title="智能体的类型 Variants of Agents"></a>智能体的类型 Variants of Agents</h3><p>在EasyRL“蘑菇书”中，已经详细介绍了“基于价值的智能体”和“基于策略的智能体”，这里简要地概括一下：</p><ul><li><strong>基于价值的智能体</strong>：显式地学习价值函数，隐式地学习策略，策略是从价值函数中推算出来的（价值表格查表、价值函数建模）。例如，深度Q学习Deep Q-Leanring需要显式学习一个Q模型作为黑盒的价值函数。</li><li><strong>基于策略的智能体</strong>：显式地学习策略，无需价值函数，策略就是智能体输出的动作。例如，策略梯度Policy Gradient就是通过基于损失函数来直接指导模型的策略，同时能够处理连续型、离散型动作策略的问题。</li><li><strong>同时基于策略和价值的智能体</strong>：演员-评论员方法Actor-Critic结合了前述两种方法，根据智能体Actor的动作，价值函数Critic给出相应的价值。由于价值是未来奖励构成的，定向的价值可以加快基于策略方法的探索学习速度。</li></ul><p>同时，另一种常见的分类“有模型强化学习智能体”和“无模型强化学习智能体”，也可以总结如下：</p><ul><li><strong>有模型强化学习智能体</strong>：在智能体内部，需要对与之交互的真实环境进行显式的建模，构建一个包括状态转移函数$p(s_{t+1}|s_t, a_t)$以及奖励函数$R(s_t, a_t)$的虚拟环境，从而在执行动作$a_t$前，对下一步对的状态和奖励进行预测。</li><li><strong>无模型强化学习智能体</strong>：无需对交互的环境进行建模，取而代之的是需要大量的采样来估计状态、动作和奖励函数，比有模型方法需要更多的数据。相比带有偏差的、容易过拟合的虚拟环境，无模型方法的泛化能力更强。</li></ul><p><img src="https://imgur-backup.hackmd.io/K6cRnki.png" alt="on-off-policy"></p><p><center>李宏毅老师教程视频截图，图片来自shaoeChen的<a href="https://hackmd.io/@shaoeChen/Syez2AmFr">笔记</a></center><br></p><p>此外，还需要强调一种基于策略学习机制的分类方式：同策略“On-Policy”和异策略“Off-Policy”，具体如下：</p><ul><li><strong>同策略On-Policy</strong>：学习策略的智能体和与环境互动的智能体是同一个智能体，类似于自己亲自玩游戏。</li><li><strong>异策略Off-Policy</strong>：学习策略的智能体和与环境互动的智能体是不同的智能体，类似于看别人在玩游戏。</li></ul><p>同策略方法的缺点在于，基于策略的智能体在更新参数$\theta’ = \theta + \eta \nabla R_\theta$之后，隐式编码在模型参数中的策略$\pi_\theta$就变成了$\pi_{\theta’}$，基于原有策略采样出的行为轨迹$\tau \sim p_\theta(\tau)$，就无法重复用在对奖励函数的梯度计算上，需要在环境中用$\pi_{\theta’}$重新采样出新的轨迹$\tau’ \sim p_{\theta’}(\tau’)$，才能计算新的$\nabla R_{\theta’}$。</p><p>与之不同的是，异策略方法能够避开反复采样的低效过程，<strong>用一个固定的额外模型与环境交互得到一批数据</strong>，用这批数据反复训练当前模型，从而避开了反复采样的过程。从这个思路出发，是对策略梯度PG的若干改进，包括重要性采样、近端策略优化PPO等。但首先需要了解为什么$\nabla R_\theta$需要反复采样。</p><h2 id="策略梯度-Policy-Gradient"><a href="#策略梯度-Policy-Gradient" class="headerlink" title="策略梯度 Policy Gradient"></a>策略梯度 Policy Gradient</h2><p>前面描述的奖励函数$R_\theta$，实际上是当前模型$\theta$经历了各种轨迹$\tau$的总体奖励，可以认为是不同轨迹奖励$R(\tau)$的期望：</p><p>$$<br>\begin{equation}<br>R_\theta = \sum_\tau p_\theta(\tau)R(\tau) = \mathbb{E}_{\tau \sim p_\theta(\tau)}[R(\tau)]<br>\label{reward-expect}<br>\end{equation}<br>$$</p><p>注意这里期望的下标表示的是轨迹$\tau$服从了概率分布$p_\theta(\tau)$，也就是有$p$这么大的概率能采样得到$\tau$。如果参数$\theta$更新了，这个分布就改变了。那么这个分布是如何计算出来的呢？一条轨迹，包括了环境的状态改变$s$和智能体的动作$a$：</p><p>$$<br>\begin{equation}<br>\tau = \{ s_1, a_1, s_2, a_2, s_3, \cdots , a_{t-1}, s_t \}<br>\end{equation}<br>$$</p><p>除了初始状态$s_1$外，其他$a$和$s$相互关联（例如$a_1$导致了$s_2$，$s_2$又导致了$a_2$），可以得到$p_\theta(\tau)$的条件概率的连乘形式：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>p_\theta(\tau) &amp; = p(s_1) p_\theta(a_1|s_1) p_\theta(s_2|a_1) \cdots p(a_{t-1} | s_{t-1}) p(s_t | a_{t-1}) \\<br>&amp; = p(s_1) \prod_{t} p_\theta(a_{t-1}|s_{t-1}) p_\theta(s_t|a_{t-1})<br>\end{split}<br>\end{equation}<br>$$</p><p>对于式子$\eqref{reward-expect}$表示的总奖励，我们希望它尽可能的大。不同于普通的损失函数通过梯度下降，优化到尽可能小，该式子应当通过梯度上升Gradient Ascent，优化到尽可能大。所以不能采用负梯度方向$-\nabla$，而是正梯度方向：</p><p>$$<br>\begin{equation}<br>\nabla R_\theta = \sum_\tau R(\tau) \nabla p_\theta(\tau) = \sum_\tau R(\tau) \nabla \left[p(s_1) \prod_{t} p_\theta(a_{t-1}|s_{t-1}) p(s_t|a_{t-1})\right]<br>\label{prod-p}<br>\end{equation}<br>$$</p><p>其中，总奖励$R(\tau)$是一个标量，所以不用求梯度，<strong>且允许相应的奖励函数不可微</strong>。但问题是，对乘法求导/求梯度是很难算的（$(f \cdot g)’ = f’ \cdot g + f \cdot g’$），尤其是式子$\eqref{prod-p}$还有一个连乘$\prod$，需要<strong>将乘法转换为加法</strong>。注意到$\nabla \log p = \frac{\nabla p}{p}$：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>\nabla R_\theta &amp; = \sum_\tau R(\tau) \nabla p_\theta(\tau) \\<br>&amp; = \sum_\tau R(\tau) p_\theta(\tau) \nabla \log p_\theta(\tau) \\<br>&amp; = \mathbb{E}_{\tau \sim p_\theta(\tau)} [R(\tau) \nabla \log p_\theta(\tau)] \\<br>&amp; = \mathbb{E}_{\tau \sim p_\theta(\tau)} \left[R(\tau) \nabla \left( \log p(s_1) + \sum_{t} \log p_\theta(a_{t-1}|s_{t-1}) + \sum_{t} \log p(s_t|a_{t-1}) \right) \right] \\<br>&amp; = \mathbb{E}_{\tau \sim p_\theta(\tau)} \left[R(\tau) \nabla \sum_{t} \log p_\theta(a_{t-1}|s_{t-1})\right] \\<br>&amp; = \mathbb{E}_{\tau \sim p_\theta(\tau)} \left[\sum_{t} R(\tau) \nabla \log p_\theta(a_{t-1}|s_{t-1})\right]<br>\end{split}<br>\label{gradient-expect}<br>\end{equation}<br>$$</p><p>其中，梯度实际上是对参数求偏导$\nabla = \frac{\partial}{\partial \theta}$，由于$p(s_1)$和$p(s_t|a_{t-1})$都是环境自身的状态变化，与智能体$\theta$无关，因此对应梯度项均为0。在实际应用中，很难通过巨量的采样得到一个准确的分布$p_\theta(\tau)$，从而准确计算式子$\eqref{gradient-expect}$的期望$\mathbb{E}_{\tau \sim p_\theta(\tau)}$。因此，假设各个轨迹的出现概率相同均为$\frac{1}{N_\tau}$，通过求均值来近似计算期望（方便起见将$t-1$改写回$t$）：</p><p>$$<br>\begin{equation}<br>\nabla R_\theta \approx \frac{1}{N_\tau} \sum_\tau \left[\sum_t R(\tau) \nabla \log p_\theta(a_{t}|s_{t})\right]<br>\label{pg-approx}<br>\end{equation}<br>$$</p><p>即便如上这种近似的解法省略了$p_{\theta}(\tau)$，在更新参数$\theta’ = \theta + \eta \nabla R_\theta$之后，智能体预测的各个动作概率$p_\theta(a_t|s_t)$改变，行为轨迹$\tau \sim p_{\theta’}(\tau)$的概率分布$p_{\theta’}(\tau)$随之改变，导致了必须在新参数$\theta’$上重新采样轨迹$\tau$，才能得到正确的奖励$R(\tau)$。</p><h2 id="近端策略优化-Proximal-Policy-Optimization"><a href="#近端策略优化-Proximal-Policy-Optimization" class="headerlink" title="近端策略优化 Proximal Policy Optimization"></a>近端策略优化 Proximal Policy Optimization</h2><p>既然我们不想再从新参数$\theta’$对应的分布$p_{\theta’}(\tau)$上，重新采样轨迹$\tau$，那么最好的办法就是复用一套固定参数$\hat{\theta}$、在对应的固定分布$q_{\hat{\theta}}(\tau)$上采样的固定轨迹。对于式子$\eqref{reward-expect}$的期望，可以改写为积分形式：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>\nabla R_\theta &amp; = \mathbb{E}_{\tau \sim p_\theta(\tau)} [R(\tau) \nabla \log p_\theta(\tau)] \\<br>&amp; = \int [R(\tau) \nabla \log p_\theta(\tau)] p_\theta(\tau) d\tau \\<br>&amp; = \int [R(\tau) \nabla \log p_\theta(\tau)] \frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} q_{\hat{\theta}}(\tau) d\tau \\<br>&amp; = \mathbb{E}_{\tau \sim q_{\hat{\theta}}(\tau)} \left[ \frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} R(\tau) \nabla \log p_\theta(\tau) \right]<br>\end{split}<br>\label{importance-sampling}<br>\end{equation}<br>$$</p><p>这样，期望的下标从$\tau \sim p_\theta(\tau)$变成了$\tau \sim q_{\hat{\theta}}(\tau)$，<strong>而$q_{\hat{\theta}}(\tau)$本身是固定的，从而轨迹$\tau$也随之变成固定的了</strong>。无论$\theta$如何变化，使用这一套用$\hat{\theta}$采集的固定轨迹，就不需要智能体$\theta$与环境进行交互，根据改变状态$s$调整行为$a$，<strong>只需“照本宣科”地走过这条轨迹，获得$p_\theta(\tau)$和$R(\tau)$即可</strong>。那么，相比式子$\eqref{reward-expect}$，式子$\eqref{importance-sampling}$多出来的这个$\frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)}$有什么实际含义呢？</p><p><img src="https://datawhalechina.github.io/easy-rl/img/ch5/5.1.png" alt="importance-sampling"></p><p><center>重要性采样Importance Sampling的示意图，其中$x$在这里指的是轨迹$\tau$，$f(\tau)=R(\tau) \nabla \log p_\theta(\tau)$<br>图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter5/chapter5">EasyRL在线版</a></center><br></p><p>乘在$f(\tau)=R(\tau) \nabla \log p_\theta(\tau)$前面的权重$\frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)}$叫做重要性权重。如上图所示，假设中间为原点0，$f(\tau)$的数值呈现类似Sigmoid函数的变化，也就是红线。其中，$p(\tau)$是我们想要逼近的样本概率分布，当前是大多数样本在负半轴，那么对应期望$\mathbb{E}_{\tau \sim p}[f(\tau)] &lt; 0$。固定分布$q(\tau)$表示大多数样本在正半轴，那么采样到负半轴的概率更大。</p><p>在$q(\tau)$上，一旦采样到一个负半轴的样本，对应概率$q(\tau) \rightarrow 0$，则权重$\frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} \rightarrow \infty$，给对应样本的$f(\tau)$赋予了一个极大的权重，说明这个样本很接近分布$p(\tau)$，<strong>重要性很高</strong>，且此时$f(\tau) &lt; 0$。最终，期望$\mathbb{E}_{\tau \sim q}\left[\frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} f(\tau)\right] &lt; 0$，$\mathbb{E}_{\tau \sim q}\left[\frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} f(\tau)\right] \approx \mathbb{E}_{\tau \sim p}[f(\tau)]$。这个过程被称为重要性采样Importance Sampling。</p><p>在此基础上，近端策略优化Proximal Policy Optimization额外考虑了两个分布相差过大的情况，也就是上图中的$p_\theta(\tau)$和$q_{\hat{\theta}}(\tau)$两个峰离得非常远，很难碰巧在后者上采样到前者中的高频样本。因此，需要限制两个智能体参数$\theta$和$\hat{\theta}$的距离，可以通过KL散度的方式进行约束。定义最大化优化目标$\max J(\theta)$：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>J(\theta) &amp; = R_\theta - \beta \mathrm{KL}_\mathrm{PPO} \\<br>&amp; = \mathbb{E}_{\tau \sim q_\hat{\theta}}\left[ \frac{p_\theta(\tau)}{q_{\hat{\theta}}(\tau)} R(\tau) \log p_\theta(\tau) \right] - \beta \mathrm{KL}(\theta, \hat{\theta})<br>\end{split}<br>\label{ppo}<br>\end{equation}<br>$$</p><p>由于约束了两个参数$\theta$和$\hat{\theta}$尽可能拉近，所以隐式编码在参数中的策略$\pi_\theta$和$\pi_\hat{\theta}$也相似。因此，近端策略优化PPO可以认为是同策略On-Policy的方法。从同策略的PG，到异策略的重要性采样，在PPO这又绕了回来，十分地有趣。而在这里，我们将这个固定参数$\hat{\theta}$、用于采样一套固定轨迹$\tau \sim q_\hat{\theta}(\tau)$的模型叫做演员Actor。</p><h2 id="深度Q网络-Deep-Q-Networks"><a href="#深度Q网络-Deep-Q-Networks" class="headerlink" title="深度Q网络 Deep Q-Networks"></a>深度Q网络 Deep Q-Networks</h2><p>正如之前的智能体分类中所说，除了基于策略的智能体之外，还有基于价值的智能体。这种方法不再显式地学习应该采取哪个动作，而是通过评价状态$s$或者动作-状态对$(s, a)$的价值，来间接地判断当前应当采取哪个动作。做出评价的方式，包括显式的价值表格、以及之前在式子$\eqref{v-function}$和$\eqref{q-function}$提到的价值函数，也称为评论家Critic。</p><p>离散划分的价值表格往往无法处理数值连续型的状态。但是，显式定义的价值函数也无法精确建模复杂的环境。因此，使用具有“万能逼近原理”的神经网络来表示价值函数（主要是Q函数），称为深度Q网络方法Deep Q-Networks。</p><p>首先，定义价值函数为式子$\eqref{v-function}$中的V函数$V_\pi(s)$，可以看到它只考虑了状态的价值。如果它是一个神经网络的话，我们应该如何训练它？EasyRL里面介绍了两种方法：蒙特卡洛方法和时序差分方法。</p><ul><li><p><strong>蒙特卡洛方法</strong>：在环境中采样各种轨迹$\tau$，在其中选取某个状态$s_t$，直接让网络学习回归式子$\eqref{v-function}$中的未来总收益$G(s_t)$，即$V_\pi(s_t) = G(s_t)$，其中$G(s_t)=\sum_t^{t+\mathrm{T}} r_t$, 每个时间点的奖励$r_t \in \tau = \{ s_{t+k}, a_{t+k}, r_{t+k} \}_{k\in (0, \mathrm{T})}$。</p></li><li><p><strong>时序差分方法</strong>：蒙特卡洛方法的最大问题是忽略了单个状态的多解性，也就是有多条轨迹$\tau$都能经过同一个$s_t$，奖励$r_t$的方差很大。而且在求$G(s_t)$时，每个奖励$r_t$也如此，求和后的方差$\mathrm{Var}[\mathrm{T} \times r_t] = \mathrm{T}^2 \mathrm{Var}[r_t]$。但是，两个状态之间的转移是相对确定的，其奖励变化$r_t = V_\pi(s_t) - V_\pi(s_{t+1})$的方差也更小，因此可以学习回归$r_t$。</p></li></ul><p><img src="https://datawhalechina.github.io/easy-rl/img/ch6/6.3.png" alt="time-diff"></p><p><center>时序差分方法的示意图，注意是未来总收益，所以$V_\pi(s_t) &gt; V_\pi(s_{t+1})$，图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter6/chapter6">EasyRL在线版</a></center><br></p><p>正因为这个“殊途同归”的多解性，即便学会了V函数，也很难直接根据最大V函数对应的状态$s$，反推出应采取的行为$a = \pi(s)$。因此，式子$\eqref{q-function}$中的Q函数$Q_\pi(s, a)$加入了行为输入，从而像式子$\eqref{det-policy}$一样反推出最优$a^* = \pi’(s)$：</p><p>$$<br>\begin{equation}<br>a^* = \pi’(s) = \arg\max_a Q_\pi (s, a)<br>\label{q-function-argmax}<br>\end{equation}<br>$$</p><p>注意，在Q函数中的输入行为$a$并不代表它一定会采取这个行为，而是将所有可能的行为$a$和当前的状态$s$都配对输入了一遍，看哪一个的价值$Q_\pi(s, a)$更大。根据Q函数的定义式$\eqref{q-function}$，$Q_\pi(s, a)$指的是采取当前行为之后的未来总收益，未来用的策略还是原来的策略$\pi$，只是当前强制用了一个行为$a$，这个行为是所有可能的行为之一，与策略$\pi$无关。</p><p><img src="https://datawhalechina.github.io/easy-rl/img/ch6/6.9.png" alt="Q-Learning"></p><p><center>深度Q网络的学习方式，图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter6/chapter6">EasyRL在线版</a></center><br></p><p>这个Q函数的学习方式，就可以是对策略的更新过程。那么问题来了，<strong>沿用原来策略$\pi$计算未来收益，找到了一个最好的$a^*$，这个只改变了一个行为的新策略$\pi’$为什么能够直接替换掉$\pi$？</strong>万一就因为改了这一个行为，未来总收益$V_{\pi’}(s) = Q_{\pi’}(s, a)$就比$V_{\pi}(s) = Q_\pi(s, a)$更差了呢。所以需要证明$V_{\pi}(s) \leq V_{\pi’}(s)$。首先改写式子$\eqref{q-function-argmax}$成$\max$形式：</p><p>$$<br>\begin{equation}<br>Q_\pi(s, \pi’(s)) = \max_a Q_\pi (s, a) \geq Q_\pi (s, a) = V_{\pi}(s)<br>\label{q-function-neq}<br>\end{equation}<br>$$</p><p>注意下标，计算未来收益时，策略都用原来的策略$\pi$，所以这个不等式是显然的，但$Q_\pi(s, \pi’(s)) \neq V_{\pi’}(s)$。根据式子$\eqref{q-function}$，展开$Q_\pi(s, \pi’(s))$，注意$G_t = r_t + V_\pi(s_{t+1})$，由不等式$\eqref{q-function-neq}$有$V_\pi(s_{t+1}) \leq Q_\pi(s_{t+1}, \pi’(s_{t+1}))$：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>V_\pi (s)<br>&amp; \leq Q_\pi(s, \pi’(s)) \\<br>&amp; = \mathbb{E}_\pi \left[ r_t + V_\pi(s_{t+1}) | s_t = s, a_t = \pi’(s) \right] \\<br>&amp; \leq \mathbb{E}_\pi \left[ r_t + Q_\pi(s_{t+1}, \pi’(s_{t+1})) | s_t = s, a_t = \pi’(s) \right] \\<br>&amp; = \mathbb{E}_\pi \left[ r_t + r_{t+1} + V_\pi(s_{t+2}) | s_t = s, a_t = \pi’(s) \right] \\<br>&amp; \cdots \\<br>&amp; \leq \mathbb{E}_\pi \left[ r_t + r_{t+1} + r_{t+2} + \cdots + r_\mathrm{T} | s_t = s, a_t = \pi’(s) \right] \\<br>&amp; = V_{\pi’}(s)<br>\end{split}<br>\label{q-function-proof}<br>\end{equation}<br>$$</p><p>个人认为，其实式子$\eqref{q-function-argmax}$是一个强假设，相当于$s$并不是一个特定的状态，而是可以随意替换成$s_t$或$s_{t+1}$都能成立的。相当于对任意状态$s$，都有只改一个$a$的新策略$\pi’$有更高的未来总收益$Q_\pi(s, \pi’(s))$，从而推出$\eqref{q-function-proof}$。</p><p>基于如此强的假设，策略$\pi$是怎么正确学习的呢？定义一个Q神经网络$Q_\pi(s, a)$，其输入是状态$s$和可能的行为$a$，而策略$\pi$是隐式编码在网络的权重当中的。参考前述的时间差分方法示意图，这个神经网络同样应当满足回归损失的约束：</p><p>$$<br>\begin{equation}<br>Q_\pi(s_{t}, a_{t}) = r_{t} + Q_\pi(s_{t+1}, \pi(s_{t+1}))<br>\end{equation}<br>$$</p><p>可以观察到，<strong>时间差分方法不需要采样出一个完整的轨迹$\tau$</strong>，每次只需要用当前的策略$\pi$与环境交互一次，采样出一组$\{ s_t, a_t, r_t, s_{t+1} \}$。如果能采到各种不同状态$s$，就可以找到一个新策略$\pi’$在各种状态下都能满足式子$\eqref{q-function-argmax}$。</p><p><img src="https://datawhalechina.github.io/easy-rl/img/ch6/6.17.png" alt="exp-relay"></p><p><center>经验重放技巧Experience Replay，图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter6/chapter6">EasyRL在线版</a></center><br></p><p>为了训练的稳定性，可以<strong>将$Q_\pi(s_{t+1}, a_{t+1})$设为一个定期更新的“目标网络”</strong>，不直接回传梯度，只有公式左边的Q网络预测值回传梯度。此外，<strong>为了减少当前策略与环境的交互的次数</strong>，将历史上的其他策略放入一个先入先出的队列中，不断将当前策略采样的$\{ s_t, a_t, r_t, s_{t+1} \}$放入这个队列，而最旧的策略不断出队，每次训练从这个队列中采样训练样本。何凯明提出的MoCo系列对比学习方法<sup class="refplus-num"><a href="#ref-MoCo">[5]</a></sup>的动量更新模型+负样本队列，就很像“目标网络”+“经验重放”这两个技巧。</p><h2 id="深度确定性策略梯度-Deep-Deterministic-Policy-Gradient"><a href="#深度确定性策略梯度-Deep-Deterministic-Policy-Gradient" class="headerlink" title="深度确定性策略梯度 Deep Deterministic Policy Gradient"></a>深度确定性策略梯度 Deep Deterministic Policy Gradient</h2><p>对于深度Q网络DQN来说，在输入状态$s$的同时，还需要遍历输出各种可能的行为$a$对应的Q值$Q(s, a)$。如果当前任务的行为空间是离散的，例如有上下左右4种动作，那么相对容易遍历，只需定义Q网络的输出数量为4即可。但如果当前任务的行为空间是连续的，例如某个控制量的取值范围是$(0, 1)$，就没办法遍历所有的数值了。</p><p><img src="https://datawhalechina.github.io/easy-rl/img/ch12/12.5.png" alt="DDPG" width="75%"></p><p><center>深度确定性策略梯度Deep Deterministic Policy Gradient在深度Q网络上的改进，图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter12/chapter12">EasyRL在线版</a></center><br></p><p>如果有一个额外的网络，帮助预测当前的$a$，使得深度Q网络获得了状态和行为2个输入，就可以只输出1个Q值代表$Q(s, a)$了。这个额外的网络就是策略梯度训练出来的网络。由于需要确定的行为$a$，式子$\eqref{pg-approx}$中基于随机概率$p_\theta(a_t|s_t)$的方法不太好用了，因此采用的确定性方法，全称就是深度确定性策略梯度Deep Deterministic Policy Gradient<sup class="refplus-num"><a href="#ref-DDPG">[6]</a></sup>。</p><p><img src="https://datawhalechina.github.io/easy-rl/img/ch12/12.8.png" alt="DDPG-train"></p><p><center>基于目标网络+经验重放的DDPG训练过程，图片来自<a href="https://datawhalechina.github.io/easy-rl/#/chapter12/chapter12">EasyRL在线版</a></center><br></p><p>之前在近端策略优化的结尾、深度Q网络的开头，我们分别定义了演员Actor和评论家Crtic，在这里，演员变成了策略网络，评论家则是Q网络。继承了深度Q网络的目标网络技巧，分别定义目标Q网络$Q_\bar{w}(s’, a’)$和目标策略网络$a’ = \mu_\bar{\theta}(s’)$，两者参数定期从原网络更新。给定经验回放缓冲区$\{s, a, r, s’\} \sim \mathcal{D}$，基于时序差分方法的Q网络损失：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>Q_w(s, a) &amp; = r + \gamma Q_\bar{w}(s’, a’) \\<br>\Rightarrow \mathcal{L}_\mathrm{Q} &amp; = \mathbb{E}_{\{s, a, r, s’\} \sim \mathcal{D}} \left\Vert  Q_w(s, a) - (r + \gamma Q_\bar{w}(s’, a’)) \right\Vert^2_2 \\<br>&amp; = \mathbb{E}_{\{s, a, r, s’\} \sim \mathcal{D}} \left\Vert  Q_w(s, a) - (r + \gamma Q_\bar{w}(s’, \mu_\bar{\theta}(s’))) \right\Vert^2_2 \\<br>&amp; \approx \frac{1}{N_s} \sum_s \left\Vert  Q_w(s, a) - (r + \gamma Q_\bar{w}(s’, \mu_\bar{\theta}(s’))) \right\Vert^2_2<br>\end{split}<br>\end{equation}<br>$$</p><p>由于是在缓冲区$\mathcal{D}$上采样，所以是求期望。同样可以仿照式子$\eqref{pg-approx}$近似成求均值。同时，策略网络的优化目标是最大化“评论家”Q网络的输出价值，加一个负号就是最小化。为了与之前的随机性方法策略梯度区分，可以展开成积分形式：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>\mathcal{L}_\mathrm{\mu} &amp; = \mathbb{E}_{\{s, a, r, s’\} \sim \mathcal{D}} \left[ -Q_w(s, a) \right] \\<br>&amp; = - \int \rho(s)Q_w(s, a) ds = - \int \rho(s)Q_w(s, \mu_\theta(s)) ds<br>\end{split}<br>\end{equation}<br>$$</p><p>可以看到，与策略梯度中的式子$\eqref{reward-expect}$不同，奖励$R(\tau)$变成了Q网络预测的Q值$Q_w(s, a)$，由策略模型预测的各行为概率$p_\theta(a_t|s_t)$构成的概率分布$p_\theta(\tau)$，变成了确定的$a = \mu_\theta(s)$，所以叫确定性策略梯度。期望里的概率值变为了在经验回放缓冲区上的采样$\rho(s)$（正常应该是$\rho(\{(s, a, r, s’)\})$）。和式子$\eqref{gradient-expect}$一样求梯度$\nabla = \frac{\partial}{\partial \theta}$，并和$\eqref{pg-approx}$一样近似求均值：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>\nabla \mathcal{L}_\mathrm{\mu} &amp; = - \nabla \int \rho(s)Q_w(s, \mu_\theta(s)) ds \\<br>&amp; = - \int \rho(s) \nabla Q_w(s, \mu_\theta(s)) \nabla \mu_\theta(s) ds \\<br>&amp; \approx \frac{1}{N_s} \sum_s \left[\nabla Q_w(s, \mu_\theta(s)) \nabla \mu_\theta(s) \right]\\<br>\end{split}<br>\end{equation}<br>$$</p><p>需要注意$Q_w(s, \mu_\theta(s))$是包含$\theta$的复合函数，复合函数求导$(f(g(x)))’ = f’(g(x)) \cdot g’(x)$。此外，虽然确定性的行为$a = \mu_\theta(s)$样本量需求小，但也导致在环境中的探索范围受限。对输出的行为$a$加入噪声，用$\mathrm{clip}(\cdot)$函数限制上下界：</p><p>$$<br>\begin{equation}<br>a = \mathrm{clip}(\mu_\theta(s) + \epsilon, a_\mathrm{low}, a_\mathrm{high}), \epsilon \sim \mathcal{N}(0, \sigma^2 I)<br>\end{equation}<br>$$</p><p>总结一下，从策略梯度PG到近端策略优化PPO、深度确定性策略梯度DDPG，<strong>强化学习与环境交互的成本在不断压缩</strong>：</p><ul><li><p>一方面，PPO将策略梯度中需要反复采样的轨迹$\tau \sim p_\theta(\tau)$改为固定的$\tau \sim q_\hat{\theta}(\tau)$，通过重要性采样方法来赋予$p_\theta(\tau)$和$q_\hat{\theta}(\tau)$两个分布的权重。但仍然需要环境给出固定轨迹的总体奖励$R(\tau)$。</p></li><li><p>另一方面，基于价值的方法DQN、DDPG直接不需要轨迹$\tau$，而是采用了时序差分方法，直接计算相邻两个状态$s_t$和$s_{t+1}$的价值Q函数之差$r_t$。目标模型技巧稳定了时序差分方法的训练过程，而经验重放技巧引入了历史交互的缓冲区队列$\{s, a, r, s’\} \sim \mathcal{D}$，进一步减少了当前策略下与环境的交互过程。</p></li></ul><h2 id="强化学习-大语言模型-RL-based-Large-Language-Models"><a href="#强化学习-大语言模型-RL-based-Large-Language-Models" class="headerlink" title="强化学习+大语言模型 RL-based Large Language Models"></a>强化学习+大语言模型 RL-based Large Language Models</h2><p>在近期火热的大语言模型领域，最经典的强化学习应用就是OpenAI发布的ChatGPT。在其第3个训练步骤中，采用了人类反馈的强化学习RLHF（Reinforcement Learning from Human-Feedback），是近端策略优化PPO的改进方法。</p><p>与式子$\eqref{ppo}$相比，奖励$R(\tau)$由一个独立的黑盒偏好模型给出（实际上是通过人类偏好排序得到的奖励），而非一个显式的公式；PPO中的KL散度约束，也不再是对权重进行约束，而是对模型输出的分布进行约束，但同样是一个固定权重、另一个学习权重。从基本定义来看，只要是能够通过分布约束，稳定强化学习的优化范围，都可以认为是PPO。</p><p><img src="/2024/07/02/Notes-About-Deep-Q-Learning/rlhf.png" alt="rlhf"></p><p><center>OpenAI提出的基于PPO的人类反馈的强化学习RLHF，图片来自<a href="https://huggingface.co/blog/rlhf">HuggingFace</a></center><br></p><p>此外，颜水成团队在2024年6月份发表在arXiv上的文章Q*<sup class="refplus-num"><a href="#ref-Q-Star">[7]</a></sup>也尝试实现了传闻中OpenAI基于深度Q学习的下一代模型。该方法改进了训练结束后的自回归模型在推理过程中的采样方式，与之前提到的贪婪方法、集束搜索Beam Search方法不同，尝试训练了一个额外的Q-Value模型，预测模型在Top-K个采样序列上的Q值，选取Q值最大的序列作为结果。值得注意的是，该方法使用开源小模型作为基线方法，在使用Q*采样后，<strong>确实和传闻中一样能够在解数学题等逻辑推理问题上，超过多个闭源大模型</strong>。此外，结合Beam Search和Levin Tree Search等搜索方法、以及类似强化学习的过程监督奖励模型，华为蒙特利尔诺亚方舟实验室提出的MindStar<sup class="refplus-num"><a href="#ref-Mind-Star">[8]</a></sup>采样方法，也能取得类似的“超越闭源大模型”的提升效果。</p><p><img src="/2024/07/02/Notes-About-Deep-Q-Learning/q-star.png" alt="q-star"></p><p><center>颜水成团队实现的基于深度Q学习的大语言模型采样方法Q*，图片来自论文原文<sup class="refplus-num"><a href="#ref-Q-Star">[7]</a></sup></center><br></p><p>显然，大语言模型底层的自回归生成序列、轨迹的能力，不仅与强化学习的结合是如鱼得水的，而且还能扩展到其他领域，尤其是以深度学习三巨头Hinton团队提出的Pixel2Seq为代表的自回归视觉感知方法<sup class="refplus-num"><a href="#ref-Pixel2Seq">[9]</a></sup>。在此基础上，谷歌DeepMind团队发表在ICML 2023上的工作“Tuning Computer Vision Models With Task Rewards”<sup class="refplus-num"><a href="#ref-Tuning">[10]</a></sup>将不可微的评测指标，用式子$\eqref{prod-p}$中的策略梯度引入到了目标检测、图片描述生成等自回归方法中。当然，还有更多能够转化为自回归生成的研究或应用任务场景，等待着我们进一步去探索如何用强化学习进一步“强化”。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Toward" data-num="1">[1]  Minsky M. Steps toward artificial intelligence[J]. Proceedings of the IRE, 1961, 49(1): 8-30.</li><li id="ref-Hung-yi-Lee" data-num="2">[2]  李宏毅. 深度强化学习. http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html</li><li id="ref-Sutton" data-num="3">[3]  Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction[M]. MIT press, 2018.</li><li id="ref-Easy-RL" data-num="4">[4]  王琦，杨毅远，江季. Easy RL：强化学习教程[M]. 人民邮电出版社, 2022.</li><li id="ref-MoCo" data-num="5">[5]  He K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual representation learning[C]// Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020: 9729-9738.</li><li id="ref-DDPG" data-num="6">[6]  Continuous control with deep reinforcement learning[J]. 4th International Conference on Learning Representations, 2016.</li><li id="ref-Q-Star" data-num="7">[7]  Wang C, Deng Y, Lv Z, et al. Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning[J]. arXiv preprint arXiv:2406.14283, 2024.</li><li id="ref-Mind-Star" data-num="8">[8]  Kang J, Li X Z, Chen X, et al. MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time[J]. arXiv preprint arXiv:2405.16265, 2024.</li><li id="ref-Pixel2Seq" data-num="9">[9]  Chen T, Saxena S, Li L, et al. Pix2seq: A Language Modeling Framework for Object Detection[C]//The Tenth International Conference on Learning Representations, 2022.</li><li id="ref-Tuning" data-num="10">[10]  Pinto A S, Kolesnikov A, Shi Y, et al. Tuning computer vision models with task rewards[C]//International Conference on Machine Learning. PMLR, 2023: 33229-33239.</li></ul>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Neural Flows</title>
      <link href="/2024/06/08/Notes-About-Neural-Flows/"/>
      <url>/2024/06/08/Notes-About-Neural-Flows/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Finite systems of deterministic ordinary nonlinear differential equations<br>may be designed to represent<br>forced dissipative hydrodynamic flow.<br>in <em>Deterministic Nonperiodic Flow</em>, Edward Lorenz</p></blockquote><p>本文是关于神经流模型Neural Flows的学习笔记<br>主要是其作为Neural ODE的全新迭代，以及可逆残差网络Invertible Residual Networks和相关补充知识</p><span id="more"></span><h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>在发现“蝴蝶效应”的著名论文《确定性的非周期流动》<sup class="refplus-num"><a href="#ref-DeterNF">[1]</a></sup>中，混沌理论之父爱德华·洛伦兹写下了上面这段话：“可以设计由确定性非线性常微分方程构成的有限系统，来表示受外力耗散流体的流动”。</p><p>这个世界终究是物理的。在扩散模型Diffusion被成功引入到图像生成任务后，郎之万动力学Langevin Dynamics<sup class="refplus-num"><a href="#ref-NCSN">[2]</a></sup>、可逆过程Reverse Process<sup class="refplus-num"><a href="#ref-DDPM">[3]</a></sup>、归一化流Normalizing Flow<sup class="refplus-num"><a href="#ref-DiffuNF">[4]</a></sup>，各种物理模型被先后引入进来。最终，各个角度被统一成随机微分方程Stochastic Differential Equation<sup class="refplus-num"><a href="#ref-SDE-ODE">[5]</a></sup>，并可以被确定的常微分方程Ordinary Differential Equation表示<sup class="refplus-num"><a href="#ref-DDIM">[6]</a></sup>。</p><p>微分方程不仅是教材上的几个章节，它是解析这个物理世界的工具之一。但也正因为是相对统一的工具，如果用更符合物理规律的理论来建模，就有机会更好地拟合这个世界的底层细节。所以，出现比Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[7]</a></sup>更加迭代的全新模型是必然的，只是应当选取哪一种物理模型而已。本次笔记要介绍的就是神经流模型Neural Flows<sup class="refplus-num"><a href="#ref-Neural-Flows">[8]</a></sup>。</p><h2 id="常微分方程的可逆性-Invertibility-of-ODE"><a href="#常微分方程的可逆性-Invertibility-of-ODE" class="headerlink" title="常微分方程的可逆性 Invertibility of ODE"></a>常微分方程的可逆性 Invertibility of ODE</h2><p>在物理层面上，流体的流动是基于向量映射关系的，也就是当前时刻$t$的某个位置$x_t$，到下一个时刻$t+\Delta t$应当流动到位置$x_{t+\Delta t}$，可以构成一个向量$\vec{x_t}$；对于所有位置$\mathrm{X}_t$，则有向量场$\vec{\mathrm{X}_t}$。</p><p>显然地，给定一个初始位置$x_0$，通过在$\vec{\mathrm{X}_t}$中无数次的流动过程，到第$\mathrm{T}$个时刻时，有且只有一个最终位置$x_\mathrm{T}$。也就是说，从起点到终点同样需要符合映射关系，否则就会出现同一个起点vs多个终点、或者一个终点vs多个起点的问题。</p><p>为了描述这种性质，我们需要将映射定义为可逆映射，也就是给定终点，同样要能够通过相反方向得到终点。而这种性质，恰好是常微分方程ODE能够满足的：</p><p>$$<br>\begin{equation}<br>x_\mathrm{T} = x_0 + \int_0^\mathrm{T} \frac{dx}{dt} dt<br>\end{equation}<br>$$</p><p>$$<br>\begin{equation}<br>x_0 = x_\mathrm{T} - \int_0^\mathrm{T} \frac{dx}{dt} dt = x_\mathrm{T} + \int_\mathrm{T}^0 \frac{dx}{dt} dt<br>\end{equation}<br>$$</p><p>在式子（1）中，可以看到正向积分$\int_0^\mathrm{T} \frac{dx}{dt} dt$；而式子（2）中，可以看到反向积分$\int_\mathrm{T}^0 \frac{dx}{dt} dt$。也就是说，常微分方程$\frac{dx}{dt}=f(x)$可以处理前一个积分结果$x_t$，或者后一个积分结果$x_{t+\Delta t}$，输出变化量$f(x)$：</p><p>$$<br>\begin{align}<br>&amp; x_{t+\Delta t} = x_t + f(x_t) \Delta t \\<br>&amp; x_{t} = x_{t+\Delta t} - f(x_{t+\Delta t}) \Delta t \\<br>\end{align}<br>$$</p><h2 id="神经流模型-Neural-Flows"><a href="#神经流模型-Neural-Flows" class="headerlink" title="神经流模型 Neural Flows"></a>神经流模型 Neural Flows</h2><p>然而，回顾<a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2">之前的笔记</a>，计算常微分方程的积分是有代价的，那便是数值求解器$\mathrm{ODESolver}$。从$0$到$\mathrm{T}$的过程越长，计算$x_\mathrm{T}$花费的时间和存储就越高，即使是各种新的数值求解器也避免不了这个问题，只能尽量用可变步长等方式缓解。</p><p><img src="/2024/06/08/Notes-About-Neural-Flows/Neural-Flow.png" width="75%"></p><center>Neural ODE与Neural Flows模型对比，可以发现Neural Flows既不需要求解器，也不需要关注瞬时变化<br>只关心起始点$x_0$和时间$\mathrm{T}$。图片来自论文原文<sup class="refplus-num"><a href="#ref-Neural-Flows">[8]</a></sup></center><p><br></p><p>那么，是否能够在去掉$\mathrm{ODESolver}$的前提下，保留一个能够满足式子（1）和（2）的$x_0$与$x_\mathrm{T}$双向、可逆映射的神经网络呢？这个神经网络只需要输入初值是$x_0$、终点时间是$\mathrm{T}$，就能直接输出$x_\mathrm{T}$，也就是：</p><p>$$<br>\begin{equation}<br>\forall x_0, \mathrm{T},~~~ x_\mathrm{T} = F(\mathrm{T}, x_0)<br>\end{equation}<br>$$</p><p>从物理的角度看，这个条件就是流体的流动过程，所以为了和Neural ODE区分，称为神经流模型Neural Flow。但是，普通的神经网络可以满足这个性质吗？反例是，一个神经网络可能会对不同的$(x_0, \mathrm{T})$，输出同样的$x_\mathrm{T}$（联想一下，分类问题是不是就是这样，需要把不同数据输出为同一个类），这就与式子（1）和（2）矛盾了。</p><h2 id="可逆残差网络-Invertible-Residual-Networks"><a href="#可逆残差网络-Invertible-Residual-Networks" class="headerlink" title="可逆残差网络 Invertible Residual Networks"></a>可逆残差网络 Invertible Residual Networks</h2><p>Neural Flow用到了可逆残差网络，是Neural ODE作者陈天琦等人在ICML 2019上发表的工作<sup class="refplus-num"><a href="#ref-IRN">[9]</a></sup>，与之前的可逆神经网络<sup class="refplus-num"><a href="#ref-INN">[10]</a></sup>完全不同的是，这篇文章提出了一个极其简洁的约束方式，使得神经网络能够满足双向、可逆的性质。</p><p><img src="/2024/06/08/Notes-About-Neural-Flows/IRN.png" alt="IRN"></p><center>与普通ResNet比较，可逆残差网络的双向映射性质的体现。从底部的不同Input出发<br>不断普通ResNet的过程中存在若干交叉，上2个交叉甚至是整体的坍塌，导致无法从Output逆向<br>图片来自论文原文<sup class="refplus-num"><a href="#ref-IRN">[9]</a></sup></center><p><br></p><p>首先，将一个普通的残差模块描述为式子（6）。同时，可以通过定义步长$h \rightarrow 0$，将其重组为一个常微分方程ODE：</p><p>$$<br>\begin{align}<br>&amp; x_{t+1} = x_t + g_{\theta_t}(x_t) \\<br>\Rightarrow &amp; x_{t+1} - x_t = g_{\theta_t}(x_t)\nonumber \\<br>\Rightarrow &amp; x_{t+h} - x_t = hf_{\theta_t}(x_t) \\<br>\Rightarrow &amp; \lim_{h\rightarrow 0} \frac{x_{t+h} - x_t}{h} = f_{\theta_t}(x_t)\nonumber \\<br>\Rightarrow &amp; \frac{dx_t}{dt} = f_{\theta_t}(x_t) \\<br>\end{align}<br>$$</p><p>那么，对于式子（7），同样可以认为有逆向过程：</p><p>$$<br>\begin{equation}<br>x_t = x_{t+h} - hf_{\theta_t}(x_t)<br>\end{equation}<br>$$</p><p>但是，仔细比较残差模块的式子（7）和常微分方程的式子（4）可以发现，既然$h = \Delta t \rightarrow 0$，那么唯一的区别就是$f(x)$的输入不一样，式子（4）是$x_{t+\Delta t}$，而式子（7）是$x_{t}$。也就是说，残差模块$f_{\theta_t}(x)$无法将$x_{t+h}$作为输入进行逆向计算，并不是一个真正的ODE。从另一个角度看，这也是一个经典的“先有鸡、先有蛋”悖论，既然都要求解$x_t$，是个未知量，还得通过$x_t$才能得到$f_{\theta_t}(x_t)$。很显然，这是自相矛盾的，也不符合ODE的可逆性质。</p><h2 id="利普希茨连续性-Lipschitz-Continuity"><a href="#利普希茨连续性-Lipschitz-Continuity" class="headerlink" title="利普希茨连续性 Lipschitz Continuity"></a>利普希茨连续性 Lipschitz Continuity</h2><p>按照ODE的结构，重写残差模块的逆向过程：对于$h\rightarrow 0$，给定已知的$x_{t+h}$，$f_{\theta_t}$需要支持输入$x_{t+h}$，得到前一个$x_t$：</p><p>$$<br>\begin{equation}<br>x_t = x_{t+h} - hf_{\theta_{t+h}}(x_{t+h}) \nonumber<br>\end{equation}<br>$$</p><p>但是，宏观上ResNet的残差模块只支持离散的步长$h = 1, f_{\theta_{t+h}}=f_{\theta_{t}}=g_{\theta_{t}}$的情况，所以ODE的结构无法直接照搬。为了在离散步长$h=1$条件下，使得固定残差模块$f_{\theta_{t}}$满足连续步长的性质，将式子（10）改写为一个反复迭代的过程：</p><p>$$<br>\begin{equation}<br>\forall n \in \mathbb{N}, x_t^0=x_{t+1} \Rightarrow x_t^{n+1} = x_{t+1} - g_{\theta_t}(x_t^n)<br>\end{equation}<br>$$</p><p>显然，我们希望这个逆向的过程能够收敛到唯一的$x_t$上，所以需要满足$\Vert x_t^{n+1} - x_t^{n}\Vert \rightarrow 0$：</p><p>$$<br>\begin{equation}<br>\lim_{n \rightarrow \infty} x_t^n = x_t \Rightarrow \forall n\rightarrow \infty,~ \Vert x_t^{n+1} - x_t^n\Vert \rightarrow 0<br>\end{equation}<br>$$</p><p>这里主要参考苏剑林的推导过程<sup class="refplus-num"><a href="#ref-Kexue-IRN">[11]</a></sup>，此处省略$t$和$\theta_t$，因为除了上标$n$以外，所有的下标都不变。可以代入式子（10），改写为函数$g(x)$的绝对差值：</p><p>$$<br>\begin{equation}<br>\Vert x_{n+1} - x_n \Vert = \Vert g(x_n) - g(x_{n-1})\Vert<br>\end{equation}<br>$$</p><p>那么两个函数的绝对差值是否有一个使其趋近于0的上界呢？这里就可以用到函数的利普希茨常数（Lipschitz Constant）：函数任意两点斜率绝对值的上确界（最大值），记作$\mathrm{Lip}(g)$：</p><p>$$<br>\begin{align}<br>&amp; \mathrm{Lip(g)} = \sup_{x_1 \neq x_2} \frac{\Vert g(x_1) - g(x_2)\Vert}{\Vert x_1 - x_2 \Vert} \nonumber \\<br>&amp; \Rightarrow \frac{\Vert g(x_1) - g(x_2)\Vert}{\Vert x_1 - x_2 \Vert} \leq \mathrm{Lip(g)} \nonumber \\<br>&amp; \Rightarrow \Vert g(x_1) - g(x_2)\Vert \leq \mathrm{Lip(g)} \Vert x_1 - x_2 \Vert<br>\end{align}<br>$$</p><p>例如，ReLU函数的$\mathrm{Lip}(g)=1$；抛物线函数$x^2$的一阶导为$2x \in (-\infty, +\infty)$，则$\mathrm{Lip}(g) = \infty$。像ReLU这样，存在一个常数$\mathrm{k}_0$，使得函数$g$的利普希茨常数$\mathrm{Lip}(g) \leq \mathrm{k}_0$，那么称这个函数满足利普希茨连续性 （Lipschitz Continuity）：</p><p>$$<br>\begin{equation}<br>\mathrm{Lip(g)} \leq \mathrm{k}_0 \Rightarrow \Vert g(x_1) - g(x_2)\Vert \leq \mathrm{k}_0 \Vert x_1 - x_2 \Vert<br>\end{equation}<br>$$</p><p><img src="/2024/06/08/Notes-About-Neural-Flows/Lip-1.png" alt="Lip-1"></p><center>通过任意两点之间的斜率，可以直观地判断出ReLU函数的利普希茨常数$\mathrm{Lip}(g)=1$。<a href="https://www.bilibili.com/video/BV1B64y157DC?t=374.8">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-Lip">[12]</a></sup></center><p><br></p><p><img src="/2024/06/08/Notes-About-Neural-Flows/Lip-2.png" alt="Lip-2"></p><center>通过求一阶导数（梯度nabla算子$\nabla$），可以判断出抛物线函数的$\mathrm{Lip}(g) = \infty$<br>还能进一步推导出，利普希茨常数有界的意义：在任意两点之间，函数值变化不会过于剧烈。<a href="https://www.bilibili.com/video/BV1B64y157DC?t=850.1">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-Lip">[12]</a></sup></center><p><br></p><p>如上图所示，利普希茨连续性直观地保证了任意两点之间，函数的变化是有上下界的，从而使得两个函数的绝对差值是有上界的。因此，将式子（13）代入式子（12），我们可以得到推导过程：</p><p>$$<br>\begin{split}<br>\Vert x_{n+1} - x_n \Vert &amp; = \Vert g(x_n) - g(x_{n-1})\Vert \\<br>&amp; \leq \mathrm{Lip(g)} \Vert x_n - x_{n-1} \Vert \\<br>&amp; = \mathrm{Lip(g)} \Vert g(x_{n-1}) - g(x_{n-2})\Vert \\<br>&amp; \leq \mathrm{Lip(g)}^2 \Vert x_{n-1} - x_{n-2} \Vert \\<br>&amp; \cdots \\<br>&amp; \leq \mathrm{Lip(g)}^n \Vert x_1 - x_0 \Vert<br>\end{split}<br>$$</p><p>显然，当满足式子（11）的$\Vert x_{n+1} - x_{n}\Vert \rightarrow 0$时，$\mathrm{Lip(g)} &lt; 1$，否则将趋近于1或者$\infty$。这个条件正是要求函数$g$、也即残差模块神经网络，满足式子（14）的利普希茨连续性。直观上看，这就是要求在式子（10）这种逆向过程中，函数的输出不能剧烈跳变，要逐步迭代收敛到逆向的目标$x_t$上。</p><p>但是，相邻两点$\Vert x_{n+1} - x_{n}\Vert \rightarrow 0$无法保证绝对收敛，一个反例就是自然对数函数$\ln(x)$，虽然相邻两点变化幅度不大，但它在$n\rightarrow \infty$时是发散的。因此，需要保证任意两点间的$\Vert x_{n+m} - x_{n}\Vert \rightarrow 0$：</p><p>$$<br>\begin{split}<br>\Vert x_{n+m} - x_{n}\Vert &amp; \leq\Vert x_{n+m} - x_{n+m-1}\Vert+\cdots \\<br>&amp; +\Vert x_{n+2} - x_{n+1}\Vert+\Vert x_{n+1} - x_{n}\Vert\\<br>&amp;\leq \left(\mathrm{Lip}(g)^{n+m-1}+\cdots+\mathrm{Lip}(g)^{n}\right)\Vert x_{1} - x_{0}\Vert\\<br>&amp; = \frac{1 - \mathrm{Lip}(g)^m}{1 - \mathrm{Lip}(g)}\cdot\mathrm{Lip}(g)^{n}\Vert x_{1} - x_{0}\Vert\\<br>&amp; \leq \frac{\mathrm{Lip}(g)^n}{1 - \mathrm{Lip}(g)}\Vert x_{1} - x_{0}\Vert<br>\end{split}<br>$$</p><p>同样地，为了$\Vert x_{n+m} - x_{n}\Vert \rightarrow 0$，应当有$\mathrm{Lip(g)} &lt; 1$，否则无解（$\mathrm{Lip(g)} = 1$）或趋近于$\infty$。当$m \rightarrow \infty$时：</p><p>$$<br>\Vert x_\infty - x_{n}\Vert \leq \frac{\mathrm{Lip}(g)^n}{1 - \mathrm{Lip}(g)}\Vert x_{1} - x_{0}\Vert<br>$$</p><p>这个不等式就是著名的巴拿赫不动点定理（Banach Fixed Point Theorem），又名压缩映射定理。其中，不动点指的是$x_\infty$，压缩指的是函数$g$，映射指的是距离度量方式$\Vert \cdot \Vert$。把之前省略的下标再放回来，$x_\infty$就是逆向的目标$x_t^\infty=x_t$。</p><h2 id="谱范数-Spectral-Norm"><a href="#谱范数-Spectral-Norm" class="headerlink" title="谱范数 Spectral Norm"></a>谱范数 Spectral Norm</h2><p>那么，既然知道了需要满足所有残差模块$g$的利普希茨常数$\mathrm{Lip}(g) &lt; 1$，如何实现这个约束呢？首先，我们知道ReLU、Sigmoid等常用的激活函数已经满足了这个约束。那么，实际上就是要给神经网络的权重$W$的利普希茨常数$\mathrm{Lip}(W)$进行约束，可以将式子（13）改写为：</p><p>$$<br>\Vert W(x_1 - x_2) \Vert \leq \mathrm{Lip}(W)\Vert x_1 - x_2 \Vert<br>$$</p><p>我们可以尝试把$W$从范数中提取出来。神经网络的权重通常是一个矩阵$W \in \mathbb{R}^{\mathrm{D}\times \mathrm{D’}}$，而求矩阵的范数一般采用谱范数（Spectral Norm）$\Vert W \Vert_2$：</p><p>$$<br>\begin{split}<br>&amp; \Vert W(x_1 - x_2) \Vert \leq \Vert W \Vert_2 \cdot \Vert x_1 - x_2 \Vert, \mathrm{Lip}(W) &lt; 1 \\<br>&amp; \Rightarrow \Vert W \Vert_2 \leq 1<br>\end{split}<br>$$</p><p>参考苏剑林的推导过程<sup class="refplus-num"><a href="#ref-Kexue-SN">[13]</a></sup>，谱范数$\Vert W \Vert_2$的定义是$W^\top W$的最大特征根的平方根，其中$x$为单位向量：</p><p>$$<br>\Vert W\Vert_2^2 = \max_{x\neq 0}\frac{x^{\top}W^{\top} Wx}{x^{\top} x} = \max_{\Vert x\Vert=1}x^{\top}W^{\top} Wx<br>$$</p><p>将$W^\top W$对角化为$\text{diag}(\lambda_1,\dots,\lambda_n)$，也即$W^{\top} W=U^{\top}\text{diag}(\lambda_1,\dots,\lambda_n)U$，$U$是正交矩阵，任意$\lambda$非负：</p><p>$$<br>\begin{aligned}<br>\Vert W\Vert_2^2 =&amp; \max_{\Vert x\Vert=1}x^{\top}\text{diag}(\lambda_1,\dots,\lambda_n) x \\<br>=&amp; \max_{\Vert x\Vert=1} \lambda_1 x_1^2 + \dots + \lambda_n x_n^2\\<br>\leq &amp; \max\{\lambda_1,\dots,\lambda_n\} (x_1^2 + \dots + x_n^2) \\<br>=&amp;\max\{\lambda_1,\dots,\lambda_n\}<br>\end{aligned}<br>$$</p><p>在求得谱范数$\Vert W\Vert_2$后，只需要对所有的残差模块权重用$\Vert W\Vert_2$归一化，然后再乘上$c \in (0, 1)$即可：</p><p>$$<br>\begin{equation}<br>W^* = c \cdot \frac{W}{\Vert W\Vert_2}<br>\end{equation}<br>$$</p><h2 id="利普希茨角度的可逆性-Invertibility-by-Lipschitz"><a href="#利普希茨角度的可逆性-Invertibility-by-Lipschitz" class="headerlink" title="利普希茨角度的可逆性 Invertibility by Lipschitz"></a>利普希茨角度的可逆性 Invertibility by Lipschitz</h2><p>对于Neural ODE，由于常微分方程$\frac{dx}{dt}=f_\theta(x_t)$本身就是神经网络，而神经网络的权重、输入数据一般是实数域$\mathbb{R}$的，所以输出$\frac{dx}{dt} &lt; \infty$，从而能够保证对于一个Neural ODE，存在一个$\mathrm{k_0}$使得利普希茨常数$\mathrm{Lip(NODE)}&lt;\mathrm{k_0}$：</p><p>$$<br>\mathrm{Lip(NODE)} = \sup \frac{dx}{dt} = \sup_{x_t} f_\theta(x_t) &lt; \mathrm{k_0}<br>$$</p><p>对于ResNet，虽然同样有神经网络输出$g_\theta(x) &lt; \infty$，但转化为ODE形式后却无法保证$\frac{dx}{dt}$符合上述性质，因为其极限形式的分母$h\rightarrow 0$，则$\frac{1}{h} \rightarrow \infty$。虽然令$hf_\theta(x_t) = g_\theta(x_t)$可以满足，但是$f_\theta(x_t)$并不是神经网络，无法保证$f_\theta(x) &lt; \infty$：</p><p>$$<br>\begin{split}<br>\frac{dx}{dt} &amp; = \lim_{h\rightarrow 0} \frac{x_{t+h}-x_t}{h} \\<br>&amp; = \lim_{h\rightarrow 0} \frac{g_\theta(x_t)}{h} = f_\theta(x_t)<br>\end{split}<br>$$</p><h2 id="神经流模型的多种形式-Variants-of-Neural-Flows"><a href="#神经流模型的多种形式-Variants-of-Neural-Flows" class="headerlink" title="神经流模型的多种形式 Variants of Neural Flows"></a>神经流模型的多种形式 Variants of Neural Flows</h2><p>最终，普通的神经网络只需满足如下两个条件，即可认为是神经流模型。其中，对于神经网络的利普希茨连续性约束，可以用式子（15）对权重的谱范数归一化来实现：</p><p>$$<br>\begin{equation}<br>F(0, x_0) = x_0, ~~~ \mathrm{Lip}(F) &lt; 1<br>\end{equation}<br>$$</p><p>在Neural Flows原文<sup class="refplus-num"><a href="#ref-Neural-Flows">[8]</a></sup>中，提出了三种不同的流模型。首先是ResNet流模型，既然讨论了这么多可逆残差网络的内容，很自然地想到直接用上它。其中，$\phi(t)$是用来满足$F(0, x_0) = x_0$这个条件的，需要$\phi(0) = 0$。而且$\vert \phi(t) \vert &lt; 1$，因为$\phi(t)$作为系数，会影响整体的$\mathrm{Lip}(F)$，如果$\vert \phi(t) \vert \geq 1$，整体的$\mathrm{Lip}(F)$有可能也大于$\geq 1$。$\mathrm{Lip}(g) &lt; 1$：</p><p>$$<br>\begin{equation}<br>F(t, x) = x + \phi(t) \cdot g(t, x)<br>\end{equation}<br>$$</p><p>类似地，为了将带有循环神经网络的GRU-ODE转换为GRU流模型，作者证明了其中的系数需要满足特定取值，才能够使得模型总体的$\mathrm{Lip}(F) &lt; 1$，证明过程较长可以阅读原文。对偶流模型主要是为了得到逆向过程的解析形式，将输入的特征维度划分为了互不相交的两组维度$A\cup B$：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>F(t, x) &amp; = x_A\exp\big(u(t, x_B)\phi_u(t)\big) \\<br>&amp; + v(t, x_B)\phi_v(t) \\<br>\end{split}<br>\end{equation}<br>$$</p><p>可以看到，实际上是用B组的维度，分别送入由神经网络$u$和$v$组成的式子（17）中的ResNet流模型，作为A组特征的动态权重和偏置，同时这个结构本身是可逆的<sup class="refplus-num"><a href="#ref-NVP">[14]</a></sup>。回顾<a href="https://lmy98129.github.io/2024/06/03/Notes-About-Neural-CDE-and-Beyond">之前Neural CDE笔记</a>中的CDE动态权重推导结果，基本上保持一致。当然，这是积分层面的动态权重，而不是微分方程层面的。</p><p>最终，Neural Flows作为Neural ODE的替代品，用式子（16）中2个极其简单的约束，只需关注起点$x_0$和时间$\mathrm{T}$（注意可以随意指定时间，同样能够输出中间结果），无需复杂的数值求解器，即可达到与Neural ODE相同的性质。而这背后，是前述庞大的数学理论体系（利普希茨连续性、巴拿赫不动点定理、谱范数）作为坚实的支撑，同时也打开了一扇解读黑盒模型的全新大门，值得进一步地深入学习和应用。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-DeterNF" data-num="1">[1]  Lorenz E N. Deterministic nonperiodic flow[J]. Journal of atmospheric sciences, 1963, 20(2): 130-141.</li><li id="ref-NCSN" data-num="2">[2]  Song Y, Ermon S. Generative modeling by estimating gradients of the data distribution[J]. Advances in neural information processing systems, 2019, 32.</li><li id="ref-DDPM" data-num="3">[3]  Ho J, Jain A, Abbeel P. Denoising diffusion probabilistic models[J]. Advances in neural information processing systems, 2020, 33: 6840-6851.</li><li id="ref-DiffuNF" data-num="4">[4]  Zhang Q, Chen Y. Diffusion normalizing flow[J]. Advances in Neural Information Processing Systems, 2021, 34: 16280-16291.</li><li id="ref-SDE-ODE" data-num="5">[5]  Song Y, Sohl-Dickstein J, Kingma D P, et al. Score-based generative modeling through stochastic differential equations[J]. 9th International Conference on Learning Representations, ICLR 2021.</li><li id="ref-DDIM" data-num="6">[6]  Song J, Meng C, Ermon S. Denoising Diffusion Implicit Models [J]. 9th International Conference on Learning Representations, ICLR 2021.</li><li id="ref-Neural-ODE" data-num="7">[7]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-Neural-Flows" data-num="8">[8]  Biloš M, Sommer J, Rangapuram S S, et al. Neural flows: Efficient alternative to neural ODEs[J]. Advances in neural information processing systems, 2021, 34: 21325-21337.</li><li id="ref-IRN" data-num="9">[9]  Behrmann J, Grathwohl W, Chen R T Q, et al. Invertible residual networks[C]//International conference on machine learning. PMLR, 2019: 573-582.</li><li id="ref-INN" data-num="10">[10]  Ardizzone L, Kruse J, Wirkert S, et al. Analyzing inverse problems with invertible neural networks[J]. 7th International Conference on Learning Representations, ICLR 2019.</li><li id="ref-Kexue-IRN" data-num="11">[11]  苏剑林. 细水长flow之可逆ResNet：极致的暴力美学. https://kexue.fm/archives/6482</li><li id="ref-Bilibili-Lip" data-num="12">[12]  ReadPaper论文阅读 (IDEA研究院). Lipschitz连续及其常量的定义讲解【深度学习中的数学ep5】. https://www.bilibili.com/video/BV1B64y157DC</li><li id="ref-Kexue-SN" data-num="13">[13]  苏剑林. 深度学习中的Lipschitz约束：泛化与生成模型. https://kexue.fm/archives/6051</li><li id="ref-NVP" data-num="14">[14]  Dinh L, Sohl-Dickstein J, Bengio S. Density estimation using real nvp[J]. 5th International Conference on Learning Representations, ICLR 2017.</li></ul>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Neural CDE and Beyond</title>
      <link href="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/"/>
      <url>/2024/06/03/Notes-About-Neural-CDE-and-Beyond/</url>
      
        <content type="html"><![CDATA[<blockquote><p>We are not the stuff that abides,<br>but patterns that perpetuate themselves.<br>by Norbert Wiener</p></blockquote><p>本文是关于神经受控微分方程Neural Controlled Differential Equations的学习笔记<br>主要是Neural CDE对于Neural ODE的反思与改进，以及其与符号回归Symbolic Regression的内在联系。</p><span id="more"></span><h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>维纳的这句名言，中文意思是：“我们并非静止不变的物品，而是能够自我延续的模式”。</p><p>训练结束后，推理阶段的神经网络模型一般会固定其可学习参数$\theta$，这些参数代表了输入数据、中间特征对于特征计算、最终输出的贡献度。因此，我们将其称为权重$W$，当然，还有调整数值总体偏移的偏置$b$。</p><p>然而，在复杂多变的实际应用场景中，对于静止不变的神经网络，其泛化性总是有限的。总有那么一个时刻，推理数据与训练数据不再是独立同分布的（i.i.d., independent and identically distributed）。我们需要模型能够根据当下的工况，按照某种模式，调整输入数据的贡献度，从而实现模型的自我延续。</p><p>根据特定模式进行有序的反馈调整，能够让自我的稳态保持得更加长久，正是控制理论的核心哲学之一。这便是我引用控制论创始人维纳名言的原因，这也是为什么我要单独讨论神经受控微分方程Neural CDE的原因。这不只是一个简单的Neural ODE分支，而是一套简洁有效的方法论。</p><h2 id="初值问题-Initial-Value-Problem"><a href="#初值问题-Initial-Value-Problem" class="headerlink" title="初值问题 Initial Value Problem"></a>初值问题 Initial Value Problem</h2><p>回顾<a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2">之前的笔记</a>，无论是显式的状态$y$、还是隐式的特征$z$，常微分方程都意味着自变量只能有一个，那就是时间$t$，而因变量$y$则随着时间$t$变化：</p><p>$$<br>\begin{equation}<br>\frac{dy}{dt} = f(y_t) ~~\Leftrightarrow~~ dy = f(y_t)dt<br>\end{equation}<br>$$</p><p>为了得到某个时刻$y_\mathrm{T}$的值，需要对常微分方程进行积分。若方程已知，则有且仅有的额外输入是初值$y_0$：</p><p>$$<br>\begin{equation}<br>y_\mathrm{T} = y_0 + \int_0^\mathrm{T} dy = y_0 + \int_0^\mathrm{T} f(y_t)dt<br>\end{equation}<br>$$</p><p>对于Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[1]</a></sup>，为了得到隐式特征$z$的初值$z_0$，需要将已知的时间序列数据$\mathrm{X}$输入到特定的编码器（这里是ODE-RNN）。给定固定的Neural ODE解码器，得到的$z_0$作为唯一的输入，直接决定了之后所有输出的隐式特征$z_\mathrm{T}$。虽然$z_0$也可以通过采样$\mathcal{N}(\mu, \sigma)$多次得到，但是$\mu, \sigma$确定了之后，同样也能确定后续$z_\mathrm{T}$的平均值范围作为输出。</p><p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/../../../../2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/latent-ode.png" alt="latent-ode"></p><p>这便是初值问题（IVP，Initial Value Problem）：一旦初值决定，结果也就决定了。那么，在时间层面上静止不变的初值输入$z_0$、以及神经网络参数$\theta$，如何应对实时变化、长度$\mathrm{T}$不断增长的时间序列数据$\mathrm{X}$呢？一个最简单的方式，就是当$\mathrm{X}$变长到$\mathrm{T}+\Delta\mathrm{T}$时，重新输入到编码器得到$z_0$、积分得到隐式特征$z_\mathrm{T}$、乃至将$z_\mathrm{T}$映射到显式的预测结果上。</p><p>考虑到除了用于解码预测的Neural ODE是一个神经网络，编码器本身也是一个神经网络，为了一个微小的长度增长$\Delta\mathrm{T}$，反复跑完整个pipeline的计算代价十分高昂。显然有一种最简单的方式，将当前时刻$t$的数据$\mathrm{X}_t$也纳入到Neural ODE的神经网络输入中，从而无需对整个$\mathrm{X}$预先编码（对$\mathrm{X}_0$编码得到$z_0$）：</p><p>$$<br>\begin{equation}<br>z_\mathrm{T} = z_0 + \int_0^\mathrm{T} f_\theta(z_t)dt = z_0 + \int_0^\mathrm{T} h_\theta(z_t, \mathrm{X}_t)dt<br>\end{equation}<br>$$</p><p>显然，这种形式等价于直接使用编码器ODE-RNN，也即当存在$\mathrm{X}_t$的时候，$z_t$与$\mathrm{X}_t$同时输入神经网络$h_\theta$，得到$z_{t+\Delta t}$的更新，反之则和经典Neural ODE一样只有$z_t$作为输入。若对于连续型时间序列，则任意时间$t$都有$\mathrm{X}_t$作为输入，则等价于纯Neural ODE模型。对于离散型时间序列进行插值（例如，B-样条插值），同样能够实现这个效果。</p><h2 id="受控微分方程-Controlled-Differential-Equations"><a href="#受控微分方程-Controlled-Differential-Equations" class="headerlink" title="受控微分方程 Controlled Differential Equations"></a>受控微分方程 Controlled Differential Equations</h2><p>与式子（3）不同的是，Neural CDE论文<sup class="refplus-num"><a href="#ref-Neural-CDE">[2]</a></sup>引入了受控微分方程（CDE，Controlled Differential Equations）的概念，也就是直接将Neural ODE的神经网络$f’_\theta(z_t)$的输出，作为控制变量、也就是时间序列数据$\mathrm{X}_t$的“系数”：</p><p>$$<br>\begin{equation}<br>dz_t = f’_\theta(z_t)d\mathrm{X}_t<br>\end{equation}<br>$$</p><p>需要注意的是，由于$dz_t$应当与$z_t$的形状相同，而$\mathrm{X}_t \in \mathbb{R}^\mathrm{D’}$可能与$z_t \in \mathbb{R}^\mathrm{D}$形状不同，也即隐式特征的维度与显式时间序列数据的维度不同。因此，神经网络$f’_\theta(z_t)$的输出形状不再是与$z_t$一样的向量，而是形状为$\mathrm{D} \times\mathrm{D’}$的线性映射矩阵。</p><p>$$<br>\begin{equation}<br>z_\mathrm{T} = z_0 + \int_0^\mathrm{T} dz_t = z_0 + \int_0^\mathrm{T} f’_\theta(z_t) d\mathrm{X}_t<br>\end{equation}<br>$$</p><p>其中，$d\mathrm{X}_t$为时间序列数据$\mathrm{X}$的瞬时变化量（不是导数）；则$\frac{d\mathrm{X}_t}{dt}$为时间序列数据的瞬时变化率，也就是一阶导数。那么显然，可以通过$\frac{d\mathrm{X}_t}{dt}$，使得式子（5）的积分也能够用以$t$为变量的常微分方程$g_{\theta, X}(z_t)$表示：</p><p>$$<br>\begin{equation}<br>\int_0^\mathrm{T} f’_\theta(z_t)\frac{d\mathrm{X}_t}{dt}dt = \int_0^\mathrm{T} g_{\theta, X}(z_t)dt<br>\end{equation}<br>$$</p><p>Neural CDE证明了式子（5）能够表示任意式子（3），但反过来存在式子（3）无法表示的式子（5），证明过程非常复杂，但是B站上的视频提供了一个形象的例子。定义$y_t$（论文及图片中为$y_s$）为一维的显式状态，Neural CDE的神经网络$f’_\theta(y_t)$输出则从矩阵变成了形状为$\mathrm{D} \times 1$的向量。如果给时间序列数据加一个常量维度1，假设$f’_\theta(y_t)$学到了需要一直输出one-hot的向量，则该积分结果可以表示为初值加上时间序列长度：</p><p>$$<br>\begin{equation}<br>y_\mathrm{T} = y_0 + \int_0^\mathrm{T} dt = y_0 + \mathrm{T}<br>\end{equation}<br>$$</p><p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/Bilibili-NCDE.png" alt="Bilibili-NCDE"></p><center>通过新增常量维度1，Neural CDE能够显式学习到时间序列的长度，<a href="https://www.bilibili.com/video/BV1F44y1X7o6?t=461.8">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-NDEF">[3]</a></sup></center><p><br></p><p>反之，如果$f’_\theta(y_t)$学到的不是一直输出one-hot向量，则是对输入数据——也就是常量维度1、时间序列数据维度$\frac{d\mathrm{X}_t}{dt}$——的加权权重，随着输入$y_t$的变化而变化的。其中常量维度1乘上对应权重向量后，可以看做偏置，即:</p><p>$$<br>\begin{equation}<br>\frac{dy}{dt} = f’_\theta(z_t)[1, \frac{d\mathrm{X}_t}{dt}]^\top = W_t^\top \frac{d\mathrm{X}_t}{dt} + b_t<br>\end{equation}<br>$$</p><p>但是，在推理过程中，式子（3）Neural ODE的输入层参数$\{W_1, b_1\} \in \theta$是固定不变的，不随着输入$y_t$的变化而变化，这等价于在Neural CDE中，$f’_\theta(y_t)$输出的$\{W_t, b_t\}$一直是定值$\{W_1, b_1\} $。因此，Neural CDE具有更强大的表达能力。</p><h2 id="反馈控制参数-Feedback-Controlled-Parameters"><a href="#反馈控制参数-Feedback-Controlled-Parameters" class="headerlink" title="反馈控制参数 Feedback-Controlled Parameters"></a>反馈控制参数 Feedback-Controlled Parameters</h2><p>然而，正是这个形象的例子，启发了笔者对Neural CDE的进一步思考：真的只有时间序列数据$\mathrm{X}_t$是“控制变量”吗？</p><p>我们似乎忽略了一个事实：什么能动态改变作用在$\mathrm{X}_t$上的权重$\{W_t, b_t\}$呢？是式子（5）的神经网络$f’_\theta(y_t)$。在式子（3）的Neural ODE中，上一个时刻的积分结果$y_t$单纯只是输入，无法改变作用在输入上的模型参数$\{W_1, b_1\}$。但是在Neural CDE中，$y_t$能够通过$f’_\theta(y_t)$改变神经网络的输出，也正是作用在输入上的参数$\{W_t, b_t\}$。</p><p>而这个$y_t$，正是由再上一个时刻$t-1$的积分结果$y_{t-1}$得到的$\{W_{t-1}, b_{t-1}\}$、以及输入的时间序列数据$\mathrm{X}_{t-1}$共同作用得到的。这是一个不断通过历史结果$y_t$的实时反馈，控制、调整下一个时刻作用在输入$\mathrm{X}_t$的权重，进行“闭环控制”的过程。这是自动化控制中最基本的理论模型。反过来，Neural ODE虽然也输入$y_t$，但无法控制作用在输入$\mathrm{X}_t$的权重。</p><p><img src="https://www.elprocus.com/wp-content/uploads/Closed-Loop-Control-System-Block-Diagram.jpg" alt="closeloop"></p><center>闭环控制示意图，将$f’_\theta(y_t)$看做“Feedback Elements”，通过乘号$\otimes$作用在输入“Input”的时间序列数据$\mathrm{X}_t$上<br>图片来自<a href="https://www.elprocus.com/what-is-a-closed-loop-control-system-its-working/">Elprocus.com</a></center><p><br></p><p>如上图所示，甚至在闭环控制模型中，反馈调整的方式就是通过对输入乘以权重（乘号$\otimes$）实现的；生成这一权重的输入，也正是“Output”历史结果$y_t$。因此，笔者个人认为，Neural CDE<sup class="refplus-num"><a href="#ref-Neural-ODE">[1]</a></sup>原文第二页底部，对于受控微分方程“Controlled Differential Equations”的注解“Not to be confused with the similarly-named but separate field of control theory”其实并不准确，这并不仅仅是名字像，而是在内在方法论上的共通，简洁而有效。</p><h2 id="符号回归-Symbolic-Regression"><a href="#符号回归-Symbolic-Regression" class="headerlink" title="符号回归 Symbolic Regression"></a>符号回归 Symbolic Regression</h2><p>显然，式子（8）中的反馈控制参数$\{W_t, b_t\}$和输入$\mathrm{X}_t$的关系是一个线性多项式，既没有任何的非线性项、也没有函数的嵌套关系。所以，Neural CDE描述复杂现实场景的能力其实仍然有限。当然，神经网络$f’_\theta(y_t)$本身是一个非线性函数，应当能够间接地学习到每个时刻如何精确地调整$\{W_t, b_t\}$，但单纯调整线性权重明显是不够的。</p><p>那么，怎样能学习到更高阶的函数关系呢？符号回归（Symbolic Regression）显然是一个值得考虑的选项，顺带还有一个诱人的赠品，就是拟合到的模型本身就是一个可解释的、显式的函数表达式，而不是神经网络参数这样的黑箱。</p><p>这里介绍两个比较热门的符号回归流派：基于预定义函数库的SINDy<sup class="refplus-num"><a href="#ref-SINDy">[4]</a></sup>（Sparse Identification of Nonlinear Dynamical Systems）、以及近期提出并大火的基于可学习激活函数KAN<sup class="refplus-num"><a href="#ref-KAN">[5]</a></sup>（Kolmogorov-Arnold Networks）。</p><p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/SINDy.png" alt="SINDy"></p><center>SINDy方法示意图，$\dot{\mathbf{X}}$为拟合目标真值，$\mathbf{\Theta}(\mathbf{X})$为输入数据代入候选函数，$\Xi$表示稀疏向量。图片来自论文原文<sup class="refplus-num"><a href="#ref-SINDy">[4]</a></sup></center><p><br></p><p>SINDy需要预先定义一系列候选函数算子$\Theta$，一般包括多次项组合（例如，$x, y, x^2, y^2, xy, x^2y, xy^2 \cdots$）、三角函数、对数函数、自然指数函数等常见函数。将输入数据的各个维度代入这些函数，得到一系列函数值。目标是找到一个稀疏的向量$\Xi$，用尽可能少的函数，正确拟合出对应输入的真值。</p><p>对于非深度学习的原始版本SINDy，拟合是通过多元回归等数值方法进行的，需要约束$\Xi$的稀疏性。对于基于深度学习的SINDy，可以将$\Xi$作为神经网络参数，进行梯度下降优化，例如结合Neural ODE得到Neural SINDy<sup class="refplus-num"><a href="#ref-Neural-SINDy">[6]</a></sup>、多层嵌套的Nested-SINDy等<sup class="refplus-num"><a href="#ref-Nested-SINDy">[7]</a></sup>。学到$\mathbf{\Theta}(\mathbf{X})\Xi$即为多项式相加表达式，无法表示、或者只能表示预设的<sup class="refplus-num"><a href="#ref-Nested-SINDy">[7]</a></sup>函数嵌套高阶关系。</p><p><img src="/2024/06/03/Notes-About-Neural-CDE-and-Beyond/KAN.png" alt="KAN"></p><center>KAN方法示意图，通过步骤3~6，将学习到的激活函数逐个设定为已知函数，解析出显式、可嵌套的表达式<br>图片来自论文原文<sup class="refplus-num"><a href="#ref-KAN">[5]</a></sup></center><p><br></p><p>不同于可学习连接权重的传统神经网络，KAN将所有连接权重设置为1，同时将之前固定不可学习的激活函数转变为可学习的。学习目标是通过学习激活函数的B-样条曲线，得到若干个任意形状激活函数的嵌套组合，同时逐步删去无激活函数的权重，从而回归出对应输入的真值。同时，在学习结束后通过对曲线的特定解析方法，可以得到这些曲线组合后的显式表达式，这种解析方法支持生成函数的嵌套关系，具有更高的可解释性和实用价值。</p><p>值得注意的是，这些符号回归方法的表达式参数，在训练结束之后仍然是固定的、与输入数据无关的。近期工作DeepOKAN<sup class="refplus-num"><a href="#ref-DeepOKAN">[8]</a></sup>从DeepONet<sup class="refplus-num"><a href="#ref-DeepONet">[9]</a></sup>的角度实现了这个思路。所以，这个方向上还有更多的可能性，等待着大家的不断探索。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Neural-ODE" data-num="1">[1]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-Neural-CDE" data-num="2">[2]  Kidger P, Morrill J, Foster J, et al. Neural controlled differential equations for irregular time series[J]. Advances in Neural Information Processing Systems, 2020, 33: 6696-6707.</li><li id="ref-Bilibili-NDEF" data-num="3">[3]  yyxzhj. Neural ODE, CDE... 神经微分方程大家族. https://www.bilibili.com/video/BV1F44y1X7o6</li><li id="ref-SINDy" data-num="4">[4]  Brunton S L, Proctor J L, Kutz J N. Discovering governing equations from data by sparse identification of nonlinear dynamical systems[J]. Proceedings of the national academy of sciences, 2016, 113(15): 3932-3937.</li><li id="ref-KAN" data-num="5">[5]  Liu Z, Wang Y, Vaidya S, et al. Kan: Kolmogorov-arnold networks[J]. arXiv preprint arXiv:2404.19756, 2024.</li><li id="ref-Neural-SINDy" data-num="6">[6]  Lee K, Trask N, Stinis P. Structure-preserving sparse identification of nonlinear dynamics for data-driven modeling[C]//Mathematical and Scientific Machine Learning. PMLR, 2022: 65-80.</li><li id="ref-Nested-SINDy" data-num="7">[7]  Fiorini C, Flint C, Fostier L, et al. Generalizing the SINDy approach with nested neural networks[J]. arXiv preprint arXiv:2404.15742, 2024.</li><li id="ref-DeepOKAN" data-num="8">[8]  Abueidda D W, Pantidis P, Mobasher M E. DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems[J]. arXiv preprint arXiv:2405.19143, 2024.</li><li id="ref-DeepONet" data-num="9">[9]  Lu L, Jin P, Pang G, et al. Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators[J]. Nature machine intelligence, 2021, 3(3): 218-229.</li></ul>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Operator Learning</title>
      <link href="/2024/01/18/Notes-About-Operator-Learning/"/>
      <url>/2024/01/18/Notes-About-Operator-Learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p>What I cannot create, I do not understand.<br>by Richard P. Feynman</p></blockquote><p>本文是关于算子学习Operator Learning的个人笔记<br>主要是物理信息神经网络PINN、深度算子网络DeepONet的基础知识，以及逆问题求解方法。</p><span id="more"></span><h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>费曼的这句名言，中文意思是“凡是我无法创造的事物，我就无法理解它”。</p><p>这就是我写这些笔记的初衷，如果我不知道这些方法是如何创造的，就无法真正意义上地理解它们。所以，深究方法本身的细节和全貌是不够的，要看它是基于什么既有方法，它的新设计解决了什么问题。虽然，我不可能彻底达到方法原作者的理解程度，总归是比眼里完全只有黑盒，更加逼近这个极限。</p><p>另外，这些方法的作者，在研究设计这些全新方法时，大多也经历了类似的过程。无数的方法都是站在巨人的肩膀上，后来者虽然不用重复一遍巨人走过的路，但是仍然要理解巨人创造的过程，从而最终自己实现全新的创造。这就是反过来的说法：“凡是我无法理解的事物，我就无法在它的基础上创造”。</p><p>所以这篇笔记写作讲算子学习，读作讲Neural ODE以外的、另一条建模微分方程（ODE和PDE）的技术分支。当然，也不一定真的要从头读到尾，毕竟很多是众所周知的知识。因为下面各种过程不会涉及很深的数学理论，可以根据每章首尾的前后衔接，按需跳读。</p><h2 id="物理信息神经网络-Physics-Informed-Neural-Network"><a href="#物理信息神经网络-Physics-Informed-Neural-Network" class="headerlink" title="物理信息神经网络 Physics-Informed Neural Network"></a>物理信息神经网络 Physics-Informed Neural Network</h2><p><a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2">之前的笔记</a>提到过，常微分方程（Ordinary Differential Equation，ODE）是自变量只有一个的微分方程，一般表示的是时间。然而，尤其是在物理领域，自变量往往是多个的（例如一个2D的场随时间的变化，包括$xy$坐标和时间$t$），因此需要引入偏微分方程。例如，描述热传导的傅里叶方程（Fourier’s Equation）的1D、2D形式，其中$u$是一个关于坐标和时间的未知函数，表示的是热量随时间在空间中的传播：</p><p>$$<br>\begin{equation}<br>\frac{\partial u}{\partial t} = \alpha\frac{\partial^2 u}{\partial x^2}, ~~~~<br>\frac{\partial u}{\partial t} = \alpha( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2})<br>\end{equation}<br>$$</p><p>上述方程可以理解为，$u$代表的热量随时间$t$的微分变化，是由$u$在空间坐标上的二阶微分、也就是热量在局部相邻位置的变化方向（一阶微分）的变化大小（二阶微分）引起的。对于此类多个自变量的偏微分方程，之前的Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[1]</a></sup>就无法建模了。而且，对于一些复杂的物理过程，有时候<span style="text-decoration: underline;"><strong>很难写出关于未知函数$u$的具体表达式，只有形如式子（1）的笼统约束</strong></span>。那么，和Neural ODE一样，我们可以将$u$用一个神经网络来表达。</p><p><img src="/2024/01/18/Notes-About-Operator-Learning/PINN.pbm" alt="PINN"></p><center>PINN示意图。$u$是一个关于坐标$x$和时间$t$的函数，用神经网络来代替这个函数<br>其中$w$和$b$为神经网络的权重、偏置参数。神经网络的输出$u$就代表了输入$(x, t)^\top$后的函数值</center><p><br></p><p>因此，Maziar Raissi等人在2017年提出了物理信息神经网络<sup class="refplus-num"><a href="#ref-PINN-PartI">[2]</a></sup><sup class="refplus-num"><a href="#ref-PINN-PartII">[3]</a></sup>（Physics-Informed Neural Network，PINN），该工作最终于2019年发表在计算物理学顶刊Journal of Computational physics<sup class="refplus-num"><a href="#ref-PINN">[4]</a></sup>。如上图所示，以式子（1）中的1D傅里叶方程为例，一个神经网络$\mathrm{NN}$接受输入的自变量为坐标$x$和时间$t$，它的输出即为$u$，参数为权重$w$（weight）、偏置$b$（bias）。因此，可以看做这个神经网络代替了$u$的具体表达式：</p><p>$$<br>u(x, t)=\mathrm{NN}(x, t | w, b)<br>$$</p><p>如上图所示，对于PINN的训练，其损失函数可以分为以下两个部分：</p><ul><li><p>第一部分是对$u$这个函数的函数值本身进行约束。例如在$t=0$时刻、$x=x_0$上的$u$值，如果已知，就可以当作初始条件（Initial Condition，IC）的真值，剩下的时刻和位置上，如果也有的已知$u$值，就可以当作边界条件（Boundary Condition，BC）的真值，将它们与PINN预测出来的$u$计算差值。</p></li><li><p>第二部分是对$u$这个函数求各个偏微分方程的值进行约束。同样地，在某个时刻和位置上，如果已知有形如式子（1）、包含$\frac{\partial u}{\partial t}$、$\frac{\partial u}{\partial x}$、$\frac{\partial^2 u}{\partial x^2}$等项的偏微分方程，那么对应计算PINN输出的$u$，相对于输入$x$和$t$的偏导，代入方程的右边得到图中的$g$，然后和左边相减，得到一个差值$R$。因为pytorch等深度学习框架需要计算梯度，因此有<code>torch.autograd</code>等自动微分API可供调用，<span style="text-decoration: underline;"><strong>这是整个PINN最巧妙的地方，利用神经网络的梯度微分学习机制</strong></span>。</p></li></ul><p>最终，将上述差值送入均方误差函数（Mean Square Error，MSE）后，相加得到最终的损失函数值，当其小于$\epsilon$时，可以认为神经网络的拟合趋于收敛，停止训练。值得注意的是，Neural ODE是需要拟合对ODE计算积分后的真实值，因此使用的是计算对应积分值的$\mathrm{ODESolver(\cdot)}$，<a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2">详见之前的笔记</a>；而PINN直接计算输出与$u$真实值的差距，同时也需要拟合如式子（1）的偏微分方程，因此使用的是计算对应偏导值的<code>torch.autograd</code>等自动微分API。</p><p>如果想要把Neural ODE的任务套用进PINN，则将输入改为只有一个自变量$t$，由于$u=\mathrm{NN}(t)= u_0 + \int \frac{du}{dt} dt$，所以无需任何ODE或PDE约束，只需要包括IC和BC等真实值条件进行约束，退化为了一个普通的神经网络。在无对应ODE或PDE约束的前提下，如果真实值过少，则会导致神经网络过拟合到这几个点上。Neural ODE至少有将神经网络的输出进行积分的关系，也就是$\frac{du}{dt} = \mathrm{NN(u, t)}$, 且$u = u_0 + \int \frac{du}{dt} dt=\mathrm{ODESolver}(\mathrm{NN}, u_0, t_0, t_N)$。</p><p>言归正传，在测试阶段，对应的PINN模型输入了$(x, t)^\top$之后，只能输出符合式子（1）等训练时指定的偏微分方程中的函数值$u$。也就是说，一旦训练停止，这个模型就无法适用于新的偏微分方程。例如，改变了初始或边界条件、改变了式子（1）本身，都意味着$u$变了，需要重新训练一个新的PINN模型。</p><h2 id="深度算子网络-Deep-Operator-Network"><a href="#深度算子网络-Deep-Operator-Network" class="headerlink" title="深度算子网络 Deep Operator Network"></a>深度算子网络 Deep Operator Network</h2><p>为了避免重新训练，肯定要想办法在训练时新增额外的输入，使得模型能够泛化到其他偏微分方程上。当然，如果能确定式子（1）本身的大致形式，只是其中的若干参数未知，则可以参见PINN原文第二部分<sup class="refplus-num"><a href="#ref-PINN-PartII">[3]</a></sup>，用神经网络拟合未知函数$u$的同时，求解待定参数，具体的方式可以见下一章节。</p><p>因此，最重要的是未知函数$u$本身的改变，我们可以将改变这个函数的额外变量输入到网络里。但是，顾名思义，<span style="text-decoration: underline;"><strong>我们无法知道这个函数的具体表达式形式，甚至连大致形式都不知道</strong></span>。因此，对于这个函数的性质，<strong>只能通过与之相关的若干数据间接了解</strong>。那么，在未知函数$u(y)$本身也要接受$y=(x, t)^\top$等输入的情况下，如何建立从这些额外的数据到未知函数$u$的映射关系呢？</p><p><strong>重新定义符号</strong>，将间接数据的观测采样点（如时间、位置点）为$\{x_0, \cdots, x_m\}$，每点的第$n$种观测值为函数$u^{(i)}(x_m)$，所有$u^{(i)} \in u$，$u$代表所有的间接数据。定义从间接数据$u$到未知函数的映射为$G$，也就是当前间接数据$u$所描述的未知函数等于$G(u)$。给定输入$y$，这个未知函数的函数值就是$G(u)(y)$。</p><p>根据上述的符号定义，我们可以发现，$G$实际上是函数到函数的映射，因为$u^{(i)}(x_m)$是关于观测点$x_m$的函数，$G(u)$是关于所有间接数据$u$的函数。这种映射被称为“算子（Operator）”。<strong>一个最直观的例子就是，常微分$\frac{d}{dt}$或偏微分$\frac{\partial}{\partial t}$等算子，可以将给定函数$f$变为另一个函数，也就是$\frac{df}{dt}$或$\frac{\partial f}{\partial t}$</strong>。</p><p>显然，我们不知道这个算子$G$到底是什么形式的，例如是不是若干个$u^{(i)}$的线性组合得到了未知函数。所以，我们也可以用神经网络来表示这个映射。因此，Chen等人<sup class="refplus-num"><a href="#ref-Uni-Approx">[5]</a></sup>在1995年证明了用神经网络作为算子，同样和普通神经网络一样，满足万能逼近定理（可以拟合任意的算子）。在此基础上，Lu等人<sup class="refplus-num"><a href="#ref-DeepONet">[6]</a></sup>在2021年的Nature子刊Nature Machine Intelligence上，发表了深度算子网络DeepONet（Deep Operator Network），提出用更深层的神经网络作为算子。</p><p><img src="/2024/01/18/Notes-About-Operator-Learning/DeepONet.png" alt="DeepONet"></p><center>DeepONet示意图。图（a）是模型输入输出：定义未知函数的间接数据函数$u$，未知函数的输入$y$，最终输出的函数值$G(u)(y)$<br>图（b）是训练数据的构成，在若干固定采样点$x_m$上的间接数据函数值$u$，对应任意输入$y$上的函数值<br>图（c）和（d）是两种DeepONet设计，每个采样点分别还是共同输入“Branch Net”</center><p><br></p><p>如上图所示，DeepONet分为两部分：一部分是输入间接数据$u$的“Branch Net”，每个采样点分别输入各自的分支网络，被称为堆叠（Stacked），反之共同输入一个网络，则为非堆叠（Unstacked）；另一部分是输入自变量$y$的“Trunk Net”，因为必然只有一条（$y$可以是一个向量，代表所有输入，例如包括了空间位置和时间$(x, t)^\top$），所以被称为主干网络。由这两个网络得到的特征$b$和$p$，分别代表$G(u)$和$y$的信息。对应下标的特征相乘求和后，最终得到$G(u)$在自变量为$y$时的函数值$G(u)(y)$。对$G(u)(y)$的约束方式可以是普通的，也可以与PINN类似（称为PI-DeepONet）。</p><h2 id="示例-Examples"><a href="#示例-Examples" class="headerlink" title="示例 Examples"></a>示例 Examples</h2><p>定义自变量输入只有时间$t$，未知函数为$s(t)$，间接数据为$u(t)$，已知两者的关系满足如下常微分方程：</p><p>$$<br>\begin{equation}<br>\frac{ds(t)}{dt} = u(t), t\in [0, 1]<br>\end{equation}<br>$$</p><p>对此进行积分可以得到：</p><p>$$<br>\begin{equation}<br>s(t) = s(0) + \int_0^t u(t’) dt’<br>\end{equation}<br>$$</p><p>那么，相应的DeepONet事实上就是在拟合式子（3）这个积分构成的算子，输入函数是$u(t)$，DeepONet输出是$g(t)$。为了不让算子只对一条间接数据时间轨迹过拟合，应当采样多条间接数据的时间轨迹函数$u^{(i)}$；同时，对应的输入自变量$y^{(i)}_j$的真值$G(u^{(i)})(y^{(i)}_j)$也应给出，且满足式子（3）的关系：</p><p>$$<br>\begin{split}<br>&amp; s(y^{(i)}_j) = G(u^{(i)})(y^{(i)}_j) \\<br>&amp; = s(0) + \int_0^{y^{(i)}_j} u^{(i)}(t) dt<br>\end{split}<br>$$</p><p>注意，$i$和$j$之间没有任何关系，有$i$个间接数据函数，每个间接数据的函数$u^{(i)}$可以通过$G$映射到一个未知函数$G(u^{(i)})$，这个未知函数上可以有$j$个任意位置的真值点$G(u^{(i)})(y^{(i)}_j)$。输入$u^{(i)}$的格式，是在该函数上采$x_0, \cdots, x_m$个固定点。因此，对于DeepONet，训练或测试数据由以下$|I| \times |J|$个三元组构成：</p><p>$$<br>\begin{split}<br>&amp; \left\{ u(x), y, G(u)(y) \right\} \\<br>&amp; = \left\{ (u^{(i)}(x_0), \cdots, u^{(i)}(x_m))^\top, y^{(i)}_j, G(u^{(i)})(y^{(i)}_j) \right\}_{i \in I, j \in J}<br>\end{split}<br>$$</p><p>由于式子（3）描述的算子十分通用，对任意的输入函数，都应当满足对应的积分关系。因此，为了充分训练DeepONet，论文原文<sup class="refplus-num"><a href="#ref-DeepONet">[6]</a></sup>采用了高斯随机场（Gaussian Random Field，GRF）或切比雪夫多项式（Chebyshev Polynomials），随机生成了若干个函数$u^{(i)}$和对应的真值$s(y^{(i)}_j) = G(u^{(i)})(y^{(i)}_j)$。训练损失函数和PINN是一样的，可以分为两部分，一部分约束输出初值$s(0)$以及其他边界条件，另一部分对输出$s(y^{(i)}_j)$，求$\frac{d}{dt}$用前述真值$G(u^{(i)})(y^{(i)}_j)$约束。</p><p><img src="/2024/01/18/Notes-About-Operator-Learning/Results.png" alt="Results"></p><center>DeepONet拟合式子（2）后，输入$u(t)$、输出$s(t)$的结果<br>可以看到$s(t)$确实是$u(t)$的积分，反之$u(t)$是$s(t)$的导数，例如$u(t)=0$时，$s(t)$曲线平缓<br>图片来自GitHub仓库<a href="https://github.com/ShuaiGuo16/PI-DeepONet/blob/main/case_study.ipynb">ShuaiGuo16/PI-DeepONet</a></center><p><br></p><p>值得注意的是，除了输入函数$u$的个数$i$外，采样点的数量个数$m$也会影响最终拟合的效果。因此，在实际问题中，应当尽可能多地采集$u^{(i)}$、且尽可能密集地采集每个$u^{(i)}$的$u^{(i)}(x_m)$，从而更好地刻画这些间接数据，生成更准确的位置函数$G(u)$。反过来，对该未知函数的自变量和函数值$(y, G(u)(y))^\top$，实际上只需要少量的采样点，作为PINN损失函数的第一部分。如果已经知道该函数$G(u)(y)$和$u$形如式子（2）的大致关系，则可以纳入到损失函数的第二部分。</p><h2 id="逆问题求解方法-Inverse-Problem-Solving"><a href="#逆问题求解方法-Inverse-Problem-Solving" class="headerlink" title="逆问题求解方法 Inverse Problem Solving"></a>逆问题求解方法 Inverse Problem Solving</h2><p>在上述的示例中可以看出，为了用ODE、PDE约束PINN、DeepONet的网络输出，显然需要已知对应的ODE、PDE的具体形式，例如式子（2）。但是，在很多复杂场景下，ODE、PDE的具体形式未知，需要反过来求解他们，因此称为逆问题（Inverse Problem）。例如，空间位置$x$或时间$t$等一个或多个自变量和网络输出$s$关联，应该是个ODE、PDE，且式子应该和间接数据的函数$u$有关，即多了一层函数$\kappa(\cdot)$，且这个函数本身有待定参数$\tilde{\theta}$。以DeepONet为例，式子（2）改写为：</p><p>$$<br>\frac{ds(t)}{dt} = \kappa(u(t) | \tilde{\theta}), t\in [0, 1]<br>$$</p><p>例如，我们大概知道$\kappa(\cdot)$是一个线性函数，则可以写作（式子（2）就相当于$\omega = 1$, $\beta = 0$）：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>&amp; \frac{ds(t)}{dt} = \omega \cdot u(t) + \beta, \\<br>&amp; t\in [0, 1], \tilde{\theta} = \{\omega, \beta\}<br>\end{split}<br>\end{equation}<br>$$</p><p>那么，PINN的损失函数第二项就可以改写为（这里函数符号用DeepONet的输出$s(y)=s(x, t)$）：</p><p>$$<br>R = \mathcal{L}(s, u, \theta, \tilde{\theta}) - \mathcal{L}(s(x, t), \theta)<br>$$</p><p>其中，第一项使用间接数据函数$u$代入式子（4）右边，计算$s(y)=G(u)(y)$真值，多了待定参数$\tilde{\theta} = \{\omega, \beta\}$，第二项用自动微分API求神经网络输出的$\frac{ds(x, t)}{dt}$。在PyTorch等现代深度学习框架中，可以直接将$\tilde{\theta}$也设置成可学习参数，与PINN、DeepONet的神经网络参数$\theta$一起进行梯度下降优化，在训练收敛后，$\{\omega, \beta\}$的值即为式子（4）的具体形式，在学习了神经网络的同时，求解出了ODE、PDE的近似形式。当然，肯定不仅限于线性函数一种，所以有较高的实用价值。</p><h2 id="结语-Conclusions"><a href="#结语-Conclusions" class="headerlink" title="结语 Conclusions"></a>结语 Conclusions</h2><p>至此，写好了这篇非常基础的算子学习笔记。实际上，算子学习并没有这么简单，更加本质的数学理论可以继续推导出更精彩的傅里叶神经算子<sup class="refplus-num"><a href="#ref-FNO">[7]</a></sup>（Fourier Neural Operator，FNO）等更强大的神经算子方法，用来求解更复杂的ODE、PDE。这里推荐阅读知乎上熊巍老师的系列专栏，尤其是<a href="https://zhuanlan.zhihu.com/p/520487599">这一篇</a>。同样地，这也是实践了最开始在前言里提出的“反过来的说法”：“凡是我无法理解的事物，我就无法在它的基础上创造”。让我们继续探索，看懂并创造更多精彩的东西。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Neural-ODE" data-num="1">[1]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-PINN-PartI" data-num="2">[2]  Raissi M, Perdikaris P, Karniadakis G E. Physics informed deep learning (part I): Data-driven solutions of nonlinear partial differential equations[J]. arXiv preprint arXiv:1711.10561, 2017.</li><li id="ref-PINN-PartII" data-num="3">[3]  Raissi M, Perdikaris P, Karniadakis G E. Physics informed deep learning (part II): Data-driven discovery of nonlinear partial differential equations[J]. arXiv preprint arXiv:1711.10566, 2017.</li><li id="ref-PINN" data-num="4">[4]  Raissi M, Perdikaris P, Karniadakis G E. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations[J]. Journal of Computational physics, 2019, 378: 686-707.</li><li id="ref-Uni-Approx" data-num="5">[5]  Chen T, Chen H. Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems[J]. IEEE transactions on neural networks, 1995, 6(4): 911-917.</li><li id="ref-DeepONet" data-num="6">[6]  Lu L, Jin P, Pang G, et al. Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators[J]. Nature machine intelligence, 2021, 3(3): 218-229.</li><li id="ref-FNO" data-num="7">[7]  Li, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., and Anandkumar A., “Fourier Neural Operator for Parametric Partial Differential Equations”[C]//International Conference on Learning Representations, 2021.</li></ul><p><br></p><blockquote><p>感谢阅读！如有意见和建议，欢迎通过首页的联系方式联系作者。<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Neural ODE and Beyond 3</title>
      <link href="/2024/01/10/Notes-About-Neural-ODE-and-Beyond-3/"/>
      <url>/2024/01/10/Notes-About-Neural-ODE-and-Beyond-3/</url>
      
        <content type="html"><![CDATA[<p>本文是学习Neural ODE过程中的第三篇个人笔记</p><p>主要是SDE的基本原理、高斯过程近似、重参数技巧和均摊分析<br>以及在状态估计中的应用，包括Kevin Course和Prasanth B. Nair在2023年Nature和NeurIPS上的论文。</p><span id="more"></span><h2 id="勘误和一些推论-Corrigendum-and-Corollaries"><a href="#勘误和一些推论-Corrigendum-and-Corollaries" class="headerlink" title="勘误和一些推论 Corrigendum and Corollaries"></a>勘误和一些推论 Corrigendum and Corollaries</h2><p>首先需要更正一下，其实Neural ODE也支持直接用中间的隐式状态表示预测结果，不需要额外的网络来解码隐状态。可以参见陈天琦团队的github仓库<sup class="refplus-num"><a href="#ref-torchdiffeq">[1]</a></sup>的<a href="https://github.com/rtqichen/torchdiffeq/blob/master/examples/ode_demo.py#L166">简单示例</a>。由于这个示例需要拟合的是下图螺旋运动轨迹方程，只有两个变量：运动点的2D坐标$x$和$y$，而且目标方程也不复杂，只有几个参数，所以直接让神经网络接受上一次输出的$(x, y)^\top$，再输出下一次的$(x, y)^\top$，不需要复杂的隐藏变量$z(t)$，也能正确拟合这个方程。</p><p><img src="https://github.com/rtqichen/torchdiffeq/blob/master/assets/ode_demo.gif?raw=true" alt="ode-demo"></p><center>Neural ODE的简单示例动画，动画的每一帧是一轮学习后的测试结果。<br>左图是这个螺旋曲线的动点在不同时刻$t$下在$x$轴和$y$的坐标变化序列，虚线是预测序列，实线是目标序列。右图是这个螺旋曲线经过所有时间后，在2D的$x-y$坐标系下运动的轨迹，虚线是预测轨迹，实线是目标轨迹。<br>图片来自torchdiffeq官方github仓库<sup class="refplus-num"><a href="#ref-torchdiffeq">[1]</a></sup></center><p><br></p><p>而且，如果目标方程确定的话，实际上就让网络拟合这一个方程就可以了，不需要任何的额外输入（除了初始状态$(x_0, y_0)^\top$），所以也就不需要像Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[2]</a></sup>或者Latent ODE<sup class="refplus-num"><a href="#ref-Latent-ODE">[3]</a></sup>原文里的RNN、ODE-RNN作为编码器（文章里面经常称为Recognition Model，应该是领域术语），生成隐状态服从的高斯分布$z(t_0) \sim \mathcal{N}(\mu, \sigma)$的均值和方差。</p><p>$$<br>\begin{equation}<br>z(t+\epsilon) = z(t) + \int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’<br>\end{equation}<br>$$</p><p>有趣的是，Neural ODE为了和ODE保持一致，像上面的式子一样，能够不断地在同一个微分函数上积分，然后与初值相加，确实是不允许输入和输出的$z$形状不一致的（容易联想到Diffusion扩散模型的基本原理和ODE有联系，这就是另一些故事了，感兴趣可以去搜相应的工作）。也就是说，不允许$z(t_0)$是一个隐式的特征，而剩下的$z(t&gt;t_0)$是显式的预测值。所以，凡是使用了隐式特征的Neural ODE，都需要一个额外的解码器，可以参见<a href="https://github.com/rtqichen/torchdiffeq/blob/master/examples/latent_ode.py#L263">这个示例代码</a>。</p><p>所以，从某种意义上来说，前面几篇笔记反复提到的“错误”也不全错，对复杂过程的建模，而且需要一个编码器生成初始状态作为条件condition，就是需要在隐式特征的状态上做积分。但是，如果解码器$\phi$是线性的且没有偏置，那么输出仍然服从和隐式状态一样的变化量关系约束。由于对任意$t$都有$y(t)=\phi(z(t))$：</p><p>$$<br>\begin{align}<br>&amp; y(t+\epsilon) = \phi(z(t+\epsilon)) \nonumber \\<br>&amp; = \phi\left(z(t) + \int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’\right) \nonumber \\<br>&amp; = \phi(z(t)) + \phi\left(\int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’\right) \nonumber \\<br>&amp; = y(t) + \Delta y|_t^{t+\epsilon} \\<br>\end{align}<br>$$</p><p>其中，最后这项$\phi(\cdot)$可以记作$\Delta y|_t^{t+\epsilon}$，也就是$\epsilon$长度时间内$y$的变化量。不妨令$\epsilon \rightarrow 0$，则$\epsilon = dt$，可以推出：</p><p>$$<br>\begin{align}<br>&amp; y(t+\epsilon) - y(t) = \Delta y|_t^{t+\epsilon} \nonumber \\<br>&amp; \Rightarrow \lim_{\epsilon \rightarrow 0} \frac{y(t+\epsilon) - y(t)}{\epsilon} = \lim_{\epsilon \rightarrow 0} \frac{\Delta y|_t^{t+\epsilon}}{\epsilon} \nonumber \\<br>&amp; \Rightarrow \frac{dy}{dt} = \lim_{\epsilon \rightarrow 0} \frac{\Delta y|_t^{t+\epsilon}}{\epsilon} \nonumber \\<br>&amp; \Rightarrow \int_t^{t+\epsilon} \frac{dy}{dt} dt = \int_t^{t+\epsilon} \lim_{\epsilon \rightarrow 0} \frac{\Delta y|_t^{t+\epsilon}}{\epsilon} dt \nonumber \\<br>&amp; \Rightarrow \int_t^{t+\epsilon} \frac{dy}{dt} dt = \Delta y|_t^{t+\epsilon} \nonumber\\<br>&amp; \Rightarrow y(t+\epsilon) = y(t) + \int_t^{t+\epsilon} \frac{dy}{dt} dt \nonumber \\<br>\end{align}<br>$$</p><p>为什么非线性的解码器不能做到这点呢？最简单的例子就是指数函数：$e^{(a+b)} = e^a \cdot e^b \neq e^a + e^b$，$a$和$b$相加后再输入的结果，不能等于$a$和$b$分别输入再相加的结果。比较遗憾的是，Neural ODE的默认解码器是<a href="https://github.com/rtqichen/torchdiffeq/blob/master/examples/latent_ode.py#L157">非线性的</a>，所以甚至不能满足式子（2）的关系。所以，将隐式特征线性解码成显式状态（例如上图例子中的$(x, y)^\top$），对应的显式状态仍然满足和式子（1）一样的积分关系。只是$\frac{dy}{dt}$无法用一个函数$f$来表示，而是像上面的第二步推导是一个极限。</p><h2 id="随机微分方程-Stochastic-Differential-Equation"><a href="#随机微分方程-Stochastic-Differential-Equation" class="headerlink" title="随机微分方程 Stochastic Differential Equation"></a>随机微分方程 Stochastic Differential Equation</h2><p>如果有观察过Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[2]</a></sup>和Latent ODE<sup class="refplus-num"><a href="#ref-Latent-ODE">[3]</a></sup>原文的实验部分，可以发现它们的拟合的时间序列往往是平滑形式的。但是，很多真实的物理过程是存在大量随机的，例如流体运动、热量传递等，底层都是分子原子的布朗运动（Brownian Motion）。只要输入相同，微分方程$f(\cdot)$输出一般没有随机性。当然，其基于VAE的思想确实能够通过对若干次初始状态$z(t_0) \sim \mathcal{N}(\mu, \sigma)$的采样，最后对预测结果算均值来一定程度上缓解这个问题，但是最终的曲线趋势仍然是平滑的。</p><p>以下推导直接参考剑桥大学2019年出版的教材“Applied Stochastic Differential Equations”<sup class="refplus-num"><a href="#ref-Applied-SDE">[5]</a></sup>（Kevin Course和Prasanth B. Nair在2023年发表的Nature正刊<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup>和NeurIPS正会<sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>论文就参考了这个教材）。</p><p>为了描述一个带有噪声过程$w(t)$的隐式状态$x(t)$变化过程，我们将常微分方程$\frac{dx(t)}{dt} = f(x(t), t)$改写为：</p><p>$$<br>\begin{equation}<br>\frac{dx(t)}{dt} = f(x(t), t) + L(x(t), t)w(t)<br>\end{equation}<br>$$</p><p>其中，随机过程$w(t)$本身与状态$x(t)$无关，一般是白噪声过程（White Noise），例如外界随机影响、内部随机运动。而$L(x(t), t)$和$f$一样，是一个与$x(t)$有关的任意函数（也可以与$x(t)$无关，带$x(t)$的项目就为0）。</p><p>那么，和<a href="https://lmy98129.github.io/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/#%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B-Ordinary-Differential-Equation">之前的笔记</a>一样，给定初值$x(t_0)$，对随机微分方程式子（3）求积分得到任意$t$时刻下的$x(t)$：</p><p>$$<br>\begin{align}<br>&amp; x(t) - x(t_0) \nonumber \\<br>&amp; = \int_{t_0}^{t} f(x(t), t) dt + \int_{t_0}^{t} L(x(t), t)w(t) dt \\<br>\end{align}<br>$$</p><p>显然，由于第一个积分是确定性的，无论是求解析解还是数值解，都是可行的方案。问题比较大的是第二个积分，因为它带有一个随机过程$w(t)$.。将这个积分写成极限形式：</p><p>$$<br>\begin{align}<br>&amp; \int_{t_0}^{t} L(x(t), t)w(t) dt \nonumber \\<br>&amp; = \lim_{n \rightarrow \infty} \sum_k L(x(t^*_k), t^*_k)w(t^*_k)(t_{k+1} - t_k), \nonumber \\<br>&amp; \mathrm{where} \nonumber \\<br>&amp; t_0 &lt; t_1 &lt; \cdots &lt; t_n = t, ~~ t^*_k \in [t_k, t_{k+1}]<br>\end{align}<br>$$</p><p>简而言之，将$[t_0, t]$划成$n \rightarrow \infty$个小区间，在任意两个区间之间计算矩形面积，宽为$t_{k+1} - t_{k}$，高为这个区间中取一个点$t^*_k$对应的函数值$L(x(t^*_k), t^*_k)w(t^*_k)$，将所有矩形面积相加即为积分。然而，由于随机过程$w(t^*_k)$并没有上下界，所以这样取一个或多个$t^*_k \in [t_k, t_{k+1}]$代表小区间矩形高度是没有意义的（形象一点就是一会儿很高、一会儿很低）。</p><p>为了保证这个代表小区间高度的被积函数是有界的，我们需要尝试将白噪声过程$w(t)$替换为有界的随机过程。布朗运动（Brownian Motion）就比较合适，$w(t)dt = d\beta(t) \sim \mathcal{N}(0, Qdt)$，$Q$为方差的扩散系数，满足以下的性质：</p><ul><li>给定时间区间$\Delta t_k = t_{k+1} - t_k$，$\Delta \beta_k = \beta(t_{k+1}) - \beta(t_k) \sim \mathcal{N}(0, Q\Delta t_k)$都是一个有界的高斯分布。</li><li>初始时间的$\beta(t_0)=0$，且在不重叠的时间段，$\Delta \beta_k$的值是相互独立的，不会被前后的差值影响。</li></ul><p>由此，我们可以代入$w(t)dt = d\beta(t)$，重写式子（5）为：</p><p>$$<br>\begin{align}<br>&amp; \int_{t_0}^{t} L(x(t), t)d\beta(t) \nonumber \\<br>&amp; = \lim_{n \rightarrow \infty} \sum_k L(x(t^*_k), t^*_k)(\beta(t_{k+1}) - \beta(t_k)), \nonumber \\<br>&amp; \mathrm{where} \nonumber \\<br>&amp; t_0 &lt; t_1 &lt; \cdots &lt; t_n = t, ~~ t^*_k \in [t_k, t_{k+1}] \nonumber \\<br>\end{align}<br>$$</p><p>但是，在区间中取不同的点$t^*_k \in [t_k, t_{k+1}]$，对于函数$L(x(t^*_k), t^*_k)$取值也有影响，最终影响积分值。因此，在这里直接采用伊藤随机积分（Itô Stochastic Integral），取$t=t_k$，保证最终的积分值是唯一的。</p><p>$$<br>\begin{align}<br>&amp; \int_{t_0}^{t} L(x(t), t)d\beta(t) \nonumber \\<br>&amp; = \lim_{n \rightarrow \infty} \sum_k L(x(t_k), t_k)(\beta(t_{k+1}) - \beta(t_k)), \nonumber \\<br>&amp; \mathrm{where} ~ t_0 &lt; t_1 &lt; \cdots &lt; t_n = t<br>\end{align}<br>$$</p><p>最终，式子（4）可以重写为：</p><p>$$<br>\begin{align}<br>&amp; x(t) - x(t_0) \nonumber \\<br>&amp; = \int_{t_0}^{t} f(x(t), t) dt + \int_{t_0}^{t} L(x(t), t)d\beta(t) \nonumber \\<br>\end{align}<br>$$</p><p>相应的随机微分方程，被称为伊藤随机微分方程（Itô SDE）：</p><p>$$<br>\begin{align}<br>&amp; \frac{dx(t)}{dt} = f(x(t), t) + L(x(t), t)\frac{d\beta(t)}{dt} \nonumber \\<br>&amp; \Rightarrow dx(t) = f(x(t), t)dt + L(x(t), t)d\beta(t)<br>\end{align}<br>$$</p><p>其中，函数$f(\cdot)$被称为漂移函数（Drift Function），因为它决定了整个变化过程的总体趋势。函数$L(\cdot)$被成为扩散函数（Diffusion Function），因为它基于布朗运动，决定了随机运动（类似于粒子扩散）的幅度。</p><p><img src="https://www.wolfram.com/mathematica/new-in-9/time-series-and-stochastic-differential-equations/HTMLImages.en/stochastic-differential-equation-for-exponential-d/O_49.png" alt="wolfram"></p><center>设置不同的扩散函数系数$\sigma$后，多次采样SDE的曲线。图片来自<a href="https://www.wolfram.com/mathematica/new-in-9/time-series-and-stochastic-differential-equations/stochastic-differential-equation-for-exponential-d.html">Mathematica官网</a></center><h2 id="高斯过程近似-Gaussian-Process-Approximation-of-SDE-Solutions"><a href="#高斯过程近似-Gaussian-Process-Approximation-of-SDE-Solutions" class="headerlink" title="高斯过程近似 Gaussian Process Approximation of SDE Solutions"></a>高斯过程近似 Gaussian Process Approximation of SDE Solutions</h2><p>在Kevin Course和Prasanth B. Nair的两篇论文<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup><sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>中，都提到了可以通过高斯过程（Gaussian Process）来近似解随机微分方程。首先，包括这两篇论文，以及剑桥大学教材<sup class="refplus-num"><a href="#ref-Applied-SDE">[5]</a></sup>，都将任务场景描述为了以下的“连续-离散”系统（Continuous-Discrete System），意思是观测值$y(k)$是离散的、不随时间连续的，而系统的状态$x(t)$是在时间上连续、且带有随机性质的。根据式子（7），引入观测值与内在状态的关系：</p><p>$$<br>\begin{align}<br>&amp; dx(t) = f(x(t), t)dt + L(x(t), t)d\beta(t),  \nonumber \\<br>&amp; y(k) = h(x(t_k)) + r_k<br>\end{align}<br>$$</p><p>其中$r_k \sim \mathcal{N}(0, R)$为观测时的底噪，$h$是状态$x(t_k)$到观测$y(k)$的映射函数。<span style="text-decoration: underline;"><strong>实际上，这就是状态估计的基本任务设置。</strong></span>这里省略一个证明，就是线性随机微分方程（漂移函数$f$是线性的）的解$x(t)$是一个高斯过程。对应线性SDE写作：</p><p>$$<br>\begin{align}<br>d\tilde{x}<br>&amp; = \tilde{f}(x(t), t)dt + L(t)d\beta(t), \nonumber \\<br>&amp; = [-A(t)\tilde{x}(t)+b(t)]dt + L(t)d\beta(t) \\<br>\end{align}<br>$$</p><p>其中，线性参数$A(t)$和$b(t)$是待求解项。为了简化书写，省略式子（9）扩散函数$L$中的$x(t)$。根据教材<sup class="refplus-num"><a href="#ref-Applied-SDE">[5]</a></sup>，这个解的边际分布（Marginal Distribution，只包含一部分变量的分布，例如2D高斯分布在其中一个1D轴上的投影是1D高斯分布）是$q(x(t))=\mathcal{N}(x(t)|m(t), P(t))$，其中$m(t)$和$P(t)$分别是$x(t)$的期望和标准差，且应当服从如下的微分方程约束（教材原文是矩阵形式的）：</p><p>$$<br>\begin{align}<br>&amp; \frac{d\mathbf{m}(t)}{dt} = -\mathbf{A}(t)\mathbf{m}(t) + \mathbf{b}(t) \\<br>&amp; \frac{d\mathbf{P}(t)}{dt} = -\mathbf{A}(t)\mathbf{P}(t) - \mathbf{P}(t)^\top\mathbf{A}(t) + \mathbf{L}(t)\mathbf{Q}\mathbf{L}(t)^\top<br>\end{align}<br>$$</p><p>由于不是重点，这里简要介绍之后的步骤。在理想情况下，边际分布$q(x(t))$应当与对应的真实分布$p(x(t)|y(t))$一致，也就是计算KL散度$\mathrm{KL}(q || p)$。使用拉格朗日乘子法（Lagrange Multipler Function），最小化KL散度公式，并使用两个拉格朗日乘子$\mathbf{\lambda}(t)$、$\mathbf{\Psi}(t)$联立约束等式（10）和（11），求解后得到待求解的线性参数$A(t)$和$b(t)$表达式：</p><p>$$<br>\begin{align}<br>&amp; \mathbf{A}(t) = -\mathbb{E}_q[f(\mathbf{x}(t), t)] + 2\mathbf{L}(t)\mathbf{Q}\mathbf{L}^\top(t)\mathbf{\Psi}(t) \nonumber \\<br>&amp; \mathbf{b}(t) = \mathbb{E}_q[f(\mathbf{x}(t), t)] + \mathbf{A}(t)\mathbf{m}(t) + \mathbf{L}(t)\mathbf{Q}\mathbf{L}^\top(t)\mathbf{\lambda}(t) \nonumber \\<br>\end{align}<br>$$</p><p>具体过程参见教材<sup class="refplus-num"><a href="#ref-Applied-SDE">[5]</a></sup>的第12.8章节。总而言之，通过假定（其实就是近似）SDE中的未知漂移函数$f(\cdot)$为线性、同时根据线性SDE的解$x(t)$是高斯过程的性质，得到其边际分布$q(x(t))$均值方差的约束式子（10）和（11），联立边际分布和真实分布的KL散度以及这些约束式子，用拉格朗日乘子法计算出$A(t)$和$b(t)$，代入式子（9）得到近似真实SDE的线性SDE。</p><h2 id="在状态估计中的应用-Application-in-State-Estimation"><a href="#在状态估计中的应用-Application-in-State-Estimation" class="headerlink" title="在状态估计中的应用 Application in State Estimation"></a>在状态估计中的应用 Application in State Estimation</h2><p>这里以Kevin Course和Prasanth B. Nair的2023年Nature论文<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup>为例。首先，他们分别定义了观测值$y(t)$和隐式状态$x(t)$的映射函数、以及先验和后验两个SDE：</p><p>$$<br>\begin{align}<br>&amp; y(t) = h(x(t)) + r(t) \\<br>&amp; dx(t) = f_\theta(x(t), t)dt + \Sigma_\theta(t)d\beta(t) \\<br>&amp; dx(t) =  [-A_\phi(t)x(t)+b_\phi(t)]dt + \Sigma_\theta(t)d\beta(t) \\<br>\end{align}<br>$$</p><p>其中，式子（13）是先验SDE，也就是我们待求的SDE；式子（14）是后验SDE，就是通过上一章节的高斯过程近似方法，得到的具体$A_\phi(t)$和$b_\phi(t)$。可以认为，后验SDE是一个用线性SDE近似得来的额外参考，相比直接让一个黑盒的Neural SDE<sup class="refplus-num"><a href="#ref-Neural-SDE">[4]</a></sup>用参数$\theta$去拟合数据，更加地符合SDE的基本规律（<span style="text-decoration: underline;"><strong>也就是说，至少不能比线性SDE的结果还差</strong></span>）。</p><p>由此，文章提出的学习目标ELBO（证据下界，Evidence Lower Bound）是：</p><p>$$<br>\begin{equation}<br>\begin{split}<br>    &amp; \log p(\mathcal{D}) \\<br>    &amp; = \log \mathbb{E}_{p(\theta)}\left[\mathbb{E}_{\tilde{P}|\theta}\left[\prod_{i=1}^\mathrm{N} p(y(t_i) | x(t_i))\right]\right] \\<br>    &amp;\geq \sum_{i=1}^{N} \mathbb{E}_{p_\phi(x(t_i))}[\log p(y(t_i) | x(t_i))] \\<br>    &amp;-\frac{1}{2}\int_{0}^{T} \mathbb{E}_{q_\phi(x(t))q_\phi(\theta)}{\lvert\lvert{r(x(t), \theta,\phi)}\rvert\rvert_{\Sigma_\theta Q\Sigma^\top_\theta}^2}<br>    \,dt \\<br>    &amp; - D_{KL}(q_\phi(\theta) \mid \mid p(\theta)) = \mathrm{ELBO}(\phi)<br>\end{split}<br>\end{equation}<br>$$</p><p>其中，$\mathbb{E}_{\tilde{P}|\theta}$是待求的先验SDE式子（13）对应的期望，$\mathbb{E}_{p(\theta)}$是参数$\theta$所在空间的概率分布对应的期望（实际上这个期望可以拿掉，因为无法对参数空间采样，或者说近似为当前学到的参数$\theta$，毕竟当前参数既然出现了，概率肯定最大）。 $r(x(t)\theta,\phi) = -A_\phi(t)x(t) + b_\phi(t) - f_\theta(x(t), t)$，也就是近似后验SDE约束待求先验SDE，而且只有漂移函数项约束。同时也用到了后面的扩散函数项$\Sigma_\theta$，也就是$\lvert\lvert{v}\rvert\rvert_{\Sigma_\theta Q\Sigma^\top_\theta}^2=v^\top(\Sigma_\theta Q\Sigma^\top_\theta)^{-1}v$。最后一项是对参数分布的约束，$p(\phi)$为给定的先验约束（一般是高斯分布），$q_\phi(\theta)$为真实的参数分布。</p><p>实际上，在式子（15）的不等式中，只有不等号右边的第一、二项是真的下界，用到了琴生不等式（Jensen’s Inequation），$\mathbb{E}[-\log(p)] \geq -\log\mathbb{E}(p)$，应该是参考了陈天琦团队的2020年AISTATS会议论文“Scalable gradients for stochastic differential equations”<sup class="refplus-num"><a href="#ref-AISTATS-grad">[8]</a></sup>，他们也定义了先验、近似后验两个SDE，然后对ELBO式子做了分解，得到了一个重构真实值项和一个近似后验SDE约束先验SDE的积分项，也就是第一、二项。</p><p>所以，在式子（15）中，KL散度是后来加上的，所以和之前的<a href="https://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/#%E5%9C%A8VAE%E4%B8%AD%E7%9A%84%E5%8F%98%E4%BD%93-Variant-in-VAE">变分推断笔记</a>有一定的区别，那边的KL散度是推导出来的，用来约束隐式特征，但是这边的KL散度是约束的参数。只是形式类似，都是重构真实值和KL散度约束的组合。</p><h2 id="重参数技巧和均摊分析-Reparameterization-and-Amortization"><a href="#重参数技巧和均摊分析-Reparameterization-and-Amortization" class="headerlink" title="重参数技巧和均摊分析 Reparameterization and Amortization"></a>重参数技巧和均摊分析 Reparameterization and Amortization</h2><p>与之前的<a href="https://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/#%E9%87%8D%E5%8F%82%E6%95%B0%E5%8C%96%E6%8A%80%E5%B7%A7-Reparameterization">变分推断笔记</a>类似，也是为了避免多次前向，那边是给中间的隐式特征分布从$\mathcal{N}(\mu, \sigma)$转为$\mathcal{N}(0, I)$，这里是对隐式特征分布$q_\phi(x(t))$。因为，这是近似后验SDE（参数为$\phi$）输出的当前时刻$t$的隐式状态$x(t)$概率分布，这个概率分布是很难精确找到的，毕竟SDE是带随机性的。当然，也可以通过反复前向多次、采多个$x(t)$的方式来近似它。</p><p>但是，可以回想第3章节“高斯过程近似”里面，为了求这个线性SDE的式子（10）和（11），我们已经推导出了$x(t)$的边际分布，也就是$q(x(t))=\mathcal{N}(x(t)|m(t), P(t))$，所以，我们可以直接用这个高斯分布，代替多次前向采样得到的$q_\phi(x(t))$。但是，就算不采样$x(t)$了，式子（15）对应的$r(\cdot)$函数里，每个时刻对应的$A_\phi(t)$和$b_\phi(t)$还是照样得算的。</p><p>此时，可以看到式子（10）和（11），刚好就是$A_\phi(t)$和$b_\phi(t)$构成的，由此可以重新整理成$A_\phi(t)$和$b_\phi(t)$的表达式，然后代入$r(\cdot)$函数。其中，$\oplus$是克罗内克加法（Kronecker Addition）。具体细节可以参见Nature原文<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup>：</p><p>$$<br>\begin{align}<br>&amp; r(x(t), t, \theta, \phi) \nonumber \\<br>&amp; = \mathrm{vec}^{-1}((P_\phi(t) \oplus P_\phi(t) )^{-1}\mathrm{vec}(\Sigma_\theta Q \Sigma_\theta^\top \nonumber \\<br>&amp; - \frac{dP_\phi(t)}{dt}))(m_\phi(t) - x(t)) + \frac{dm_\phi}{dt} - f_\theta(x(t), t) \\<br>\end{align}<br>$$</p><p>另外，<a href="https://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/#%E7%A4%BA%E4%BE%8B-Example">之前的笔记</a>里面有简要地提到均摊分析（Amortized Analysis）的概念，当时是为了强调参数量不应当与数据规模挂钩，否则数据量无限大则参数无限大，无法实际应用。Kevin Course和Prasanth B. Nair在NeurIPS 2023上发表的论文“Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs”<sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>，在标题里面就同时提到了重参数技巧和均摊分析。在这篇文章里，重参数技巧和Nature版本论文一致，均摊分析指的是，尝试将整段长度为N的时间序列数据，切分为M份，每份长度为N/M，从而更好地实现并行化的训练和预测。</p><h2 id="结语-Conclusions"><a href="#结语-Conclusions" class="headerlink" title="结语 Conclusions"></a>结语 Conclusions</h2><p>至此，已经写好了三篇笔记，基本搞懂了Neural ODE、SDE以及状态估计。但是，还有很多的细节没有搞懂，例如这篇里面省略的若干推导过程，以及状态估计的两篇论文<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup><sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>的更多应用场景、数据和建模方式，尤其是NeurIPS论文的附加材料<sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>给出了针对不同任务的网络结构设计。此外，现在的笔记内容全是个人理解，难免错漏，之后肯定要修改。</p><p>令人感到意外的是，三篇笔记前后关联了很多知识点，ODE和SDE的微分和积分形式、变分推断中的ELBO、重参数技巧、均摊分析。回想我在<a href="https://lmy98129.github.io/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/#more">第一篇笔记</a>里吐槽的“各种统计学、数据科学、机器学习的视频都在强调”，就体现了统计机器学习领域各理论分支的共通之处。希望这次的笔记能作为一个全新的开始，让我们继续探索，看懂更多精彩的东西！</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-torchdiffeq" data-num="1">[1]  Chen R T Q. https://github.com/rtqichen/torchdiffeq</li><li id="ref-Neural-ODE" data-num="2">[2]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-Latent-ODE" data-num="3">[3]  Rubanova Y, Chen R T Q, Duvenaud D K. Latent ordinary differential equations for irregularly-sampled time series[J]. Advances in neural information processing systems, 2019, 32.</li><li id="ref-Neural-SDE" data-num="4">[4]  Tzen B, Raginsky M. Neural stochastic differential equations: Deep latent gaussian models in the diffusion limit[J]. arXiv preprint arXiv:1905.09883, 2019.</li><li id="ref-Applied-SDE" data-num="5">[5]  Särkkä S, Solin A. Applied stochastic differential equations[M]. Cambridge University Press, 2019.</li><li id="ref-Nature-State" data-num="6">[6]  Course K, Nair P B. State estimation of a physical system with unknown governing equations[J]. Nature, 2023, 622(7982): 261-267.</li><li id="ref-NeurIPS-State" data-num="7">[7]  Course K, Nair P B. Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs[C]//Thirty-seventh Conference on Neural Information Processing Systems. 2023.</li><li id="ref-AISTATS-grad" data-num="8">[8]  Li X, Wong T K L, Chen R T Q, et al. Scalable gradients for stochastic differential equations[C]//International Conference on Artificial Intelligence and Statistics. PMLR, 2020: 3870-3882.</li></ul><p><br></p><blockquote><p>感谢阅读！如有意见和建议，欢迎通过首页的联系方式联系作者。<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Neural ODE and Beyond 2</title>
      <link href="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/"/>
      <url>/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/</url>
      
        <content type="html"><![CDATA[<p>本文是学习Neural ODE过程中的第二篇个人笔记</p><p>主要是ODE的基本原理，包括前向计算过程，以及基于伴随方法的反向传播<br>同时会简要地提一下State Estimation状态估计，其余论文细节以及SDE会在下一次记录。</p><span id="more"></span><h2 id="常微分方程-Ordinary-Differential-Equation"><a href="#常微分方程-Ordinary-Differential-Equation" class="headerlink" title="常微分方程 Ordinary Differential Equation"></a>常微分方程 Ordinary Differential Equation</h2><p>常微分方程指的是自变量只有一个的微分方程，在这里一般表示的是时间$t$，若有多个自变量则为偏微分方程。设因变量为$y$，两者的变化关系$f(y, t)$可以用常微分方程表示：</p><p>$$<br>\begin{equation}<br>dy = f(y, t)dt<br>\end{equation}<br>$$</p><p>为了得到某一个时刻$\mathrm{T}$上的$y_\mathrm{T}$具体值, 对式子（1）在$[0, \mathrm{T}]$上求定积分：</p><p>$$<br>\begin{equation}<br>y_\mathrm{T} = y_0 + \int_0^\mathrm{T} f(y, t)dt<br>\end{equation}<br>$$</p><p>其中，$y_0$为$y$在$t=0$时刻的初始值。显然，如果没有这个初始值$y_0$，式子（2）的积分项只是起止时刻的$y$的总变化量，也就是$\Delta y=y_\mathrm{T}-y_0$。因此，可以称这种问题为初值问题（IVP，Initial Value Problem）。</p><h2 id="常微分方程的求解器-ODE-Solver"><a href="#常微分方程的求解器-ODE-Solver" class="headerlink" title="常微分方程的求解器 ODE Solver"></a>常微分方程的求解器 ODE Solver</h2><p>对于$f(y,t)$，如果它是一些简单的函数，则可以直接求解得到积分的解析解。然而，当它过于复杂而无法求解积分时，需要用数值计算的方法来近似计算其积分值，记为求解器$\mathrm{ODESolver}$，则式子（2）可以改写为：</p><p>$$<br>y_\mathrm{T} = \mathrm{ODESolver}(y_0, f, [0, \mathrm{T}])<br>$$</p><p>最简单的$\mathrm{ODESolver}$是欧拉方法（Euler’s Method）。设在自变量轴$t$上的固定步长$h$，从初始时间$t_0=0$到下一步长时间$t_1=t_0+h$段内，为了知道$t_1$上具体的$y$值是多少，需要和式子（2）一样求积分，但是过于复杂没办法求解析解。</p><p>由于$f(y, t)$表示的是$y$随$t$的变化量，也就是导数，则可以求出在初始时间$t_0$对应的初值$y_0$上的导数$f(y_0, t_0)$。那么，根据导数的性质，将该导数作为斜率（Slope），乘以自变量轴上$t$的变化量，也就是步长$h$，可以得到因变量轴$y$上经过该步长的变化量$h \ f(y_0, t_0)$。将这个变化量加上初值，则为下一步长时间的因变量值$y_1$（的近似值）：</p><p>$$<br>y_1 = y_0 + h \ f(y_0, t_0)<br>$$</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/eulerdiagram.png" alt="eulerdiagram"></p><center>欧拉方法示意图，图中的自变量轴写成了$x$，而不是$t$。<a href="https://teaching.smp.uq.edu.au/scims/Appl_analysis/Eulers_method.html">图片</a>来自昆士兰大学<sup class="refplus-num"><a href="#ref-Queensland">[1]</a></sup></center><p><br></p><p>在得到了下一对自变量和因变量$(t_1, y_1)^\top$后，继续取$f(y_1, t_1)$计算$y_2$。如此迭代，则可以算到$y_\mathrm{T}$，但是该解析解一定会和真实值有一定的误差，因为这种计算方法基于步长$h$和斜率$f(x_t, y_t)$构成的三角形，而不是平滑变化过程。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/euler-method.png" alt="euler-method"></p><center>欧拉方法计算过程的轨迹与真实函数的对比。<a href="https://en.wikipedia.org/wiki/Euler_method">图片</a>来自维基百科<sup class="refplus-num"><a href="#ref-Wikipedia">[2]</a></sup></center><p><br></p><p>但是，随着步长$h$的逐渐减小，欧拉方法计算过程的轨迹也会和真实函数越来越近，可以参见维基百科<sup class="refplus-num"><a href="#ref-Wikipedia">[2]</a></sup>给出的示例。值得注意的是，<strong>这一计算过程不仅能够得到$y_\mathrm{T}$本身，也能将过程中若干个中间结果$y_t$连起来，可视化$y$的变化过程</strong>。</p><h2 id="神经常微分方程-Neural-ODE"><a href="#神经常微分方程-Neural-ODE" class="headerlink" title="神经常微分方程 Neural ODE"></a>神经常微分方程 Neural ODE</h2><p>回顾上一节，常微分方程求解器的前提条件是，已知变化关系函数$f(y,t)$的具体形式，且$f(y,t)$的积分难求解析解。但在实际应用中，还有更多只知道若干个$(t, y_t)^\top$的数据点（可能均匀采样，也可能不均采样），不知道$f(y,t)$具体形式的情况。那么，如何通过学习的方式，拟合出$f(y,t)$后，再使用$\mathrm{ODESolver}$求解$y_\mathrm{T}$呢？</p><p>在讲2018年理论三大会NeurIPS的Best Paper、陈天琦团队发表的Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup>之前，我们需要回顾一个更加熟悉的工作，也就是已经成为CV界著名的基础设施、大佬何凯明团队在CV三大会CVPR 2016上发表的ResNet<sup class="refplus-num"><a href="#ref-ResNet">[4]</a></sup>。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/ResBlock.png" alt="ResBlock"></p><center>ResNet中的一个Residual Block，图中的隐式特征为$x$。</center><p><br></p><p>对于ResNet中的第$t$个Residual Block，其输入的隐式特征为$x_t$，处理该特征的网络参数为$\theta_t$，输出的隐式特征为$x_{t+1}$，则该Residual Block输入输出隐式特征的过程，可以用公式表示为：</p><p>$$<br>x_{t+1} = x_t + f(x_t, \theta_t)<br>$$</p><p>由于Resisual Block的个数一般是整数个，则步长$h=1$。当步长大小趋近于0，也即$h \rightarrow 0$时，有：</p><p>$$<br>\begin{align}<br>&amp; x_{t+1} = x_t + f(x_t, \theta_t) \nonumber \\<br>&amp; \Rightarrow \frac{x_{t+1} - x_t}{1} = f(x_t, \theta_t) \nonumber \\<br>&amp; \Rightarrow \frac{x_{t+h} - x_t}{h} = f(x_t, \theta_t) \nonumber \\<br>&amp; \Rightarrow \lim_{h \rightarrow 0} \frac{x_{t+h} - x_t}{h} = f(x_t, t, \theta) \nonumber \\<br>&amp; \Rightarrow \frac{dx_t}{dt} = f(x_t, t, \theta) \\<br>\end{align}<br>$$</p><p>其中，在转换为极限时，Residual Block $f(x_t, \theta_t)$需要改成$f(x_t, t, \theta)$。因为当步长$h \rightarrow 0$时，需要无数个$\theta_t$进行迭代，参数总量趋于无穷，无法实际应用。转为固定参数$\theta$后，$t$可以提示网络要输出对应时间下的结果。</p><p>所以，如式子（3）所示，ResNet作为一个神经网络，同样可以表示为常微分方程ODE的形式。当然，也可以从式子（3）中对步长（从步长为固定整数1、迭代次数也是固定的，到步长趋于0、迭代次数趋于无穷）、网络参数（从每次迭代使用不同的网络参数，到所有迭代共享一个网络参数且用$t$提示网络当前迭代时间）的修改看出，原始的ResNet并不能表示常微分方程，需要进行一定的改造。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/resnet-vs-neuralode.png" alt="resnet-vs-neuralode"></p><center>ResNet与Neural ODE的对比。图片来自Neural ODE论文原文<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup></center><p><br></p><p>在Neural ODE原文<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup>的首图中，可以更直观地看出两者的区别。纵轴为网络深度，可以视为自变量轴$t$；横轴为输入、输出和隐式特征，可以视为因变量$x$或$y$。左图是ResNet，时间$t$的步长为固定整数1，每一次$x$都只能从上一个步长变化到下一个，变化过程是离散的，只能拿这些因变量作为验证点（图中黑色实心圆点，evaluation locations）；右图图是Neural ODE，时间$t$的步长为无穷小，可以近似为连续过程，任意不均匀的时间点都可以计算$x$，作为验证点。</p><p>同样的，对于循环神经网络RNN，虽然与ResNet的网络参数使用方式不同，所有迭代共享一个网络参数，但也无法迭代非整数个步长。上图没有考虑网络参数是否共享的问题，因此RNN也一样只能输出类似于左侧的结果。</p><p>因此，Neural ODE能够直接在不知道$f(y,t)$具体形式的情况，基于若干个$(t, y_t)^\top$的数据点作为训练集，用网络参数$\theta$拟合出一个神经网络形式的ODE，也就是$f(y_t, t, \theta)$，然后再将这一形式代入到$\mathrm{ODESolver}$中，求解出需要的$y_\mathrm{T}$值。</p><h2 id="伴随方法-Adjoint-Method"><a href="#伴随方法-Adjoint-Method" class="headerlink" title="伴随方法 Adjoint Method"></a>伴随方法 Adjoint Method</h2><p>那么，如何训练出一个Neural ODE呢？最自然的方式，肯定是在某一点有真实值$(t_1, y_t)^\top$时，将其与Neural ODE的输出$\hat{y_t}$计算损失并反向传播梯度。但是，从上述Neural ODE的性质可以看出，它的迭代步长远小于ResNet、RNN的整数步长，前向输出$\hat{y_t}$所经历的迭代次数也非常多（例如$10^2\sim 10^3$次）。如果直接建立梯度的计算图，将需要保存大量的前向和反向的中间特征和中间梯度，消耗大量资源。因此，Neural ODE原文采用了伴随方法（Adjoint Method）。这里参考这篇知乎文章的推导过程<sup class="refplus-num"><a href="#ref-Zhihu-Adjoint">[5]</a></sup>。</p><p>首先，需要注意的是，Neural ODE并未直接对预测值$\hat{y_t}$使用式子（3）进行ODE方式的更新，而是和ResNet、RNN一样，对隐式特征进行更新。然后通过另一个神经网络，输入隐式特征，输出预测值。这里为了和原文保持一致，将隐式特征记作$z(t)$。省略输出预测值、预测值与真实值计算损失的过程，将损失函数$\mathcal{L}$记为隐式特征的函数$\mathcal{L}(z(t))$：</p><p>$$<br>\begin{align}<br>\mathcal{L}(z(t_1)) &amp; = \mathcal{L}(\mathrm{ODESolver}(z(t_0), f, t_0, t_1, \theta)) \nonumber \\<br>&amp; = \mathcal{L}(z(t_0) + \int_{t_0}^{t_1} f(z(t), t, \theta)dt) \nonumber \\<br>\end{align}<br>$$</p><p>由链式法则，在任意时刻$t \leq t_1$（因为是反向传播，从最终的$t_1$算梯度往回传），对于损失函数求隐式特征偏导：</p><p>$$<br>\frac{\partial \mathcal{L}}{\partial z(t)} = \frac{\partial \mathcal{L}}{\partial z(t_1)} \frac{\partial z(t_1)}{\partial z(t)}<br>$$</p><p>定义一个伴随状态（Adjoint State），与时间$t$相关的函数$a(t)$：</p><p>$$<br>\begin{equation}<br>a(t) = \frac{\partial \mathcal{L}}{\partial z(t)}<br>\end{equation}<br>$$</p><p>那么对于任意$t+\epsilon &gt; t$时刻（包括$t_1$在内），都有：</p><p>$$<br>\begin{align}<br>\frac{\partial \mathcal{L}}{\partial z(t)} &amp; = \frac{\partial \mathcal{L}}{\partial z(t+\epsilon)} \frac{\partial z(t+\epsilon)}{\partial z(t)} \nonumber \\<br>&amp; = a(t+\epsilon) \frac{\partial z(t+\epsilon)}{\partial z(t)} \\<br>\end{align}<br>$$</p><p>从$t$时刻开始，求解$t+\epsilon$时刻的隐式特征$z(t+\epsilon)$，可以算积分：</p><p>$$<br>\begin{equation}<br>z(t+\epsilon) = z(t) + \int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’<br>\end{equation}<br>$$</p><p>将式子（4）、（6）代入式子（5），可以得到：</p><p>$$<br>\begin{align}<br>&amp; a(t) = a(t+\epsilon) \frac{\partial}{\partial z(t)} ( z(t) + \int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’) \nonumber \\<br>&amp; = a(t+\epsilon) (1 + \frac{\partial}{\partial z(t)} (\int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’)) \nonumber \\<br>&amp; \Rightarrow a(t+\epsilon) - a(t) \nonumber \\<br>&amp; = - a(t+\epsilon) \frac{\partial}{\partial z(t)} (\int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’)<br>\end{align}<br>$$</p><p>式子（7）即可描述伴随方程$a(t)$随时间$t$的变化，进一步计算$\frac{da(t)}{dt}$：</p><p>$$<br>\begin{align}<br>&amp; \frac{da(t)}{dt} = \lim_{\epsilon \rightarrow 0} \frac{a(t+\epsilon) - a(t)}{\epsilon} \nonumber \\<br>&amp; = \lim_{\epsilon \rightarrow 0} \frac{- a(t+\epsilon) \frac{\partial}{\partial z(t)} (\int_{t}^{t+\epsilon} f(z(t’), t’, \theta)dt’)}{\epsilon} \nonumber \\<br>&amp; = \lim_{\epsilon \rightarrow 0} \frac{- a(t+\epsilon) \frac{\partial}{\partial z(t)} (\epsilon \cdot f(z(t), t, \theta))}{\epsilon} \nonumber \\<br>&amp; = \lim_{\epsilon \rightarrow 0} - a(t+\epsilon) \frac{\partial f(z(t), t, \theta)}{\partial z(t)} \nonumber \\<br>&amp; = - a(t) \frac{\partial f(z(t), t, \theta)}{\partial z(t)} \\<br>\end{align}<br>$$</p><p>由于$\epsilon \rightarrow 0$，且偏导$\frac{\partial}{\partial z(t)}$与$\epsilon$无关。一个小区间的积分，就是高度为函数值，宽度为无穷小的矩形面积，则上式中的积分，就等于在$t$这个点上的$f$函数值乘以一个$dt’ = \epsilon$。分子分母两个$\epsilon$约去后，又由$\epsilon \rightarrow 0$，则$a(t+\epsilon) = a(t)$。</p><p>式子（8）就是伴随状态$a(t)=\frac{\partial \mathcal{L}}{\partial z(t)}$随时间的常微分方程，既然是常微分方程，就可以使用$\mathrm{ODESolver}$近似求解任意时刻的伴随状态，无需对偏导$\frac{\partial \mathcal{L}}{\partial z(t)}$本身建立复杂的反向传播计算图：</p><p>$$<br>\begin{align}<br>&amp; a(t_0) = a(t_1) + \int_{t_1}^{t_0} \frac{da(t)}{dt} dt \nonumber \\<br>&amp; = a(t_1) - \int_{t_1}^{t_0} a(t) \frac{\partial f(z(t), t, \theta)}{\partial z(t)} dt \nonumber \\<br>&amp; = \mathrm{ODESolver}(a(t_1), - a(t) \frac{\partial f}{\partial z(t)}, t_1, t_0)<br>\end{align}<br>$$</p><p>但是，$\frac{\partial \mathcal{L}}{\partial z(t)}$只是反向传播的一部分，计算出这个损失函数与隐式特征的偏导之后，还要计算出损失函数与网络参数的偏导，也定为伴随状态$a_\theta(t) = \frac{\partial \mathcal{L}}{\partial \theta(t)}$。虽然，根据Neural ODE的性质，不同迭代次数下的网络参数$\theta$是不变的。但是，由于最终的梯度由$\geq 1$个不同真实值$(t, y_t)^\top$计算损失累积得到，所以认为仍然与时间有关，但是$\frac{\partial \theta}{\partial t} = 0$。由链式法则：</p><p>$$<br>\begin{align}<br>&amp; a_\theta(t) = \frac{\partial \mathcal{L}}{\partial z(t+\epsilon)} \frac{\partial z(t+\epsilon)}{\partial \theta(t)} \nonumber \\<br>&amp; + \frac{\partial \mathcal{L}}{\partial \theta(t+\epsilon)} \frac{\partial \theta(t+\epsilon)}{\theta(t)} \nonumber \\<br>&amp; = a(t+\epsilon) \frac{\partial z(t+\epsilon)}{\partial \theta(t)} + a_\theta (t+\epsilon) \cdot 1 \\<br>&amp; = a(t+\epsilon)  \int_{t}^{t+\epsilon} \frac{\partial f}{\partial \theta} dt + a_\theta (t+\epsilon) \nonumber \\<br>&amp; \Rightarrow a_\theta(t+\epsilon) - a_\theta(t) \nonumber \\<br>&amp; =  - a(t+\epsilon)  \int_{t}^{t+\epsilon} \frac{\partial f}{\partial \theta} dt \\<br>\end{align}<br>$$</p><p>其中，式子（6）的$z(t+\epsilon)$积分可以代入到式子（10）中。式子（11）即可描述伴随方程$a_\theta(t)$随时间$t$的变化，进一步计算$\frac{da_\theta(t)}{dt}$：</p><p>$$<br>\begin{align}<br>&amp; \frac{da_\theta(t)}{dt} = \lim_{\epsilon \rightarrow 0} \frac{a_\theta(t+\epsilon) - a_\theta(t)}{\epsilon} \nonumber \\<br>&amp; = \lim_{\epsilon \rightarrow 0} \frac{- a(t+\epsilon)  \int_{t}^{t+\epsilon} \frac{\partial f}{\partial \theta} dt}{\epsilon} \nonumber \\<br>&amp; = - a(t) \frac{\partial f(z(t), t, \theta)}{\partial \theta(t)} \\<br>\end{align}<br>$$</p><p>过程与式子（8）相同，此处省略若干步骤。由此，式子（12）也是对伴随状态$a_\theta(t) = \frac{\partial \mathcal{L}}{\partial \theta(t)}$的常微分方程，也可以使用$\mathrm{ODESolver}$近似求解任意时刻的伴随状态，无需对$\frac{\partial \mathcal{L}}{\partial \theta(t)}$本身建立复杂的反向传播计算图，同式子（9）：</p><p>$$<br>\begin{align}<br>&amp; a_\theta(t_0) = a_\theta(t_1) + \int_{t_1}^{t_0} \frac{da_\theta(t)}{dt} dt \nonumber \\<br>&amp; = a_\theta(t_1) - \int_{t_1}^{t_0} a(t) \frac{\partial f(z(t), t, \theta)}{\partial \theta} dt \nonumber \\<br>&amp; = \mathrm{ODESolver}(a_\theta(t_1), - a(t) \frac{\partial f}{\partial \theta}, t_1, t_0)<br>\end{align}<br>$$</p><p>从式子（13）可以看到，由于$a_\theta(t)$依赖于$a(t)$的求解，$a(t)$又依赖于$z(t)$的求解，因此Neural ODE原文将它们同时送入同一个$\mathrm{ODESolver}$，从而进一步提高了计算效率。为了便于复用，Neural ODE的作者团队封装了这套特殊算法的代码库，作为他们开源项目的组成部分：<a href="https://github.com/rtqichen/torchdiffeq">torchdiffeq</a>。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/adjoint-method.png" alt="adjoint-method"></p><center>Neural ODE针对伴随方法设计的反向传播算法。<br>其中“aug_dynamics”相当于式子（3）、（9）和（13）的联立之后，互相代入现有值<br> 图片来自Neural ODE论文原文<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup></center><p><br></p><p>有趣的是，可以注意到前面的时间全是$t_0$和$t_1$，而且是从$t_1$倒着回到$t_0$（这倒是好理解，因为是算梯度，肯定是从最后一次计算损失的时候往回传）。为什么不是整条预测序列呢（例如从$t_1$到$t_\mathrm{start}$）？如果这样的话，可以看到用上图中只有一个真实值$(t_1, y_{t_1})^\top$计算损失得到的$\frac{\partial \mathcal{L}}{\partial z(t_1)}$，忽略了从$t_1$到$t_\mathrm{start}$中间若干个其他通过真实值$(t, y_t)^\top$得到的$\frac{\partial \mathcal{L}}{\partial z(t_1)}$，这样会导致最终计算出的$\frac{\partial \mathcal{L}}{\partial z(t_0)}$有较大的误差。因此，Neural ODE原文只用上述算法计算真实值之间的伴随状态，遇到真实值就用真实值的$\frac{\partial \mathcal{L}}{\partial z(t_1)}$作为初始值，重新用上述算法计算，从而使得累积误差最小。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/reverse-mode.png" alt="reverse-mode"></p><center>Neural ODE使用伴随状态进行反向传播的方式。<br>上图：先计算损失$\mathcal{L}$，得到真实的$\frac{\partial \mathcal{L}}{\partial z(t)}$。下图：红线是$\mathrm{ODESolver}$计算出来的伴随状态，蓝色虚线是基于真实的$\frac{\partial \mathcal{L}}{\partial z(t)}$来重新开始计算$a(t)$，从而使得误差累积更小。图片来自Neural ODE论文原文<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup></center><h2 id="在状态估计中的应用-Application-in-State-Estimation"><a href="#在状态估计中的应用-Application-in-State-Estimation" class="headerlink" title="在状态估计中的应用 Application in State Estimation"></a>在状态估计中的应用 Application in State Estimation</h2><p>从前文可以看到，Neural ODE的隐式特征（也可以称为隐式状态，Hidden State）实际上和ResNet、RNN一样，是黑盒化的特征向量或张量，实际上无法反应与客观世界对应的、结构化的内在状态，同时也很难直观地可视化。为了能够在一定程度上将这些隐式状态可视化，Kevin Course和Prasanth B. Nair在2023年10月的Nature正刊上发表了“State estimation of a physical system with unknown governing equations”<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup>。</p><p><img src="/2024/01/07/Notes-About-Neural-ODE-and-Beyond-2/state-estimation.png" alt="state-estimation"></p><center>基于Neural SDE的状态估计结果。左图为学习到的隐式状态$x(t)$，右图为对应流体仿真结果的真实值、预测值和标准差（蓝色，用于衡量预测值与真实值的偏差程度）。图片来自Nature论文原文<sup class="refplus-num"><a href="#ref-Nature-State">[6]</a></sup></center><p><br></p><p>该工作采用了相比Neural ODE更加贴近真实物理系统、考虑了随机布朗运动的Neural SDE（SDE即随机微分方程，Stochastic Differential Equation），通过在有限的观测数据$y(t)$上学习，得到了更强的对$y(t)$进行内插和外推的能力，同时也学习到了更加可解释的隐式状态$x(t)$。</p><p>虽然，他们也认为，Neural SDE相比纯符号模型（通过建模方程、待定参数拟合的方式）可解释性更低，但是也可用于（1）无法用方程拟合的复杂高维数据，例如视频数据<sup class="refplus-num"><a href="#ref-NeurIPS-State">[7]</a></sup>；（2）无法确定合适的基础方程用于建模和拟合的情况。至于这些工作如何实现状态估计的、以及相应的技术细节，就留到下次笔记。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Queensland" data-num="1">[1]  Euler's method. https://teaching.smp.uq.edu.au/scims/Appl_analysis/Eulers_method.html</li><li id="ref-Wikipedia" data-num="2">[2]  Euler method. https://en.wikipedia.org/wiki/Euler_method</li><li id="ref-Neural-ODE" data-num="3">[3]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-ResNet" data-num="4">[4]  He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</li><li id="ref-Zhihu-Adjoint" data-num="5">[5]  Maple小七. 理解伴随法(Adjoint Method)在Neural ODE中的应用. https://zhuanlan.zhihu.com/p/337575425</li><li id="ref-Nature-State" data-num="6">[6]  Course K, Nair P B. State estimation of a physical system with unknown governing equations[J]. Nature, 2023, 622(7982): 261-267.</li><li id="ref-NeurIPS-State" data-num="7">[7]  Course K, Nair P B. Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs[C]//Thirty-seventh Conference on Neural Information Processing Systems. 2023.</li></ul><p><br></p><blockquote><p>感谢阅读！如有意见和建议，欢迎通过首页的联系方式联系作者。<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Neural ODE and Beyond 1</title>
      <link href="/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/"/>
      <url>/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/</url>
      
        <content type="html"><![CDATA[<p>本文是学习Neural ODE过程中的第一篇个人笔记</p><p>为了较为全面地理解其中的VAE思想，首先需要学习一些基础知识，例如Variational Inference变分推断<br>比较复杂的其他过程，包括ODE、伴随方法、以及更进阶的SDE，会在之后的笔记中再记录。</p><span id="more"></span><h2 id="前言-Introduction"><a href="#前言-Introduction" class="headerlink" title="前言 Introduction"></a>前言 Introduction</h2><p>最近，估计是搜了若干比较数学理论的东西，被B站的推荐系统疯狂轰炸，各种统计学、数据科学、机器学习的视频都在强调“变分推断”。然而，我总是看不懂，反复问自己“为什么要使用变分推断？”，“为什么大家都在强调变分推断很重要，最新的研究也一直层出不穷？”。</p><p>起初，我觉得这就是一个高大上的名词，反正在CV、NLP乃至语音，大力出奇迹的事情多了去了，用得着再回到统计理论这边吗？感觉统计理论距离落地应用总是很远，用的数据集有很多也是比较玩具的（理想化）。然而万万没想到，项目确实碰到了这个问题，需要用到类似Neural ODE的方法，基于观测来建模一个过程的内部状态变化，那么深入了解变分推断就是很重要的工作了。</p><p>虽然，我确实接触过VAE（变分自编码器Variational Auto-Encoder）的概念，知道自编码器确实可以通过高斯分布的$\mu$和$\sigma$的显式形式，来代替隐式的表征$z$，来实现更加可控地重构图像$x$，也知道为了保证这一点，需要找出一个ELBO（证据下界，Evidence Lower Bound）作为网络的优化目标。但是从头到尾，“变分”这个名词总如天外来客，没有由来。</p><p>PS：下面的各种过程主要都是变量代换，以及一些现成的公式，不涉及很深的数学理论，可以根据每章首尾的前后衔接，按需跳读。</p><h2 id="贝叶斯公式-Bayes-Formula"><a href="#贝叶斯公式-Bayes-Formula" class="headerlink" title="贝叶斯公式 Bayes Formula"></a>贝叶斯公式 Bayes Formula</h2><p>事实上，这仍然是最底层的贝叶斯理论引出，这里就参考B站视频<sup class="refplus-num"><a href="#ref-Bilibili-VI">[1]</a></sup>。首先讲一个CV的例子：有观测到的图像$x$，其隐式状态是one-hot的类别编码$z$。例如，有三个类A、B、C，如果这个图像是A类，则$z=(1, 0, 0)^\top$。为了知道这个图像到是否真的属于类别A，需要知道相应的概率。也就是给定观测值$x$，其隐式状态应该属于$z$的概率。这显然是一个条件概率，写作$p(z|x)$。根据贝叶斯公式，有：</p><p>$$<br>p(z|x)=\frac{p(x|z)p(z)}{p(x)}<br>$$</p><p>各个项表达的意思是：1）分子：$p(x|z)p(z)=p(x,z)$，观测值$x$和隐式状态$z$的联合概率（Joint Probability），就是观测值$x$和隐式状态$z$同时出现的概率，其中$p(z)$为隐式状态出现的先验概率（Prior Probability），$p(x|z)$就是隐式状态固定的条件下，样本出现的概率；2）分母：$p(x)=\int_0^\mathrm{\infty} p(x,z) dz$，观测值本身出现的先验概率，就是所有可能的隐式状态$z$下，观测值$x$出现的概率之和；3）总体：$p(z|x)$后验概率（Posterior Probability），在观测值已经出现的这一种先验下（分母），观测值与隐式状态同时出现的概率（分子）。</p><p>很多人都知道在学贝叶斯的过程中，他们会被告知$p(z|x) \sim p(x|z)p(z)$，因为一旦$x$确定下来了，$p(x)$就是个常数。但是，这个常数到底能不能省略呢？如果要知道$p(z|x)$的确切数值的话，其实是必须知道的。按照我个人的理解，如果观测值$x$是一个过于罕见或者常见的样本，导致$p(x)$本身非常小或者非常大，那么这将会决定$p(z|x)$的最终数值，联合概率$p(x,z)$再大再小也不能与后验概率$p(z|x)$划等号。</p><p>换而言之，不同的观测值$x$决定了不同的$p(x)$，而不同的$p(x)$最终决定了$p(z|x)$的取值。例如，这个B站视频<sup class="refplus-num"><a href="#ref-Bilibili-VI">[1]</a></sup>里面的一个可视化例子，横轴为不同的隐式状态取值$z$，纵轴为不同方法计算出的概率取值，取不同的观测值$x$：</p><p><img src="/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/example-prior.png" alt="example-prior"></p><center>可以看到，单纯地估计联合概率（蓝线“Joint”）是不够的<br>与真正带有先验$p(x)$的后验概率（红线“True Posterior”，通过数值计算得到）有非常明显的不同。<br><a href="https://www.bilibili.com/video/BV1Gs4y157BU?t=388.3">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-VI">[1]</a></sup></center><p><br></p><p>所以，正如上面的截图中所说，需要找到一个更简单的分布，来逼近这个因为先验概率$p(x)=\int_0^\mathrm{N} p(x,z) dz$比较难算（因为没办法穷尽所有的可能，去找到观测值$x$本身出现的概率），而导致本身比较难算的后验概率$p(z|x)$。</p><h2 id="变分推断-Variational-Inference"><a href="#变分推断-Variational-Inference" class="headerlink" title="变分推断 Variational Inference"></a>变分推断 Variational Inference</h2><p>为了解决这个问题，变分的思想就是使用一些可以参数化的（例如高斯分布可以用$\mu$和$\sigma$两个参数来表示）、更简单的概率分布，来近似一个难算的概率分布，例如在这边就是后验分布$p(z|x)$。从泛函的角度来讲，就是由一族函数构成的空间（类比机器学习里面常提的参数空间），我们要通过变化输入参数（Variable），来找到这个空间中最能满足近似目标的一个函数。</p><p>至于为什么叫推断，实际上还是前面的一套贝叶斯的思路，用先验分布和联合分布来推断后验分布，所以如果不用变分操作，就可以直接叫贝叶斯推断（Bayesian Inference）了。</p><p>首先，为了逼近、近似一个分布，肯定需要衡量我们预测的分布和目标分布的相似度。最常用的就是KL散度（Kullback-Leibler Divergence）：</p><p>$$<br>\begin{align}<br>D(q||p) = &amp; \ H(q, p)-H(q) \nonumber \\<br>= &amp; \ \int q(x)\log\frac{q(x)}{p(x)}dx \nonumber \\<br>= &amp; \ \mathbb{E}_{x\sim q}[\log q(x) - \log p(x)] \nonumber \\<br>\end{align}<br>$$</p><p>由于后验分布$p(z|x)$中，难算的主要是$p(x)$，所以我们不能直接近似它，而且在近似过程中肯定不能再引入$x$了，那么只剩下隐式状态$z$。我们用来近似$p(z|x)$的后验概率就记作$q_\theta(z)$，其中$\theta$就是参数。那么，基于KL散度来衡量两者的相似度，有这样的计算过程：</p><p>$$<br>\begin{align}<br>&amp; D(q_{\theta}(z)||p(z|x)) \nonumber \\<br>&amp; = \ \mathbb{E}_{z\sim q} [ \log q_{\theta}(z) - \log \frac{p(x, z)}{p(x)} ] \nonumber \\<br>&amp; = \ \mathbb{E}_{z\sim q} [ \log q_{\theta}(z) - \log p(x, z) ]  + \log p(x)<br>\end{align}<br>$$</p><p>其中，$\log p(x)$和$z$没关系，所以用期望公式的$q_\theta(z)$来加权求和之后，还是自己本身，所以可以从里面拿出来。那么，我们整理上述公式，$\log p(x)$等于式子（1）中的期望项的负号和KL散度的组合：</p><p>$$<br>\begin{align}<br>\log p(x) = &amp; \ \mathbb{E}_{z\sim q} [ \log p(x, z) - \log q_{\theta}(z) ] \nonumber \\<br>&amp; + D(q_{\theta}(z)||p(z|x)) \nonumber \\<br>\geq &amp; \ \mathbb{E}_{z\sim q} [ \log p(x, z) - \log q_{\theta}(z) ]<br>\end{align}<br>$$</p><p>可以看到，不等号右边的期望里，一个是近似结果$q_\theta(z)$，另一个是贝叶斯的分子、比较好算的联合概率分布$p(x,z)$，完全避开了最难算的$p(x)$。而且，虽然$p(x)$具体取值不知道，但是我们知道它是一个定值，所以不等号左边，如果KL散度越来越小了，那么两个分布越来越接近，反过来期望就越来越大。那么，我们的优化目标就可以从式子(1)中的最大化的KL散度，迁移到式子(2)的最大化不等号右边的下界。</p><p>这个最大化的意思就是，因为这个下界恒小于等于$\log p(x)$的真实值。那么，不断抬高这个下界，就能使得这个下界的值，逼近$\log p(x)$的真实值。这个下界也就是VAE等带“变分”二字的方法中常说的ELBO（证据下界，Evidence Lower Bound），这个“证据”就指的是$p(x)$，因为它反映了观测数据的真实分布。</p><h2 id="示例-Example"><a href="#示例-Example" class="headerlink" title="示例 Example"></a>示例 Example</h2><p>假定一个标量形式的隐式状态$z$的先验概率分布$p(z)$为：</p><p>$$<br>p(z) = \mathrm{e}^{-z}\cdot \mathrm{I}(z\geq 0) = \left\{<br>\begin{aligned}<br>&amp;\mathrm{e}^{-z} &amp;z\geq 0 \cr<br>&amp;0 &amp;z&lt;0 \cr<br>\end{aligned}<br>\right.<br>$$</p><p>给定隐式状态取值为$z$时，观测值$x$的条件概率$p(x|z)$为高斯分布：</p><p>$$<br>\begin{align}<br>p(x|z) = &amp; \ \mathcal{N}(x; \mu=z, \sigma=1) \nonumber \\<br>= &amp; \ \frac{1}{\sqrt{2\pi}}\mathrm{e}^{(-\frac{1}{2}(x-z)^2)} \nonumber \\<br>\end{align}<br>$$</p><p>那么，可以计算出联合分布$p(x, z)$，以及进一步对联合分布中的所有隐式状态$z$积分，得到的观测值$x$的先验概率分布$p(x)$</p><p>$$<br>\begin{align}<br>p(x, z) = &amp; \ p(x|z)p(z) \nonumber \\<br>= &amp; \ \frac{1}{\sqrt{2\pi}}\mathrm{e}^{(-\frac{1}{2}(x-z)^2)} \cdot \mathrm{e}^{-z}\cdot \mathrm{I}(z\geq 0) \nonumber \\<br>\end{align}<br>$$</p><p>$$<br>\begin{align}<br>p(x) = &amp; \ \int_0^\infty p(x, z) dz \nonumber \\<br>= &amp; \ \int_0^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{(-\frac{1}{2}(x-z)^2)} \cdot \mathrm{e}^{-z}\cdot \mathrm{I}(z\geq 0) dz \nonumber \\<br>\end{align}<br>$$</p><p>可以看到，联合分布$p(x, z)$本身是两个指数函数的乘积，可以正常地算出函数值。但是对其在$[0, \infty)$（也就是$z\geq 0$）上算积分，事实上是非常难算的。而实践中大部分场景就是若干个指数函数（或者带有指数函数的高斯分布）组合成的，只能通过数值解法插值出来，也就是上面视频截图里的红线部分。</p><p>那么，基于上一章节描述的变分推断，是否能比较好地解这个问题（也就是近似后验概率$p(z|x)$）呢？首先，我们给出一个简单的参数化概率分布$q_\theta(z)$：</p><p>$$<br>q_\theta(z) = \theta\mathrm{e}^{-\theta z}\cdot \mathrm{I}(z\geq 0) = \left\{<br>\begin{aligned}<br>&amp; \theta \mathrm{e}^{-\theta z} &amp;z\geq 0 \cr<br>&amp;0 &amp;z&lt;0 \cr<br>\end{aligned}<br>\right.<br>$$</p><p>计算前述式子（2）里的ELBO，记作$\mathcal{L}_q$：</p><p>$$<br>\begin{align}<br>\mathcal{L}_q = &amp; \ \mathbb{E}_{z\sim q} [ \log p(x, z) - \log q_{\theta}(z) ] \nonumber \\<br>= &amp; \ \mathbb{E}_{z\sim q} [ \log \frac{1}{\sqrt{2\pi}}\mathrm{e}^{(-\frac{1}{2}(x-z)^2)} \cdot \mathrm{e}^{-z}\cdot \mathrm{I}(z\geq 0) \nonumber \\<br>&amp; - \log \theta\mathrm{e}^{-\theta z}\cdot \mathrm{I}(z\geq 0) ] \nonumber \\<br>\end{align}<br>$$</p><p>由于$\log (\cdot)$函数的定义域就是$(0, \infty)$，同时$\mathrm{I}(z\geq 0)$表示$z&lt;0$时取$0$作为加权，导致代入$\log (\cdot)$无意义，所以可以直接舍去。将指数函数$\mathrm{e}^{(\cdot)}$与$\log(\cdot)$抵消，并整理与$z$和$\theta$无关的项为常数$\mathrm{C}$后，得到：</p><p>$$<br>\mathcal{L}_q = \mathbb{E}_{z\sim q} [ -\frac{1}{2}z^2 + (x - 1 + \theta)z - \log \theta + \mathrm{C} ]<br>$$</p><p>对带参数$\theta$的指数分布$q$求期望，有$\mathbb{E}_\theta [z^n] = \frac{n!}{\theta^n}$，则上式中的$z^2$和$z$项目均可以代入该期望公式。同时，$\log \theta$与$z$无关，对其求期望的结果还是本身：</p><p>$$<br>\mathcal{L}_q = - \frac{1}{\theta^2} + \frac{x-1+\theta}{\theta} - \log \theta + \mathrm{C}<br>$$</p><p>上式就是化简后的ELBO，为了求这个ELBO最大化时的参数$\theta$，令导数$\frac{\partial \mathcal{L}_q}{\partial \theta}=0$，代入$x=1.5$：</p><p>$$<br>\frac{\partial \mathcal{L}_q}{\partial \theta} = \frac{2}{\theta^3} - \frac{0.5}{\theta^2} + \frac{1}{\theta} = 0<br>$$</p><p>计算得到方程的解是$\theta=1.186$。将该参数代入$q_\theta(z)$，可以画出绿色曲线如下图所示：</p><p><img src="/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/example-vi.png" alt="example-vi"></p><center>联合概率为蓝线“Joint”，真正带有先验$p(x)$的后验概率为红线“True Posterior”（通过数值计算得到），<br>以及变分推理后得到的绿线$q_\theta(z)$。<a href="https://www.bilibili.com/video/BV1Gs4y157BU?t=822.4">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-VI">[1]</a></sup></center><p><br></p><p>一方面，可以看到虽然绿色的曲线比蓝色的（联合分布）稍微好点了，但是距离红色（真实的后验概率）还是很远，说明$q_\theta(z)$的构造和选取很影响最终结果，而且这也只是一个观测数据点$x=1.5$的解，需要遍历所有数据点，每个样本优化出一个参数$\theta_x$，数据集无限大则参数无限大，拟合成本高且不实用。</p><p>从均摊分析（Amortized Analysis）的角度上考虑，机器学习、神经网络等学习方法可以有$\mathrm{K}$个全局参数，在训练过程中联合调整，与数据集规模无关，这样就能得到有限个参数，且训练结束后即可直接应用到测试集上。</p><p>另一方面，即使是标量形式的隐式状态$z$和观测值$x$都如此地难近似，更不要说高维的数据了，此时就需要机器学习、神经网络等学习方法，用更大规模的参数$\theta$在高维数据上学习拟合到更好的函数$q_\theta(z)$。</p><h2 id="在VAE中的变体-Variant-in-VAE"><a href="#在VAE中的变体-Variant-in-VAE" class="headerlink" title="在VAE中的变体 Variant in VAE"></a>在VAE中的变体 Variant in VAE</h2><p>首先，需要强调的一点是，Neural ODE<sup class="refplus-num"><a href="#ref-Neural-ODE">[3]</a></sup>作为2018年的理论三大会NeurIPS的Best Paper，肯定是有其基本理论的，其中之一就是VAE。因此，它的底层学习机制还是一个生成式的模型，因为它的大部分任务是对时间序列的内插和外推，所以需要基于学习到的隐式状态，生成新的数据。</p><p>而前面描述的变分推断还是一个判别式的模型，粗浅一点讲，判别式模型是$x\rightarrow z$，而生成式模型是$z\rightarrow x$。但是从因果图来说，都是$z\rightarrow x$，因为这是数据产生的方式，要先有客观状态（物体就是类别A），才能有相应的观测（类别A的图片），生成式模型尝试模拟这个过程，判别式模型倒推反演这个过程。</p><p>那么是否有判别式的模型，帮助我们直接从观测数据倒推出内部的隐式状态呢？其实是有的，之后的记录中会详细对比，这里先讲基础的VAE和Neural ODE（而且Neural ODE真的不能有判别任务吗？也不尽然，其实原文里面有对应实验）。</p><p>这里参考B站视频<sup class="refplus-num"><a href="#ref-Bilibili-VAE">[2]</a></sup>，VAE的编码器Encoder是$q_\phi(z|x)$，给定输入数据求解隐式状态，生成器Decoder是$p_\theta(x|z)$，给定隐式状态求解生成数据，同时先验概率$p(x)$仍然是难求解的项目。同时，为了继承原有的变分性质，有别于普通自编码器（Auto-Encoder）输出了纯黑盒的中间隐式向量$z$，$q_\phi(z|x)$对于每个样本都输出$\mu_\phi(x)$和$\sigma_\phi(x)$，作为用于近似后验概率$p(z|x)$的高斯分布函数的参数。</p><p>同样，从均摊分析的角度考虑，如果ELBO使用式子（2）里的$q_\theta(z)$，每个样本仍然是要都学习一个$\theta_x$。因此，直接引入编码器$q_\phi(z|x)$，包含全局的参数$\phi$。重新构造ELBO（$\mathcal{L}_q$）如下所示：</p><p>$$<br>\begin{align}<br>\mathcal{L}_q = &amp; \ \mathbb{E}_{z\sim q} [ \log p(x, z) - \log q_{\phi}(z|x)] \nonumber \\<br>= &amp; \ \mathbb{E}_{z\sim q} [ \log p_\theta(x|z)p(z) - \log q_{\phi}(z|x) ] \nonumber \\<br>= &amp; \ \mathbb{E}_{z\sim q} [ \log p_\theta(x|z) + \log p(z) - \log q_{\phi}(z|x) ] \nonumber \\<br>= &amp; \ \mathbb{E}_{z\sim q} [ \log p_\theta(x|z) - \log \frac{q_{\phi}(z|x)}{p(z)} ] \nonumber \\<br>= &amp; \ \mathbb{E}_{z\sim q} [ \log p_\theta(x|z) ] - D(q_{\phi}(z|x)||p(z))  \\<br>\end{align}<br>$$</p><p>在式子（3）中，可以看到最终的两项分别对应了生成器和编码器：1）第一项$\mathbb{E}_{z\sim q} [ \log p_\theta(x|z) ]$的意思是，给定隐式向量$z$，生成器重构出真实观测值$x$的概率应当最大，重构出其他无关观测值的概率应当最小（因为我们是最大化ELBO），注意是采若干个$z\sim q$，对应若干个$x$，算期望；2）第二项$- D(q_{\phi}(z|x)||p(z))$，其实就是最小化KL散度$D(q_{\phi}(z|x)||p(z))$，也就是给定观测值$x$，编码器的编码的隐式向量$z$应当服从其先验概率分布$p(z)$。</p><p>与$p(x)$不同，隐式向量$z$是编码器学出来的，因此其概率分布可以预设。而$p(x)$是与数据观测值$x$有关，是一个自然分布，无法进行有效的预设，只能尝试拟合。因此，可以将先验概率分布设为标准高斯分布$\mathcal{N}(0, \mathrm{I})$。</p><p>当然，仔细看过的学习者会发现：不对啊，根据前面变分推断的分析，我最初设立$q_\phi(z|x)$的初衷是去拟合后验概率分布$p(z|x)$的，怎么这里又要去与一个先验概率分布$p(z)$拉近呢，这不是矛盾了吗？事实上，在一些场景里面，这会引发“后验塌陷”问题，也就是在学习过程中，$q_\phi(z|x)$过于接近先验分布$p(z)$，而不接近真实的后验分布$p(z|x)$。相当于直接将观测样本“死记硬背”，映射到标准高斯分布$\mathcal{N}(0, \mathrm{I})$里面，至于编码就不怎么学了。</p><p>这种情况可以通过多种方式解决：1）修改ELBO的优化目标，既然ELBO有两项，就可以调整加权，例如$\beta$-VAE使用$\beta&gt;1$来鼓励模型更多地使用隐式状态$z$，而不是直接去$p(z)$里映射<sup class="refplus-num"><a href="#ref-Beta-VAE">[4]</a></sup>；2）修改先验分布，防止过拟合；3）修改模型架构，例如递归VAE<sup class="refplus-num"><a href="#ref-Recursive-VAE">[5]</a></sup>。</p><h2 id="重参数化技巧-Reparameterization"><a href="#重参数化技巧-Reparameterization" class="headerlink" title="重参数化技巧 Reparameterization"></a>重参数化技巧 Reparameterization</h2><p>对于式子（3）的ELBO，将其转换为编码器和解码器的损失函数。对于编码器对应的KL散度项，由于两者都是高斯函数：1）基于给定观测数据$x$，编码器预测了高斯函数的均值方差参数$q_\phi(z|x) = \mathcal{N}(z;\mu_\phi(x), \mathrm{\Sigma}_\phi(x))$，2）先验概率分布是标准高斯$q(z)=\mathcal{N}(z; 0, \mathrm{I})$。所以，直接代入高斯函数的KL散度公式：</p><p>$$<br>\begin{align}<br>&amp; D(\mathcal{N}(\mu_0, \mathrm{\Sigma}_0) || \mathcal{N}(\mu_1, \mathrm{\Sigma}_1)) \nonumber \\<br>&amp; = \frac{1}{2}(\mathrm{tr}(\mathrm{\Sigma_1}^{-1}\mathrm{\Sigma_0})  + (\mu_1 - \mu_0)^\top\mathrm{\Sigma_1^{-1}}(\mu_1-\mu_0) \nonumber \\<br>&amp; - \mathrm{K} + \log \frac{\mathrm{det}\mathrm{\Sigma_1}}{\mathrm{det}\mathrm{\Sigma_0}}) \nonumber \\<br>\end{align}<br>$$</p><p>$$<br>\begin{align}<br>&amp; D(q_\phi(z|x)||p(z)) = \frac{1}{2}(\mathrm{tr}(\mathrm{\Sigma_\phi(x)})  + \mu_\phi(x)^\top\mu_\phi(x) \nonumber \\<br>&amp; - \mathrm{K} + \log (\mathrm{det}\mathrm{\Sigma_\phi(x)})) \nonumber \\<br>\end{align}<br>$$</p><p>其中，$\mathrm{K}$是隐式向量$z$的维度大小。不得不说，这公式具体怎么来的，我也没推导过。可以看到式子可微，通过反向传播能更新参数，问题不大。</p><p>对于解码器对应的最大化重建项，将重建结果的概率$p_\theta(x|z)$也建模为一个高斯分布$p_\theta(x|z) = \mathcal{N}(x; \mu_\theta(z), \sigma^2\mathrm{I})$，$\sigma$为定值，这样求$\log (\cdot)$之后，有：</p><p>$$<br>\log p_\theta(x|z) = -\mathrm{C}\Vert x-\mu_\theta(z) \Vert^2 + \mathrm{D}<br>$$</p><p>其中，$\mathrm{C}$和$\mathrm{D}$都是与$\theta$无关的常数项。因此，在后续反向传播求梯度时，只需要求解$\nabla_\theta \Vert x-\mu_\theta(z) \Vert^2$，就是真实观测值$x$与基于$z$的重建结果$\mu_\phi(z)$算L2-范数。但是，真正的最大化重建项是一个期望$\mathbb{E}_{z\sim q_\phi} [ \log p_\theta(x|z) ]$，需要在编码器预测的高斯分布$q_\phi(z|x) = \mathcal{N}(z;\mu_\phi(x), \mathrm{\Sigma}_\phi(x))$上多次采样，这个多次前向采样的过程，是无法通过反向传播，从而一路更新到编码器这边（相当于是要根据解码器输出的均值方差$\mu_\phi(x)$，$\mathrm{\Sigma}_\phi(x)$，新建一个高斯分布）。</p><p><img src="/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/reparameterization.png" alt="reparameterization"></p><center>红框内就是无法回传梯度，需要新建高斯分布进行随机采样的环节<br>可以看到重参数之后，编码器预测的均值方差$\mu_\phi(x)$，$\mathrm{\Sigma}_\phi(x)$，能够收到梯度。<a href="https://www.bilibili.com/video/BV1Ns4y1J7tK?t=462.7">视频截图</a>来自B站<sup class="refplus-num"><a href="#ref-Bilibili-VAE">[2]</a></sup></center><p><br></p><p>那么就需要避免这种新建高斯分布进行随机采样的操作。如上图的右半图所示，重参数技巧选择在一个标准高斯分布上采样，然后让采样的结果与编码器预测的均值方差$\mu_\phi(x)$，$\mathrm{\Sigma}_\phi(x)$，进行线性变换，从而得到与直接在编码器输出的高斯分布上采样等效的结果，还能传梯度到编码器（黑框和黑线）。</p><h2 id="在Neural-ODE中的应用-Application-in-Neural-ODE"><a href="#在Neural-ODE中的应用-Application-in-Neural-ODE" class="headerlink" title="在Neural ODE中的应用 Application in Neural ODE"></a>在Neural ODE中的应用 Application in Neural ODE</h2><p>想要了解VAE在Neural ODE中的应用，最直观的肯定是看pipeline和学习目标ELBO。很巧的是，陈天琦团队在2019年NeurIPS发表的Neural ODE续作Latent ODE<sup class="refplus-num"><a href="#ref-Latent-ODE">[6]</a></sup>中，应该是作者们特别设计了排版，让pipeline和学习目标放在了同一页相邻的地方。这篇文章其实和Neural ODE也就左半边编码器Encoder不一样（一个是RNN，一个是ODE-RNN），所以我们直接看Latent ODE的图：</p><p><img src="/2023/12/30/Notes-About-Neural-ODE-and-Beyond-1/latent-ode.png" alt="latent-ode"></p><p>可以看到，这个ELBO式子（9）可以说是和前面的式子（3）一模一样，也是对生成器（ODESolve的红色部分）最大化重构项，以及最小化编码器（ODE-RNN的绿色部分）输出的高斯分布（图正中间的$\mu$和$\sigma$）与先验分布的KL散度。</p><p>但是需要注意的是，这也继承了VAE的任务特性：一方面，训练的过程是自监督的，观测数据既作为输入，也作为重构目标，如果观测数据的数量以及内容偏少，学习的实际效果是难以保证的（例如直接观测数据点太少的情况）；另一方面，隐式状态的表达形式是高斯分布的参数，虽然它相比于自编码的黑盒向量更加显式，但还不是我们想要的与客观世界对应的、结构化的内在状态（例如类别、阶段、变化等）。</p><p>而且，这也并不是Neural ODE的特殊之处，把左右两边的编解码器，全部换成RNN或者Transformer，其实也能对时序数据的隐式状态进行建模。而Neural ODE真正的优势，简而言之，正是Latent ODE的标题：不均匀采样的时间序列，而这就要等到下次笔记了。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul id="refplus"><li id="ref-Bilibili-VI" data-num="1">[1]  车库里的老锤.【15分钟】了解变分推理.  https://www.bilibili.com/video/BV1Gs4y157BU</li><li id="ref-Bilibili-VAE" data-num="2">[2]  车库里的老锤.【15分钟】了解变分自编码器. https://www.bilibili.com/video/BV1Ns4y1J7tK</li><li id="ref-Neural-ODE" data-num="3">[3]  Chen R T Q, Rubanova Y, Bettencourt J, et al. Neural ordinary differential equations[J]. Advances in neural information processing systems, 2018, 31.</li><li id="ref-Beta-VAE" data-num="4">[4]  Higgins I, Matthey L, Pal A, et al. beta-vae: Learning basic visual concepts with a constrained variational framework[C]//International conference on learning representations. 2016.</li><li id="ref-Recursive-VAE" data-num="5">[5]  Kim M, Pavlovic V. Recursive inference for variational autoencoders[J]. Advances in Neural Information Processing Systems, 2020, 33: 19632-19641.</li><li id="ref-Latent-ODE" data-num="6">[6]  Rubanova Y, Chen R T Q, Duvenaud D K. Latent ordinary differential equations for irregularly-sampled time series[J]. Advances in neural information processing systems, 2019, 32.</li></ul><p><br></p><blockquote><p>感谢阅读！在2023年的最后一天，终于写好了这篇笔记！<br>也是时隔多年，再次在博客里发一篇技术文章，令人万分感慨。<br>如有意见和建议，欢迎通过首页的联系方式联系作者。<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>    <style>    #refplus, #refplus li{         padding:0;        margin:0;        list-style:none;    }；    </style>    <script src="https://unpkg.com/@popperjs/core@2"></script>    <script src="https://unpkg.com/tippy.js@6"></script>    <script>    document.querySelectorAll(".refplus-num").forEach((ref) => {        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');        let refel = document.querySelector(refid);        let refnum = refel.dataset.num;        let ref_content = refel.innerText.replace(`[${refnum}]`,'');        tippy(ref, {            content: ref_content,        });    });    </script>    ]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reading Report on Relation-Shape Convolutional Neural Network for Point Cloud Analysis in CVPR2019</title>
      <link href="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/"/>
      <url>/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/</url>
      
        <content type="html"><![CDATA[<p>本文是2019年5月《模式识别》专业课的读书报告</p><p>主要内容是在阅读中国科学院自动化所模式识别国家重点实验室刘永成团队的CVPR2019会议论文（oral）<br>《用于3D点云分析的形状关系卷积神经网络》过程中的个人理解、要点摘录以及收获和感悟。</p><span id="more"></span><blockquote><p>中文标题：CVPR2019《Relation-Shape Convolutional Neural Network for Point Cloud Analysis》读书报告</p></blockquote><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>该论文《Relation-Shape Convolutional Neural Network for Point Cloud Analysis》，即《用于3D点云分析的形状关系卷积神经网络》，是由中国科学院自动化所模式识别国家重点实验室15级在读博士刘永成团队提交的CVPR 2019会议论文。该论文现已入选并拟为会议现场演讲论文。作为IEEE主办的计算机视觉、模式识别和人工智能领域的国际顶级会议，CVPR 2019将于今年6月16~20日在美国加州召开。</p><p>论文提出了一种根据局部点之间的几何拓扑关系作为特征进行处理的新型卷积神经网络，从而实现对3D点云的模式识别。基于针对传统2D图像的CNN，该论文提出了扩展到3D点云的Relation-Shape CNN。该方法对¬局部点云子集选取中心点作为采样点，通过对采样点与其他点的几何关系让卷积层从几何关系向量中学习一个高维的映射函数，从而得到了能够对3D点的空间分布进行显示推理的卷积结果，进而有区分度地反映其隐含的3D形状。</p><p>Relation-Shape CNN方法在三个主流的点云分析任务上均实现了行业内领先的优秀性能。除此之外，该方法不仅可以从点云中学习3D形状特征，还能从点云的2D投影空间中推理3D形状特征。</p><p>笔者（注：以下代表本读书报告作者）看到，近年来，卷积神经网络已经在2D图像这类规则数据的模式识别处理中获得了相当大的成功，而该论文在将卷积神经网络网络扩展到3D点云这类不规则数据的研究方面走出了一大步。</p><h3 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h3><p>目前，在3D点云模式识别领域的很多研究工作是集中在将卷积神经网络在识别现有网格数据（例如图像）的成功模式复制到3D点云上，例如将3D点云转化为一般的体元（voxel）或者转化为简单的多视图平面图像等。这些方法都将导致3D点云内在蕴含的复杂几何细节信息的损失。</p><p>对此，笔者也十分肯定，传统的2D图像与3D点云的区别相当巨大，在2D图像上的旧有模式识别方法往往不能很好地适合对3D点云的处理。<br>为了直接处理点云数据，PointNet对每个点进行学习并从全局角度提取最终的特征，这种方式却忽略了局部结构，而局部结构已经被证明在图像卷积网络中提取高维度视觉特征的过程中的重要性。为了解决这个问题，一些基于取样和体元（例如Superpoint）的方法被提了出来，它们在一定程度上建立在全局到局部的语义关系的学习上。但是这些方法十分依赖于对于局部点集的高效感知学习，这是十分难以达成的。</p><p>笔者在自己个人的实践过程中，也感受到了这一点，对于一类具体的模式识别问题，单纯地依赖现有方法框架的学习效率和训练得出模型的识别效果，其最终的整体性能是相当差的，因为这忽略了很多重要的先验知识，这些先验知识能够通过指导对数据结构、网络结构上的改进来提升整体性能。<br>总体上，对于一组3D点云P的识别目前存在着3类挑战：</p><ol><li>P往往是无序的，因此需要卷积得到的表征能够满足置换排列的不变性，在笔者看来，也就是说对于某一种特定的排列方式应当能够在其出现在整组点云的任意位置上的情况下被识别出来，也就是对点的输入顺序不敏感。</li><li>P是分布在3D空间中的，因此需要卷积得到的表征能够对于例如旋转、偏移变换等常见的几何刚体变换具有语义上的不变性。</li><li>P事实上组成了一个特定形状，因此，卷积网络需要具备有区分度的“形状意识”，笔者认为这正意味着需要从各点之间的几何关系推理出其表示的3D形状这一能力，因此才引出了论文的主要思路：根据局部点之间的几何拓扑关系作为特征进行学习的方法。</li></ol><p>论文表示：问题（1）已经能够通过对称函数很好地解决，然而问题（2）、（3）都需要进行全新的研究工作。这一项研究工作的主要目的就是将一般的2D网格CNN扩展到能够解决以上问题的特殊结构上。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-1.png" alt="pic-1"></p><center>图1 点云与点云所表示的潜在形状之间的关系</center><p>对于图1，笔者看到，论文根据该图能够说明只有讨论局部的点与点之间的几何拓扑关系，才能够获取3D点云所表示的各个局部所代表的潜在形状关系。<br>综上所述，笔者认为，正如论文在问题提出中的思路，基于关键的先验知识和对于当前问题研究总体进展的把握，使用一定的数学、计算理论工具对系统结构进行改进，是当前研究工作的重要思路。</p><h3 id="论文成果"><a href="#论文成果" class="headerlink" title="论文成果"></a>论文成果</h3><p>论文提出了一种根据局部点之间的几何拓扑关系作为特征进行处理的新型卷积神经网络RS-CNN（Relation-Shape Convolutional Neural Network）。该方法的关键在于对点之间的几何拓扑关系进行学习，这种学习方式能够对3D点云中存在内在意义的形状信息进行编码。</p><p>特别地，对于整体点云的每个局部的卷积都通过选取该局部点云的中心采样点和其邻居点集构建。然后，这一卷积权重结果被用于学习一般认为是低维的采样点与邻居点集之间的关系在高维度上的表征。通过这一卷积方式，我们就能够获取到对点所在的空间层面的、具有明确推理过程的感知表征。这些感知表征有区分度地反映了特定点集模式构成的潜在形状，从而实现了形状的感知。不仅如此，这些表征能够在各种几何先验知识条件下，包括置换排列的不变性、对于网格数据变换的鲁棒性（例如，旋转和偏移等）。</p><p>通过将这些卷积作为基本操作，我们能够构建出一个多层的类似于CNN的深度神经网络架构：RS-CNN。这一架构能够实现在点云分析的过程中进行语义形状感知学习。</p><p>之后，论文总结了目前取得的关键成果：</p><ul><li>提出了一个基于形状学习的新型卷积操作：形状关系卷积。它能够明确地对点之间的几何关系的进行编码，从而得到了良好的形状感知能力和鲁棒性。</li><li>提出了一个通过多层形状关系卷积构建的神经网络架构RS-CNN。它能够扩展传统的CNN到为实现点云的语义形状感知学习而构造的特殊架构上。</li><li>通过3种具有挑战性的性能评测以及经验性、理论性的分析，展示RS-CNN达到了行业领先的优秀性能。</li></ul><p>论文还在接下来的相关研究（Related Work）中提到了取得以上成果所基于的行业内目前的研究成果。例如：</p><ul><li>基于3D到2D视图变换的方法、3D形状向3D表面网格变换的方法。</li><li>对3D点云使用深度学习。例如PointNet、PointNet++系列框架，后者开始注意到对于局部结构特征的学习，此外还有Superpoint将点云的部分转化为几何体元，Graph Convolution Network将局部的点云绘制成平面图像进行处理，但以上研究均未考虑到局部点云中点之间的3D空间关系，还有一些将点云映射为高维空间以适应经典CNN应用的研究、以及一些对点云的几何特性例如排列不变性、3D变换的鲁棒性的研究。</li><li>关系学习。通过对关系的学习进而得到数据相关的权重的研究、尤其是在3D点云中对于点之间关系的学习在业界已经获得了相当的进展，但大部分研究均没有考虑到局部点之间关系的学习，这也为本论文提出的方法提供了思路。</li></ul><p>笔者看到，论文作者的研究方向选取是建立在对大量业内相关研究的深刻理解和分析上的。若没有对3D点云分析的整体研究方向具有如此深刻的把握，基本上很难在该领域选取到一个较好的研究方向。</p><p>这也可以在作者的GitHub仓库上看出，作者建立了一个GitHub仓库，收集了自2017年以来的点云分析的重要研究文献资料（笔者注：地址为 <a href="https://github.com/Yochengliu/awesome-point-cloud-analysis">https://github.com/Yochengliu/awesome-point-cloud-analysis</a> ）。这说明了研读相关领域内的重要文献是科研工作的重要组成部分之一，而科研工作取得的成果也基于对前人研究的分析和思考。</p><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>在算法实现方面，论文首先讨论了形状感知的表征学习。论文指出，点云分析的关键就在于有区分度地表示出具有鲁棒性的潜在形状。在这里我们使用基于上下文的形状感知表征学习，通过将传统的网格CNN扩展到一种新型的形状关系卷积（RS-Conv）上来达成这一目的。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-2.png" alt="pic-2"></p><center>图2 RS-Conv的概要图</center><p>对于图2，论文解释如下：对于中心样本点$x_i$每一个邻居点$x_j$的卷积权重$w_{ij}$，都通过对在预设定的几何关系向量$h_{ij}$（即中心样本点$x_i$与每一个邻居点$x_j$构成的向量）得到的映射Μ中转换得到。</p><p>通过这种方式，感知卷积表征 $\sigma(A({ w_{ij}∙f_{x_j},∀x_j }))$（此处的 $f_{x_j}$ 为对于 $x_j$ 的一个特征向量，事实上就是 $x_j$ 的坐标位置等信息）就能够具有表现力地推理出每个点的空间层级，最终得到了高判别度的形状感知能力。正如在图像CNN中那样，进一步的通道数提升的映射被用来产生一个更加强大的形状感知表征。</p><p>笔者认为，如图中所示，通过通道数逐步提高的多层感知机（MLP，事实上可以认为是卷积核大小与输入大小相同的CNN）的处理，能够从低维度提取更多的细节特征到更高的维度，从而更加能够更好地识别局部点集构成的潜在形状特征。<br>论文进一步介绍了形状关系卷积的算法推理过程，如下所示。</p><h4 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h4><p>为了实现局部卷积的归纳学习，我们将局部点云子集$P_{sub}⊂\mathbb{R}^3$建模为一个建模为一个球形邻域，该邻域的中心点为采样点$x_i$，其余点作为$x_i$的邻居点$x_j∈N(x_i )$。在该邻域上，我们构建了一个一般性的卷积操作方法：</p><p>$$<br>\begin{equation}<br>f_{P_{sub}}=\sigma(A({ T(f_{x_j}),∀x_j })),d_{ij} &lt; r,∀x_j∈N(x_i)<br>\end{equation}<br>$$</p><p>笔者看到，以上一般卷积操作方法中特征变换函数Τ事实上就是神经元模型中的判别函数（最简单的形式即权重向量与特征向量的点乘），该操作方法也同样具有非线性的激活函数，而与普通的神经元不同的是：聚合函数函数$A$，这一函数应当是论文为了能够将整个局部邻域的特征进行聚合从而生成一份单一特征的，从而满足将点云格式的特征转码为经典CNN能够处理的特征格式。</p><h4 id="经典CNN的限制"><a href="#经典CNN的限制" class="headerlink" title="经典CNN的限制"></a>经典CNN的限制</h4><p>在经典的网格CNN中，特征变换函数实现为：</p><p>$$Τ(f_{x_j} )=w_j∙f_{x_j}$$</p><p>其中$w_j$为学习得出的卷积权重，$f_{x_j}$为对于点$x_j$的一个特征向量，点乘符号 ∙ 表示按元素相乘。该卷积方法在点云数据上直接使用会存在两个缺陷：1）由于$w_j$不与其他点共享参数，因此该卷积对于输入点集不具有置换排列不变性。2）在反向传播中，$w_j$的梯度仅与孤立点$x_j$相关，因此该卷积难以捕捉到点间关系。</p><h4 id="转换：基于关系的学习"><a href="#转换：基于关系的学习" class="headerlink" title="转换：基于关系的学习"></a>转换：基于关系的学习</h4><p>为了克服上述问题，我们将卷积转换为从几何关系中学习。在方法上，我们将$w_j$替换为$w_{ij}$，并让$w_{ij}$从中心样本点$x_i$与每一个邻居点$x_j$构成的几何关系向量$h_{ij}$中学习一个高维的映射函数$M$。该过程可以描述为：</p><p>$$<br>\begin{equation}<br>Τ(f_{x_j})=w_{ij} ∙ f_{x_j}=M(h_{ij})∙f_{x_j}<br>\end{equation}<br>$$</p><p>其中，映射函数$M$的目标是从几何先验中学习一个高维的、有表现力的关系表达，以编码 3D 点集的空间布局，这里我们使用共享的多层感知机（MLP）实现映射函数$M$。以这种方式，$w_j$巧妙地转换为$w_{ij}$，它的梯度由预定义的几何先验关系向量$h_{ij}$决定，且与点$x_i$和$x_j$均几何相关。于是，公式$(1)$中的$f_{P_{sub}}$变为：</p><p>$$<br>\begin{equation}<br>f_{P_{sub}}=σ(A({M(h_{ij} )∙f_{x_j},∀x_j }))<br>\end{equation}<br>$$</p><p>该卷积方法聚集了点$x_i$和所有邻居点$x_j∈N(x_i)$之间的几何关系表达，因此可以对3D 点的空间分布进行显式的推理，进而有区分力的反映其隐含的 3D 形状。其中几何先验$h_{ij}$可以灵活设置，因为使用多层感知机实现的映射函数M能将$h_{ij}$映射为高维的关系向量，以实现与特征$f_{x_j}$进行通道对齐。</p><p>笔者看到，论文所描述的共享参数就是几何先验性地让$w_{ij}$从中心样本点$x_i$与每一个邻居点$x_j$构成的几何关系向量$h_{ij}$之中的中心样本点$x_i$。通过$w_{ij}$描述$x_i$与每一个邻居点$x_j$的关系而非$x_j$这孤立一点的权重，将局部点集所描述的整个潜在形状用$x_i$这一共享参数进行相对位置的描述，而非直接使用每一个邻居点$x_j$的绝对位置进行描述，从而从本质上赋予了这一方法置换排列不变性。</p><h4 id="通道数提升的映射"><a href="#通道数提升的映射" class="headerlink" title="通道数提升的映射"></a>通道数提升的映射</h4><p>从公式$(3)$中可以看出，$f_{P_{sub}}$对应的通道数量是等于$f_{x_j}$特征向量的。这与经典的图像CNN中，为了能够获得更加抽象的表征而降低图像分辨率，从而增加通道数量的做法不同。因此，如图2的中间部分所示，我们添加了一个基于多层感知机的通道数提升映射来实现这一方法。</p><p>之后，论文介绍了RS-Conv这一新型卷积操作的4个特性：</p><ul><li>置换排列不变性。在映射函数$M(h_{ij})$中，低维的关系$h$和多层感知机$M$都能够实现对点输入顺序的置换排列不变性，因为它们描述的是样本点与邻居点的相对位置关系，对输入顺序不敏感。再加之聚合函数$A$使用的是对称函数，能够在整体上实现置换排列不变性。</li><li>对于网格变换的鲁棒性。因为低维的关系$h$描述的是基于3D欧式距离的相对位置关系，因此对于旋转、平移等变换操作具有鲁棒性。</li><li>点间关系的互动。RS-Conv的方法创新性地提出了不是对一个孤立的点进行学习而是对点间关系进行学习。</li><li>权重的共享，在该方法中这是一个关键的特性，通过对不同的特定点集使用相同的学习函数实现更好地鲁棒性并降低学习的复杂度。在公式$(3)$中，对称函数$A$、共享的多层感知机$M$、以及预先设定的几何先验$h$都独立于特定的点集结构的制约，满足了这一特性。</li></ul><p>论文进一步讨论了RS-Conv在经典2D网格卷积方面进行应用的能力。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-3.png" alt="pic-3"></p><center>图3 使用3×3卷积核的经典2D网格卷积示意图</center><p>如图3所示，在2D网格卷积中我们可以注意到，$w_j$总是隐含着$x_i$与$x_j$的一个固定的位置关系，也就是说，$w_j$在学习过程中同样和在RS-Conv一样受到了相对位置关系的限制，实际上编码了一种规则的网格关系。因此，论文提出的形状关系卷积方法具有通用性，同样也能够建模经典的2D网格卷积。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-4.png" alt="pic-4"></p><center>图4 应用于点云分类（a）和点云物体分割（b）的RS-CNN结构。<br><br>其中N为点云中点的总数，C为通道数。<br></center><p>不仅如此，论文也提到了基于RS-Conv构成的多层卷积神经网络RS-CNN的结构，可以说与经典的CNN极为类似。如图4所示，在点云分类中，由于需要输出对于每一种分类的预测概率，使用了若干层全连接层；而在点云物体分割中，和经典的图像语义分割一样，对于每一层都进行的大范围的连接，从而对多层学习到的表征成功地通过特征传播方法（feature propagation）进行上采样（笔者注：unsample，上采样的作用是能够将特征点还原到源输入格式的空间，例如像素空间或3D点空间，从而达到像素、3D点级别的预测），完成逐个像素或点的预测分割操作。</p><p>最后，论文提到RS-Conv和RS-CNN的一些实现细节。</p><ul><li>RS-Conv的实现。使用的激活函数依然是经典的ReLU函数。在映射函数M中，使用了三层的共享MLP来实现随机连续的映射。低纬度关系h_ij通过10通道的向量定义，格式为（3D欧式距离, $x_i-x_j$, $x_i$，$x_j$），通道数1+3+3+3=10。通道数提升映射使用了单层的MLP实现。而每一层MLP都使用了批归一化（笔者注：batch normalization，能够将每次输入的数据分布进行规范化，让其均匀分布在当前层上，从而加速神经网络的训练速度、防止过拟合）。</li><li>用于点云分析的RS-CNN。采样中心点一般选取在距离点云原点最远的的点。在局部点云邻域中，固定数目的邻居点作为一个批次batch进行卷积操作，同时也采取归一化操作来保持领域的中心不变。为了能够实现高效的学习，我们强制RS-CNN学习高于3种不同尺度（笔者注：一般是不同范围上的，虽然邻域本身的球型半径相同，但是学习时选取的领域子集范围可以不同）的邻域关系，但是学习结束之后由于使用的是同一组MLP，因此分享同一份权重，因此与多尺度分组学习（Multi-Scale Grouping, MSG）针对不同尺度生成的多份权重不同。RS-CNN基于PyTorch实现，具体参数此处省略。</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>为了验证RS-CNN的有效性，论文作者在在主流的点云分析任务上进行了测试，包括点云分类、部件分割和法向预测。</p><p>ModelNet40上的点云分类结果如表1所示，在仅使用3D坐标和1k个稀疏点作为输入的情况下，RS-CNN仍然实现了最佳分类效果（93.6%的精度）。<br>同样，如图5所示，RS-CNN在给出点数不断随机减少的过程中，分类的准确率下降速度是同类方法中最慢的。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/table-1.png" alt="table-1"></p><center>表1 ModelNet40上的形状分类测试结果</center><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-5.png" alt="pic-5"></p><center>图5 3D点云的点数随机减少过程中不同方法的准确率变化</center><p>ShapeNet part上的部件分割效果示意图如图6所示。如表2所示，尽管点云所形成的形状多种多样，并且很容易产生混淆，RS-CNN依然可以准确地将部件分割出来。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/table-2.png" alt="table-2"></p><center>表2 ShapeNet part上的形状部件分割测试结果</center><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-6.png" alt="pic-6"></p><center>图6 形状部件分割测试效果</center><p>ModelNet40上的法向预测结果如图7所示。与PointNet以及PointNet++相比，RS-CNN可以取得更加准确的法向预测结果，偏移程度明显较其他模型更小。尽管如此，论文表示，RS-CNN仍然难以有效推理棘手的形状，比如旋转楼梯（可以从图中看出偏移程度较大）以及错综复杂的植物。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-7.png" alt="pic-7"></p><center>图7 ModelNet40上的法向预测结果</center><p>由于公式（3）中的几何先验$h_{ij}$可以灵活地定义，因此论文在ModelNet40上测试了五个比较直观的例子，结果如表6所示。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/table-6.png" alt="table-6"></p><center>表6 不同的几何先验结构对于准确率的影响</center><p>可以看到，仅仅使用3D欧式距离作为低维几何关系（model A），RS-CNN依然能够取得92.5%的精度，这是十分令人印象深刻的。而其他的几何先验结构也同样得出了较好的精度。<br>此外，为了测试RS-CNN的几何形状推理能力，我们强制置零某一维的坐标值，即将3D点云投影到2D空间（model E，图9），如表12所示，得到的分类精度均接近92.2。这证明了RS-CNN不仅可以从3D点云中学习3D形状，还能从2D投影空间中推理3D形状。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/pic-8.png" alt="pic-8"></p><center>图8 将3D点云投影到XY、XZ、YZ等2D平面上</center><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/table-12.png" alt="table-12"></p><center>表12 识别3D点云的不同方向2D投影的准确率</center><p>为了验证所提出的RS-Conv的鲁棒性，论文设置几何先验$h_{ij}$为3D欧式距离，然后在ModelNet40上进行鲁棒性测试，结果如表7所示。<br>虽然几何关系能够做到旋转不变，但网络初始输入的特征仍然会受到旋转的影响。针对这一问题，我们引入法向将每一个局部点集旋转到以法向和采样点确定的局部坐标系中，实现了旋转不变。但该旋转会给形状识别带来困难，因此分类精度会有所下降。</p><p><img src="/2019/06/30/Reading-Report-on-Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis-in-CVPR2019/table-7.png" alt="table-7"></p><center>表7 通过测试旋转、偏移等操作对于分类精度的影响<br><br>验证论文提出的RS-Conv的鲁棒性<br></center><p>其他的测试还有模型简化测试（Ablation Study），对于对称函数A、映射函数M的选取等，RS-CNN在以上测试中均获得了优秀的结果。此处由于篇幅限制，暂且省略。<br>综上，笔者看到，RS-CNN以其具有创新性的对于局部点云的点间几何关系的先验知识作为特征进行学习的优良特性，在使用了类似于经典CNN的网络结构的前提下，依然能够获得相当优良的测试结果。这体现了先验知识作为另一种研究方向的关键作用。</p><h3 id="收获体会"><a href="#收获体会" class="headerlink" title="收获体会"></a>收获体会</h3><p>阅毕全文，笔者看到，论文不同于以往研究中对于深度神经网络的层数等结构特征进行改造，而考虑了3D点云内在的几何先验知识，从而成功地针对这些几何先验知识构造出了新的卷积操作形状关系卷积RS-Conv。而且，使用这一全新卷积操作的、类似经典CNN结构的RS-CNN，能够在实验性能对比上超越相当多的对于深度神经网络结构改造的方法。</p><p>可以说，这是一次先验知识本质研究相对于经验性结构改造的成功。也正因为该方法在结构上与经典CNN类似，在一定程度上使得对于深度神经网络接触不是特别深入的笔者，在阅读论文过程中遇到的理解上的障碍相对较小。通过阅读本篇论文，笔者有以下的收获体会：</p><ul><li><p>一种全新的研究思路。笔者认为，论文专注于研究问题中先验知识而非经验性地改造网络结构的思路，对于其他在现有深度神经网络框架下基于复杂不规则数据问题的适配和改进工作，具有很大的启发性。本论文以3D点云特有的几何先验知识为切入点，根据先验知识的指导对经典卷积操作的进行合理改进，在使用类似经典CNN的网络结构的前提下，取得了业界领先的性能测试结果，这是一个基于先验知识改进神经网络基本结构的全新研究思路。</p></li><li><p>模式识别、深度学习相关论文的基本格式和专业术语。在阅读过程中，笔者进一步巩固了之前已经了解的卷积层、全连接层、多层感知机（MLP）、批归一化（batch normalization）、激活函数、判别函数等专业术语的基本原理和功能作用，并进一步接触了一篇模式识别、深度学习顶级会议论文的基本格式：</p><p>1) 简介Introduction提出并解释问题，回顾研究领域内的现有成果，并简要给出自己的方法；<br>2) 相关研究Related Work说明了自己给出的方法是基于哪些现有研究成果；<br>3) 接下来的章节应当具体描述自己给出的方法所用到的数学建模、算法推导、基本结构、特性、实现细节等，全方面地描述这一方法的实现思路；<br>4) 实验测试Experiment通过具体的性能测试结果，图表文结合地来考察该方法的具体性能；<br>5) 结论Conclusion总结上文的要点，通过结论来说明文首简介中提及的内容是得到准确论证的。</p></li></ul><ul><li><p>论文写作、排版和文字表达的技巧。在阅读论文的过程中，笔者获得了较好的阅读体验，不存在过多的阅读理解上的障碍，不仅说明了论文本身提出的方法在结构上类似于经典CNN，比较容易理解，而且也说明了作者的论文写作技巧、排版技巧以及文字表达能力是十分优秀的，这也是值得笔者学习的地方。</p></li><li><p>进一步深入研究的方向。笔者看到，论文仅仅是在类似经典的CNN网络结构上便取得了相当重大的成果，那么是否能够通过对神经网络的结构以及卷积单元的进一步改造从而让该方法的综合性能更上一层楼，便成为了进一步深入研究的方向。</p></li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>论文《Relation-Shape Convolutional Neural Network for Point Cloud Analysis》地址：<br><a href="https://arxiv.org/abs/1904.07601">https://arxiv.org/abs/1904.07601</a></li><li>论文作者刘永成的中文分享：<br><a href="https://mp.weixin.qq.com/s/Jso2YZs2NEtMORZsLkrJ5w">https://mp.weixin.qq.com/s/Jso2YZs2NEtMORZsLkrJ5w</a></li><li>论文作者建立的2017年以来点云分析的重要研究文献资料GitHub仓库：<br><a href="https://github.com/Yochengliu/awesome-point-cloud-analysis">https://github.com/Yochengliu/awesome-point-cloud-analysis</a></li><li>中文解读：<br><a href="http://www.ijiandao.com/2b/baijia/250710.html">http://www.ijiandao.com/2b/baijia/250710.html</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Training DeepID1 Network for Face Comparison with Google Colab+Tensorflow</title>
      <link href="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/"/>
      <url>/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/</url>
      
        <content type="html"><![CDATA[<p>本文由2019年6月《软件工程》必修课的课程设计报告的AI部分改编</p><p>主要介绍了“员工考勤管理系统”课程设计中的员工人脸打卡子系统<br>该系统使用了Google CoLab提供的在线Tensorflow GPU平台训练得到的DeepID人脸特征提取比对模型，<br>以及基于该模型搭建的Tensorflow+OpenCV+Flask人脸比对Python服务器</p><span id="more"></span><blockquote><p>中文标题：使用Google CoLab+Tensorflow训练DeepID1人脸比对模型</p></blockquote><h3 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h3><ol><li><a href="https://colab.research.google.com/drive/1BKcLNYjffhhQEWQErclZMojsjBpTViSq">Google CoLab</a>（需要访问国外网站的能力）</li><li>GitHub（待发布）</li></ol><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/deepid.png" alt="deepid"></p><center>图1.1 DeepID的网络结构<br>其中DeepID层能够提取出160维特征向量<br><br></center><p>DeepID是香港中文大学王晓刚教授团队在CVPR2014上发表的论文《Deep Learning Face Representation from Predicting 10,000 Classes》提出的方法，全称为Deep hidden IDentity feature（DeepID）。</p><p>该方法是一种特征提取的算法，对于一个多层卷积-池化网络进行多分类任务训练后，在其中一层中间层DeepID层能够提取出输入的任意人脸图片的160维深层次特征向量（实际上是160x2x60维的特征向量）。</p><p>而这种特征提取的能力是面向任意的（需要经过预先裁剪和对齐后的）人脸图像的，因此作者做出了一个形象的比喻：即使是分10000个类，网络也能够有效区分出每个类别的人脸的显著特征（从而通过特征之间的距离，识别出两张人脸是否为同一人）。</p><p>因此，这一方法体现出的以下特性，使得我们最终在众多人脸特征提取方法中选取了DeepId:</p><ol><li>方法实现的<strong>仅需一次训练即可获得的人脸特征提取能力</strong>，十分适合企业员工人脸考勤环境下员工人脸库经常性变动、待对比人脸图像来源较为复杂的应用场景。</li><li>方法的<strong>网络结构简单，易于理解和实现。同时，网络层数较少，</strong>相应地也能够减少训练所消耗的时间和硬件资源，便于我们在短周期（8周，AI子系统开发仅一周）的软件工程课程设计开发过程中安排进度。最终，该算法的训练时长在Google CoLab上为50000次/2小时。</li><li>方法的<strong>准确率较高</strong>，在Tensorflow的实现+YouTube Aligned Faces数据集上的测试集人脸比对识别准确率能够达到96%。</li></ol><p>当然，这一方法作为一个2014年提出的方法，（也是DeepID三代中的第一个版本）也存在着一定的缺陷：</p><ol><li><strong>仅适用于提取图像中的正脸</strong>，也就是通过摄像头正对人脸拍摄的、或者是通过一定图像处理算法重新对齐的人脸。对于侧脸、带有一定歪斜的人脸等日常生活中常见的人脸图像，识别能力大打折扣。<strong>也正因如此，GitHub上DeepID的Tensorflow实现采用了Youtube Aligned Faces数据集，已经做过了人脸对齐的预处理</strong>，用来训练DeepID较为方便。</li><li>在实际使用的过程中，笔者发现这一模型对于裁剪得出的人脸图像的<strong>光线明暗、是否佩戴眼镜</strong>等变化是敏感的，只有在光照条件、脸部配饰等状况近似于人脸图像采集时的情况下，才能够被识别为同一人。</li></ol><p>因此，目前主流的人脸特征比对方法都聚焦在人脸检测阶段的多特征点提取、侧脸特征点的重新对齐、人脸3D模型识别（一个最著名的案例，就是Apple在iPhone上用于FaceID的3D结构光特征点识别方案）等研究方向。<br>至于Google Colab，是谷歌打造的的一个在线深度学习平台，基于Jupyter Notebook+Tensorflow，能够通过简单的配置，使用Google免费提供的云端GPU资源，从而无需本地硬件资源地轻松训练自己的神经网络。在很久之前的一次计设校赛上曾经使用过这一平台，因此本项目也继续使用这个平台对DeepID网络进行训练。</p><h3 id="训练环境搭建"><a href="#训练环境搭建" class="headerlink" title="训练环境搭建"></a>训练环境搭建</h3><p>访问 <a href="https://colab.research.google.com，如果没有谷歌账号可以先去注册一个，列表中是已有的Jupyter">https://colab.research.google.com，如果没有谷歌账号可以先去注册一个，列表中是已有的Jupyter</a> Notebook文件，创建的文件一般会放在Google 云端硬盘的<code>/colab notebook</code>文件夹下。一般是创建Python 3笔记本，</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-1.png" alt="colab"></p><center>图2.1 Google Colab的初始界面</center><p>Colab的环境初始化结束后，呈现的是经典的jupyter notebook界面，先点击“代码执行程序-更改运行时类型”，将“硬件加速器”从“None”修改为“GPU”，这样就可以<strong>免费使用基于谷歌提供的云端Nvidia GTX Tesla T4 GPU的Tensorflow GPU版本，显存15GB</strong>，比自己笔记本的4G独显性能高多了。</p><p><strong>注意！千万不要选择TPU！</strong> </p><p>虽然TPU是Google推出的号称Tensorflow专用的GPU平台，但是其训练速度真的难以接受，在下文我会附上GPU和TPU训练DeepID网络时的Tensorboard检测到的数据，足以体现两者之间的性能差异。</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-2.png" alt="colab"></p><center>图2.2 在Colab选取GPU<br></center><p>之后可以在左侧边栏中，查看文件目录，会发现一个“挂在Google云端硬盘”的选项，点击之后就会生成一个cell。内容大致为<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行此单元格即可装载您的 Google 云端硬盘。</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&#x27;/content/drive&#x27;</span>)</span><br></pre></td></tr></table></figure></p><p>运行之后，会生成一个链接拿到Google 云端硬盘生成的授权码，输入到这个cell中，即可成功挂在你的Google 云硬盘。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Go to this URL <span class="keyword">in</span> a browser: https://accounts.google.com/o/oauth2/auth?....</span><br><span class="line"></span><br><span class="line">Enter your authorization code:</span><br><span class="line">··········</span><br><span class="line">Mounted at /content/drive</span><br></pre></td></tr></table></figure></p><p>之所以需要挂载Google云硬盘，是基于这样的考虑：</p><p>Google Colab有一个“防挖矿”机制，为了防止自己免费开放的GPU资源被矿工拿来挂机挖矿，Colab会自动回收那些运行了很久或者和网页端断线很久的项目的<strong>所有资源：包括GPU和所有文件</strong>。</p><p>因此尽量不要尝试在训练的过程中关闭浏览器，然后等时间到了再次打开浏览器查看结果，很有可能早已训练结束，模型文件已经生成，但是由于Colab的这个机制导致文件被删除。</p><p>所以在训练过程中，需要挂载Google 云端硬盘，<strong>将模型文件和训练生成的Tensorboard日志的路径放在云端硬盘里</strong>，就算谷歌回收了资源也能够及时保存。</p><p>但是，需要注意的是，<strong>数据集最好不要放在Google 云端硬盘里</strong>，因为网上有人试过了，Colab从Google云端硬盘上获取文件时不是直接读取文件系统，而是发送请求进行文件分块下载的，这个网络IO带来的延迟会极大地拖慢训练的速度。</p><p>此外，这个数据集直接上传到Google Colab上的速度也是堪忧。但是，值得称赞的是，<strong>在Colab里直接用Shell命令下载在线的数据集</strong>，速度极快，能够达到15M/s。以下是下载YouTube Aligned Faces数据集的输出，30秒完成~</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-3.png" alt="数据集下载"></p><center>图2.3 下载YouTube Aligned Faces数据集的输出</center><p>还有一个需要注意的地方，就是Colab上已经装好了Tensorflow 1.14、OpenCV以及matplot、numpy、PIL等深度学习常用的python库，若需要其他库也是直接执行shell命令pip install即可。<strong>这里的Tensorflow 1.14与目前常用的1.x版本相比，在API上有着许多区别</strong>，如果直接复制他人的代码，会出现许多的问题。</p><p>笔者也因此几乎是把GitHub上的DeepID实现从头开始添加中文注释和改写API，学到了很多搭建Tensorflow训练框架的相关API用法（例如session、variable和namescope），也算是继续了之前《人工智能》大作业的“注释阅读法”的个人习惯。</p><p>以上就是一些搭建Colab环境的注意事项，如果你已经看懂了这些，而且熟悉Jupyter Notebook，就可以开始着手编写训练代码了。</p><h3 id="编写训练代码"><a href="#编写训练代码" class="headerlink" title="编写训练代码"></a>编写训练代码</h3><h4 id="下载YouTube-Aligned-Faces数据集"><a href="#下载YouTube-Aligned-Faces数据集" class="headerlink" title="下载YouTube Aligned Faces数据集"></a>下载YouTube Aligned Faces数据集</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载youtube aligned face数据集</span></span><br><span class="line">!wget --http-user=wolftau --http-password=wtal997 http://www.cslab.openu.ac.il/download/wolftau/aligned_images_DB.tar.gz</span><br><span class="line"><span class="comment"># 解压下载的数据集</span></span><br><span class="line">!<span class="built_in">mkdir</span> -p data</span><br><span class="line">!tar -zxf aligned_images_DB.tar.gz -C Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/data</span><br></pre></td></tr></table></figure><h4 id="裁剪数据集图片"><a href="#裁剪数据集图片" class="headerlink" title="裁剪数据集图片"></a>裁剪数据集图片</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  此处开始为DeepID人脸特征提取、比对代码</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  来源为：https://github.com/jinze1994/DeepID1</span></span><br><span class="line"><span class="string">  主要工作：增加了详细中文注释、更新了部分tensorflow2.0的新API</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  crop.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  裁剪训练数据集图片，图片已经经过了对齐预处理</span></span><br><span class="line"><span class="string">  所谓对齐就是裁剪到只剩下人脸，且已经事先将带有倾斜的人脸对齐过了</span></span><br><span class="line"><span class="string">  因此此处只需裁剪并缩放到 (55,47) 的像素即可</span></span><br><span class="line"><span class="string">  这样的处理适合被检测对象配合、也就是主动进行识别的场景</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  crop_img_by_half_center</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  从1/4处开始裁剪1/2尺寸的图像并缩放</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crop_img_by_half_center</span>(<span class="params">src_file_path, dest_file_path</span>):</span><br><span class="line">    <span class="comment"># 打开图像</span></span><br><span class="line">    im = Image.<span class="built_in">open</span>(src_file_path)</span><br><span class="line">    <span class="comment"># 获取图像尺寸</span></span><br><span class="line">    x_size, y_size = im.size</span><br><span class="line">    <span class="comment"># 开始裁剪的坐标</span></span><br><span class="line">    start_point_xy = x_size / <span class="number">4</span></span><br><span class="line">    <span class="comment"># 裁剪结束时的坐标</span></span><br><span class="line">    end_point_xy   = x_size / <span class="number">4</span> + x_size / <span class="number">2</span></span><br><span class="line">    <span class="comment"># 生成方形框</span></span><br><span class="line">    box = (start_point_xy, start_point_xy, end_point_xy, end_point_xy)</span><br><span class="line">    <span class="comment"># 裁剪</span></span><br><span class="line">    new_im = im.crop(box)</span><br><span class="line">    <span class="comment"># 缩放为（55，47）</span></span><br><span class="line">    new_new_im = new_im.resize((<span class="number">47</span>,<span class="number">55</span>))</span><br><span class="line">    <span class="comment"># 保存</span></span><br><span class="line">    new_new_im.save(dest_file_path)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  walk_through_the_folder_for_crop</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  遍历数据集文件夹，进行图像的处理，生成目标文件夹</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">walk_through_the_folder_for_crop</span>(<span class="params">aligned_db_folder, result_folder</span>):</span><br><span class="line">    <span class="comment"># 若不存在目标文件夹，新建一个</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(result_folder):</span><br><span class="line">        os.mkdir(result_folder)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开每一个youtube人物文件夹</span></span><br><span class="line">    <span class="keyword">for</span> people_folder <span class="keyword">in</span> os.listdir(aligned_db_folder):</span><br><span class="line">        src_people_path = aligned_db_folder + people_folder + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        dest_people_path = result_folder + people_folder + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        <span class="comment"># 创建每一个人物文件夹对应的目标文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest_people_path):</span><br><span class="line">            os.mkdir(dest_people_path)</span><br><span class="line">        <span class="comment"># 打开每一个人物文件夹下的视频文件夹</span></span><br><span class="line">        <span class="keyword">for</span> video_folder <span class="keyword">in</span> os.listdir(src_people_path):</span><br><span class="line">            src_video_path = src_people_path + video_folder + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">            dest_video_path = dest_people_path + video_folder + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">            <span class="comment"># 创建每一个视频文件夹对应的目标文件夹 </span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest_video_path):</span><br><span class="line">                os.mkdir(dest_video_path)</span><br><span class="line">            <span class="comment"># 对于每一个视频文件夹下的图片文件，进行处理</span></span><br><span class="line">            <span class="keyword">for</span> img_file <span class="keyword">in</span> os.listdir(src_video_path):</span><br><span class="line">                src_img_path = src_video_path + img_file</span><br><span class="line">                dest_img_path = dest_video_path + img_file</span><br><span class="line">                crop_img_by_half_center(src_img_path, dest_img_path)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  裁剪模块的主程序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 数据集路径和目标文件夹路径</span></span><br><span class="line">    aligned_db_folder = <span class="string">&quot;data/aligned_images_DB&quot;</span></span><br><span class="line">    result_folder = <span class="string">&quot;data/crop_images_DB&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> aligned_db_folder.endswith(<span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">        aligned_db_folder += <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result_folder.endswith(<span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">        result_folder += <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    <span class="comment"># 开始处理</span></span><br><span class="line">    walk_through_the_folder_for_crop(aligned_db_folder, result_folder)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="分割数据集为训练集、验证集和测试集"><a href="#分割数据集为训练集、验证集和测试集" class="headerlink" title="分割数据集为训练集、验证集和测试集"></a>分割数据集为训练集、验证集和测试集</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  split.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">   对剪裁后的数据集文件按照 8:1:1 的规模进行切分，分别作为训练集、验证集和测试集。</span></span><br><span class="line"><span class="string">   每个人保留固定数目的图片（100张）进行训练。</span></span><br><span class="line"><span class="string">   为生成测试集，对每个人构造 5 对同一个人的图片 pair，再构造 5 对不同人的图片 pair，作为测试集。</span></span><br><span class="line"><span class="string">   一个pair作为每次测试时输入的组合，用来测试同一个人是否能正确匹配、不同人是否能够分出不同的人脸比对效果</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  fatch_pics_for_one_user</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  获取一个youtube用户的所有图片</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fatch_pics_for_one_user</span>(<span class="params">people_path</span>):</span><br><span class="line">    people_imgs = []</span><br><span class="line">    <span class="comment"># 从文件夹中遍历</span></span><br><span class="line">    <span class="keyword">for</span> video_folder <span class="keyword">in</span> os.listdir(people_path):</span><br><span class="line">        <span class="keyword">for</span> video_file_name <span class="keyword">in</span> os.listdir(os.path.join(people_path, video_folder)):</span><br><span class="line">            people_imgs.append(os.path.join(people_path, video_folder, video_file_name))</span><br><span class="line">    random.shuffle(people_imgs)</span><br><span class="line">    <span class="keyword">return</span> people_imgs</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  build_dataset</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  创建训练集、验证集和测试集</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">src_folder</span>):</span><br><span class="line">    <span class="comment"># 总人数，总图片张数</span></span><br><span class="line">    total_people, total_picture = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment"># 测试用户列表、验证集、训练集</span></span><br><span class="line">    test_people, valid_set, train_set = [], [], []</span><br><span class="line">    <span class="comment"># 标签数量</span></span><br><span class="line">    label = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用户文件夹遍历</span></span><br><span class="line">    <span class="keyword">for</span> people_folder <span class="keyword">in</span> os.listdir(src_folder):</span><br><span class="line">        <span class="comment"># 获取一个youtube用户的所有图片</span></span><br><span class="line">        people_imgs = fatch_pics_for_one_user(os.path.join(src_folder, people_folder))</span><br><span class="line">        total_people += <span class="number">1</span></span><br><span class="line">        total_picture += <span class="built_in">len</span>(people_imgs)</span><br><span class="line">        <span class="comment"># 若数量在100张以内，则全部放入测试用户列表</span></span><br><span class="line">        <span class="comment"># 保证测试集中的用户不会出现在训练集和验证集中</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(people_imgs) &lt; <span class="number">100</span>:</span><br><span class="line">            test_people.append(people_imgs)</span><br><span class="line">        <span class="comment"># 否则分割到验证集和训练集中，1:9</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_set += <span class="built_in">zip</span>(people_imgs[:<span class="number">10</span>], [label]*<span class="number">10</span>)</span><br><span class="line">            train_set += <span class="built_in">zip</span>(people_imgs[<span class="number">10</span>:<span class="number">100</span>], [label]*<span class="number">90</span>)</span><br><span class="line">            label += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 测试集</span></span><br><span class="line">    test_set = []</span><br><span class="line">    <span class="comment"># 从测试用户列表中，构造5对同一个人的照片、5对不同人的照片</span></span><br><span class="line">    <span class="keyword">for</span> i, people_imgs <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_people):</span><br><span class="line">        <span class="comment"># 5对同一个人的照片</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            same_pair = random.sample(people_imgs, <span class="number">2</span>)</span><br><span class="line">            test_set.append((same_pair[<span class="number">0</span>], same_pair[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 5对不同人的照片</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            j = i;</span><br><span class="line">            <span class="keyword">while</span> j == i:</span><br><span class="line">                j = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(test_people)-<span class="number">1</span>)</span><br><span class="line">            test_set.append((random.choice(test_people[i]), random.choice(test_people[j]), <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打乱各个数据集的顺序</span></span><br><span class="line">    random.shuffle(test_set)</span><br><span class="line">    random.shuffle(valid_set)</span><br><span class="line">    random.shuffle(train_set)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出各数据集的统计信息</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\tpeople\tpicture&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;total:\t%6d\t%7d&#x27;</span> % (total_people, total_picture))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;test:\t%6d\t%7d&#x27;</span> % (<span class="built_in">len</span>(test_people), <span class="built_in">len</span>(test_set)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;valid:\t%6d\t%7d&#x27;</span> % (label, <span class="built_in">len</span>(valid_set)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;train:\t%6d\t%7d&#x27;</span> % (label, <span class="built_in">len</span>(train_set)))</span><br><span class="line">    <span class="keyword">return</span> test_set, valid_set, train_set</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  set_to_csv_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  保存到csv文件中</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_to_csv_file</span>(<span class="params">data_set, file_name</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data_set:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, item)), file=f)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  数据集切分模块的主程序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    random.seed(<span class="number">7</span>)</span><br><span class="line">    <span class="comment"># 原始数据集路径以及各数据集保存列表文件</span></span><br><span class="line">    src_folder     = <span class="string">&quot;data/crop_images_DB&quot;</span></span><br><span class="line">    test_set_file  = <span class="string">&quot;data/test_set.csv&quot;</span></span><br><span class="line">    valid_set_file = <span class="string">&quot;data/valid_set.csv&quot;</span></span><br><span class="line">    train_set_file = <span class="string">&quot;data/train_set.csv&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> src_folder.endswith(<span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">        src_folder += <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    </span><br><span class="line">    test_set, valid_set, train_set = build_dataset(src_folder)</span><br><span class="line">    set_to_csv_file(test_set,  test_set_file)</span><br><span class="line">    set_to_csv_file(valid_set, valid_set_file)</span><br><span class="line">    set_to_csv_file(train_set, train_set_file)</span><br></pre></td></tr></table></figure><h4 id="向量化数据集，便于读取"><a href="#向量化数据集，便于读取" class="headerlink" title="向量化数据集，便于读取"></a>向量化数据集，便于读取</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  vec.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  将数据格式化为向量形式，存入 data/dataset.pkl。便于训练时直接从该文件读取数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  vectorize_imgs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">  将图像向量化，事实上就是将图像转化为浮点数格式的数组</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vectorize_imgs</span>(<span class="params">img_path</span>):</span><br><span class="line">    <span class="keyword">with</span> Image.<span class="built_in">open</span>(img_path) <span class="keyword">as</span> img:</span><br><span class="line">        arr_img = np.asarray(img, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> arr_img</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  read_csv_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  读取csv文件</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_csv_file</span>(<span class="params">csv_file</span>):</span><br><span class="line">    x, y = [], []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(csv_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            path, label = line.strip().split()</span><br><span class="line">            x.append(vectorize_imgs(path))</span><br><span class="line">            y.append(<span class="built_in">int</span>(label))</span><br><span class="line">    <span class="keyword">return</span> np.asarray(x, dtype=<span class="string">&#x27;float32&#x27;</span>), np.asarray(y, dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  read_csv_pair_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  读取成对数据（也就是一个label对应两张图）的csv文件</span></span><br><span class="line"><span class="string">  事实上就是读取测试集数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_csv_pair_file</span>(<span class="params">csv_file</span>):</span><br><span class="line">    x1, x2, y = [], [], []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(csv_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            p1, p2, label = line.strip().split()</span><br><span class="line">            x1.append(vectorize_imgs(p1))</span><br><span class="line">            x2.append(vectorize_imgs(p2))</span><br><span class="line">            y.append(<span class="built_in">int</span>(label))</span><br><span class="line">    <span class="keyword">return</span> np.asarray(x1, dtype=<span class="string">&#x27;float32&#x27;</span>), np.asarray(x2, dtype=<span class="string">&#x27;float32&#x27;</span>), np.asarray(y, dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  向量化主程序，将csv文件转换为pkl文件</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>      </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    testX1, testX2, testY = read_csv_pair_file(<span class="string">&#x27;data/test_set.csv&#x27;</span>)</span><br><span class="line">    validX, validY = read_csv_file(<span class="string">&#x27;data/valid_set.csv&#x27;</span>)</span><br><span class="line">    trainX, trainY = read_csv_file(<span class="string">&#x27;data/train_set.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(testX1.shape, testX2.shape, testY.shape)</span><br><span class="line">    <span class="built_in">print</span>(validX.shape, validY.shape)</span><br><span class="line">    <span class="built_in">print</span>(trainX.shape, trainY.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 导入向量化的数据到pkl文件中</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/dataset.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(testX1, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(testX2, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(testY , f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(validX, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(validY, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(trainX, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(trainY, f, pickle.HIGHEST_PROTOCOL)</span><br></pre></td></tr></table></figure><h4 id="运行tensorboard监视训练过程"><a href="#运行tensorboard监视训练过程" class="headerlink" title="运行tensorboard监视训练过程"></a>运行tensorboard监视训练过程</h4><p>在经过了以上漫长的数据集裁剪、分割和向量化过程（第1、2步各需要20分钟）之后，就开始了训练。这里可以选用Colab内置的Tensorboard进行训练过程的监视。首先需要升级，否则无法读取训练过程中生成的日志文件。</p><p>在实际使用过程中，<strong>若训练生成的日志放在了Colab的文件目录中</strong>，Tensorboard在训练开始后过一段时间会与训练程序断开连接，<br>因此同样需要将训练程序代码中的日志文件路径设为Google 云端硬盘的路径。这样就算掉线了也能够在本地运行一个Tensorboard，手动下载Google 云端硬盘上不断更新的日志文件进行监视（或者有下载Google云端硬盘的客户端，可以使用文件夹同步功能实时更新本地的日志文件）。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  训练之前，运行tensorboard监视训练过程</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  尝试了无数次，读不到日志文件，无论是绝对路径还是相对路径</span></span><br><span class="line"><span class="string">  在mac上本地查看日志文件，是能用的，</span></span><br><span class="line"><span class="string">  后来发现升级一下tensorboard就好了，</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级，升级后首次使用会报错，清除一下报错里面提示的info文件即可</span></span><br><span class="line"><span class="comment"># !pip install --upgrade tensorboard</span></span><br><span class="line"><span class="comment"># !rm /tmp/.tensorboard-info/pid-*.info</span></span><br><span class="line"></span><br><span class="line">%reload_ext tensorboard</span><br><span class="line">%tensorboard --logdir <span class="string">&quot;/content/drive/My Drive/Colab Notebooks/deepid/log&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="训练DeepID网络"><a href="#训练DeepID网络" class="headerlink" title="训练DeepID网络"></a>训练DeepID网络</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  deepid1.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  DeepID网络训练主程序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  load_data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  从pkl向量文件中导出数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/dataset.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        testX1 = pickle.load(f)</span><br><span class="line">        testX2 = pickle.load(f)</span><br><span class="line">        testY  = pickle.load(f)</span><br><span class="line">        validX = pickle.load(f)</span><br><span class="line">        validY = pickle.load(f)</span><br><span class="line">        trainX = pickle.load(f)</span><br><span class="line">        trainY = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> testX1, testX2, testY, validX, validY, trainX, trainY</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入向量数据</span></span><br><span class="line">testX1, testX2, testY, validX, validY, trainX, trainY = load_data()</span><br><span class="line"><span class="comment"># 类型数量=训练集数量，也就是认为每一个训练集数据均为一类</span></span><br><span class="line"><span class="comment"># 因为本网络只负责特征提取而非分类，所以可以这么做</span></span><br><span class="line">class_num = np.<span class="built_in">max</span>(trainY) + <span class="number">1</span></span><br><span class="line"><span class="comment"># 清除一下当前的作用域</span></span><br><span class="line">tf.reset_default_graph();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  weight_variable</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  初始化权重，shape事实上是卷积核尺寸</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weight_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;weights&#x27;</span>):</span><br><span class="line">        <span class="comment"># 从截断的正态分布中输出随机值，以初始化权重。</span></span><br><span class="line">        <span class="keyword">return</span> tf.Variable(tf.truncated_normal(shape, stddev=<span class="number">0.1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  bias_variable</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  初始化偏置，也就是wx+b中的b，bias</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bias_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;biases&#x27;</span>):</span><br><span class="line">        <span class="comment"># 使用全零向量初始化偏置</span></span><br><span class="line">        <span class="keyword">return</span> tf.Variable(tf.zeros(shape))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  Wx_plus_b</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  求wx+b</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Wx_plus_b</span>(<span class="params">weights, x, biases</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;Wx_plus_b&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.matmul(x, weights) + biases</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  nn_layer</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  n*n的全连接层，可选激活函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nn_layer</span>(<span class="params">input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu</span>):</span><br><span class="line">    <span class="comment"># 进入对应层的命名空间</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">        <span class="comment"># 权重</span></span><br><span class="line">        weights = weight_variable([input_dim, output_dim])</span><br><span class="line">        <span class="comment"># 偏置</span></span><br><span class="line">        biases = bias_variable([output_dim])</span><br><span class="line">        <span class="comment"># 预激活</span></span><br><span class="line">        <span class="comment"># 可以这么翻译，个人认为是激活前的预处理</span></span><br><span class="line">        preactivate = Wx_plus_b(weights, input_tensor, biases)</span><br><span class="line">        <span class="comment"># 若传入了激活函数，则让它激活</span></span><br><span class="line">        <span class="keyword">if</span> act != <span class="literal">None</span>:</span><br><span class="line">            activations = act(preactivate, name=<span class="string">&#x27;activation&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> activations</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则就输出预激活量</span></span><br><span class="line">            <span class="keyword">return</span> preactivate</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  conv_pool_layer</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  卷积+池化层，在deepid中一共有3层</span></span><br><span class="line"><span class="string">  也可以定制only_conv=True来满足deepid第四层只有卷积</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  卷积：局部感知，基于相邻部分的相关性原理；权值共享、因此可以设计多核卷积</span></span><br><span class="line"><span class="string">  池化：这里使用最大池化，则说明是提取显著特征</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_pool_layer</span>(<span class="params">x, w_shape, b_shape, layer_name, act=tf.nn.relu, only_conv=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">        W = weight_variable(w_shape)</span><br><span class="line">        b = bias_variable(b_shape)</span><br><span class="line">        <span class="comment"># 输入到卷积层</span></span><br><span class="line">        conv = tf.nn.conv2d(</span><br><span class="line">            <span class="comment"># 输入x和卷积核W的大小、权重</span></span><br><span class="line">            x, W, </span><br><span class="line">            <span class="comment"># 卷积步长，tf中前后两个1不能改，中间两个为水平滑动和垂直滑动步长</span></span><br><span class="line">            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], </span><br><span class="line">            <span class="comment"># VALID方式丢弃小于窗口大小的</span></span><br><span class="line">            <span class="comment"># SAME方式相反会填充到窗口大小</span></span><br><span class="line">            padding=<span class="string">&#x27;VALID&#x27;</span>, </span><br><span class="line">            name=<span class="string">&#x27;conv2d&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        h = conv + b</span><br><span class="line">        <span class="comment"># 加入偏置，激活</span></span><br><span class="line">        relu = act(h, name=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> only_conv == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">return</span> relu</span><br><span class="line">        <span class="comment"># 若存在池化层则再进行池化</span></span><br><span class="line">        <span class="comment"># ksize参数确定了池化窗口大小</span></span><br><span class="line">        <span class="comment"># 值得注意的是这里的最大池化没有使用激活函数，也就是仅仅提取线性的显著特征</span></span><br><span class="line">        pool = tf.nn.max_pool(relu, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;VALID&#x27;</span>, name=<span class="string">&#x27;max-pooling&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> pool</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  accuracy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  在验证集上测试阶段的准确度计算，由模型预测值和实际值计算得出</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_estimate, y_real</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;accuracy&#x27;</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;correct_prediction&#x27;</span>):</span><br><span class="line">            <span class="comment"># 在测试阶段的准确度计算</span></span><br><span class="line">            correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;accuracy&#x27;</span>): </span><br><span class="line">            <span class="comment"># 对每个批次计算总的准确度均值</span></span><br><span class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        <span class="comment"># 记录准确度信息</span></span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;accuracy&#x27;</span>, accuracy)  </span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  train_step</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  训练梯度，也就是需要计算梯度下降了</span></span><br><span class="line"><span class="string">  这里采用了ADAM优化器，其他优化器的特征：</span></span><br><span class="line"><span class="string">  Momentum冲量算法增加冲量、</span></span><br><span class="line"><span class="string">  Adagrad对低频变化的参数以更大步长更新、</span></span><br><span class="line"><span class="string">  RMSProp更新时只更新梯度平方的期望（移动的均值）</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  ADAM优化器对梯度的一阶矩估计（均值）和二阶矩估计（方差）两个方面适应性调节</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">loss</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">        <span class="comment"># 初始学习率1e-4，之后同样会动态调整，一般是逐步衰减，减少趋近最优时的震荡</span></span><br><span class="line">        <span class="comment"># minimize才是更新梯度，之前是计算梯度</span></span><br><span class="line">        <span class="keyword">return</span> tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入，tf.placeholder为形参，在执行时再赋具体的值</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;input&#x27;</span>):</span><br><span class="line">    h0 = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">55</span>, <span class="number">47</span>, <span class="number">3</span>], name=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, class_num], name=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第1个卷积-池化层，4x4，当前通道数3，卷积核数量（下一层通道数）20，偏置大小20</span></span><br><span class="line">h1 = conv_pool_layer(h0, [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">20</span>], [<span class="number">20</span>], <span class="string">&#x27;Conv_layer_1&#x27;</span>)</span><br><span class="line"><span class="comment"># 第2个卷积-池化层，3x3，当前通道数20，卷积核数量40，偏置大小40</span></span><br><span class="line">h2 = conv_pool_layer(h1, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">40</span>], [<span class="number">40</span>], <span class="string">&#x27;Conv_layer_2&#x27;</span>)</span><br><span class="line"><span class="comment"># 第3个卷积-池化层，3x3，当前通道数40，卷积核数量60，偏置大小60</span></span><br><span class="line">h3 = conv_pool_layer(h2, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">40</span>, <span class="number">60</span>], [<span class="number">60</span>], <span class="string">&#x27;Conv_layer_3&#x27;</span>)</span><br><span class="line"><span class="comment"># 第4个卷积层，2x2，当前通道数60，卷积核数量80，偏置大小80</span></span><br><span class="line">h4 = conv_pool_layer(h3, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">60</span>, <span class="number">80</span>], [<span class="number">80</span>], <span class="string">&#x27;Conv_layer_4&#x27;</span>, only_conv=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后一个deepid层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;DeepID1&#x27;</span>):</span><br><span class="line">    <span class="comment"># deepid层直接与第3层相连，</span></span><br><span class="line">    <span class="comment"># 使用reshape能够拉平这两层的输出为1维数组</span></span><br><span class="line">    <span class="comment"># -1即为任意维，后跟的是每一维度实际尺寸大小，</span></span><br><span class="line">    <span class="comment"># 该大小即为整个层所有神经元个数（比实际还偏大一点），因此是拉平了的</span></span><br><span class="line">    h3r = tf.reshape(h3, [-<span class="number">1</span>, <span class="number">5</span>*<span class="number">4</span>*<span class="number">60</span>])</span><br><span class="line">    <span class="comment"># deepid层与第4层相连</span></span><br><span class="line">    h4r = tf.reshape(h4, [-<span class="number">1</span>, <span class="number">4</span>*<span class="number">3</span>*<span class="number">80</span>])</span><br><span class="line">    <span class="comment"># 初始化两次相连的权重</span></span><br><span class="line">    W1 = weight_variable([<span class="number">5</span>*<span class="number">4</span>*<span class="number">60</span>, <span class="number">160</span>])</span><br><span class="line">    W2 = weight_variable([<span class="number">4</span>*<span class="number">3</span>*<span class="number">80</span>, <span class="number">160</span>])</span><br><span class="line">    b = bias_variable([<span class="number">160</span>])</span><br><span class="line">    <span class="comment"># 直接带权重一起相加</span></span><br><span class="line">    h = tf.matmul(h3r, W1) + tf.matmul(h4r, W2) + b</span><br><span class="line">    <span class="comment"># relu激活</span></span><br><span class="line">    h5 = tf.nn.relu(h)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失函数</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">    <span class="comment"># n*n的全连接层，将拉平的第3、4层全连接到一个160个神经元的全连接层上</span></span><br><span class="line">    y = nn_layer(h5, <span class="number">160</span>, class_num, <span class="string">&#x27;nn_layer&#x27;</span>, act=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># softmax层</span></span><br><span class="line">    <span class="comment"># 1. 将logits（也就是输入y），计算为（0，1）范围的概率值</span></span><br><span class="line">    <span class="comment"># 2. 计算损失loss，这里计算的是交叉熵损失，y_认为是对应的标签</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      增加Soft-max layer的输出数量（即分类数，或识别的个体数）可以提升人脸验证的准确率。</span></span><br><span class="line"><span class="string">      即分类的类别数越多，DeepConv-Net学到的DeepID特征（160维）越有效。</span></span><br><span class="line"><span class="string">      此外，作者强调用于人脸验证的一定是160维长度的DeepID特征，而不是Softmax Layer的输出。</span></span><br><span class="line"><span class="string">      如果用SoftmaxLayer输出的结果（例如用4348个不同人的数据训练DeepID,Softmax输出是4348维）</span></span><br><span class="line"><span class="string">      进行人脸验证特征，采用联合贝叶斯人脸验证方法得到的准确率约为66%，而神经网络人脸验证方法则完全失效</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">      摘录自：https://www.cnblogs.com/venus024/p/5632243.html</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">      笔者（本人）注：可以说这个神经网络只是利用了多分类训练（可以在代码中看出同一个人的类别标签还是相同的）的形式，</span></span><br><span class="line"><span class="string">      训练神经网络在提取特征时的权重参数，从而达到提取特征、加以比对的目的</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = y, labels = y_))</span><br><span class="line">    <span class="comment"># 记录当前损失</span></span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;loss&#x27;</span>, loss)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化精确度</span></span><br><span class="line">accuracy = accuracy(y, y_)</span><br><span class="line"><span class="comment"># 初始化优化器</span></span><br><span class="line">optimizer = train_step(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并所有的记录，给session用来回调运行</span></span><br><span class="line">merged = tf.summary.merge_all()  </span><br><span class="line"><span class="comment"># 保存模型的回调</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  训练主函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取一个batch的输入</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_batch</span>(<span class="params">data_x, data_y, start</span>):</span><br><span class="line">        end = (start + <span class="number">1024</span>) % data_x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> start &lt; end:</span><br><span class="line">            <span class="keyword">return</span> data_x[start:end], data_y[start:end], end</span><br><span class="line">        <span class="keyword">return</span> np.vstack([data_x[start:], data_x[:end]]), np.vstack([data_y[start:], data_y[:end]]), end</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># 注意，trainX和trainY为具体数据和标签</span></span><br><span class="line">        data_x = trainX</span><br><span class="line">        data_y = (np.arange(class_num) == trainY[:,<span class="literal">None</span>]).astype(np.float32)</span><br><span class="line">        validY = (np.arange(class_num) == validY[:,<span class="literal">None</span>]).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 日志文件目录</span></span><br><span class="line">        logdir = <span class="string">&#x27;/content/drive/My Drive/Colab Notebooks/deepid/log&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> tf.gfile.Exists(logdir):</span><br><span class="line">            tf.gfile.DeleteRecursively(logdir)</span><br><span class="line">        tf.gfile.MakeDirs(logdir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建训练线程</span></span><br><span class="line">        sess = tf.Session()</span><br><span class="line">        <span class="comment"># 初始化所有参数，开始训练</span></span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="comment"># 写入训练日志和测试日志</span></span><br><span class="line">        train_writer = tf.summary.FileWriter(logdir + <span class="string">&#x27;/train&#x27;</span>, sess.graph)</span><br><span class="line">        test_writer = tf.summary.FileWriter(logdir + <span class="string">&#x27;/test&#x27;</span>, sess.graph)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始训练，训练次数50000次</span></span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50001</span>):</span><br><span class="line">            <span class="comment"># 获取一个batch的输入</span></span><br><span class="line">            batch_x, batch_y, idx = get_batch(data_x, data_y, idx)</span><br><span class="line">            <span class="comment"># 优化器</span></span><br><span class="line">            _ = sess.run(optimizer, &#123;h0: batch_x, y_: batch_y&#125;)</span><br><span class="line">            <span class="comment"># 运行，h0赋值为batchX，也就是图像，y_赋值为batch_y，也就是标签</span></span><br><span class="line">            summary = sess.run(merged, &#123;h0: batch_x, y_: batch_y&#125;)</span><br><span class="line"></span><br><span class="line">            train_writer.add_summary(summary, i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 每100次进行验证集测试</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                summary = sess.run(merged, &#123;h0: validX, y_: validY&#125;)</span><br><span class="line">                test_writer.add_summary(summary, i)</span><br><span class="line">            <span class="comment"># 每5000次保存一次模型</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">5000</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                saver.save(sess, <span class="string">&#x27;/content/drive/My Drive/Colab Notebooks/deepid/checkpoint/%05d.ckpt&#x27;</span> % i)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里展示一下tensorboard采集的使用TPU（由于速度过慢，未训练完）和Tesla T4 GPU（2小时训练结束）的进行50000次训练的准确率和损失率图表：</p><p>对于TPU：</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc.png" alt="TPU-acc"></p><center>图2.4 TPU训练时的准确度统计图</center><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc-1.png" alt="TPU-acc-1"></p><center>图2.5 TPU训练时的准确度与耗时（放大后）</center><p>可以看出TPU训练时的准确度上升缓慢，而且过了3个小时后，准确度仍然在0.6，而且才训练了不到4k次。</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss.png" alt="TPU-loss"></p><center>图2.6 TPU训练时的损失率统计图</center><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss-1.png" alt="TPU-loss-1"></p><center>图2.7 TPU训练时的损失率与耗时（放大后）</center><p>同样地，TPU训练时损失率下降也十分缓慢。</p><p>对于GPU：</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc.png" alt="GPU-acc"></p><center>图2.8 GPU训练时的准确度统计图</center><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc-1.png" alt="GPU-acc-1"></p><center>图2.9 GPU训练时的准确度与耗时（放大后）</center><p>可以看出TPU训练时的准确度上升呈对数曲线，在训练次数到15k~30k时就已经趋于稳定，在1小时27分时就已经结束了训练。</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss.png" alt="GPU-loss"></p><center>图2.10 GPU训练时的损失率统计图</center><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss-1.png" alt="GPU-loss"></p><center>图2.10 GPU训练时的损失率与耗时（放大后）</center><p>同样地，GPU训练时损失率下降也十分迅速。</p><p>综上，可以看出Google Colab提供的免费GPU性能十分地强劲，能够满足快速训练简单的深度学习模型的需求。这款GPU通过nvidia-smi命令查询的情况如下所示，据查，该款显卡的价格约两万元人民币，可以看出谷歌为了推广深度学习付出了巨大的成本。</p><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/nvidia-smi.png" alt="nvidia-smi"></p><center>图2.11 nvidia-smi命令得到的GPU信息：Tesla T4</center><h4 id="在测试集上使用模型文件预测，获取余弦距离阈值"><a href="#在测试集上使用模型文件预测，获取余弦距离阈值" class="headerlink" title="在测试集上使用模型文件预测，获取余弦距离阈值"></a>在测试集上使用模型文件预测，获取余弦距离阈值</h4><p>这里运行测试集除了检验模型的预测效果，更重要的是获取余弦距离的阈值，也就是<code>(true_mean + false_mean)/2</code>，意思是：小于同类组+不同类组的平均组内距离的两者平均（有点拗口，但是确实是以此为阈值）。根据这个阈值，就能判断任意两个人脸之间的距离代表的是同一个人还是不同的人。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  predict.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  预测模块，训练结束后即可使用模型文件预测</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine, euclidean</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  predict</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  预测</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">ckpt</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver.restore(sess, ckpt)</span><br><span class="line">        <span class="comment"># 计算测试集的两对数据特征值列表</span></span><br><span class="line">        h1 = sess.run(h5, &#123;h0: testX1&#125;)</span><br><span class="line">        h2 = sess.run(h5, &#123;h0: testX2&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算两个特征值列表对应两项的余弦距离</span></span><br><span class="line">    <span class="comment"># 事实上是1-余弦距离，距离越近，数值越小，符合直觉</span></span><br><span class="line">    <span class="comment"># 因此范围也从-1~1变为了0~2</span></span><br><span class="line">    pre_y = np.array([cosine(x, y) <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(h1, h2)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 求余弦距离阈值</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">part_mean</span>(<span class="params">x, mask</span>):</span><br><span class="line">        <span class="comment"># mask事实上是测试集的标签，若是testY，1就代表对应的两张图为同类，0为不同类，1-testY反之</span></span><br><span class="line">        <span class="comment"># 以testY为例，在这一乘法下，留下的非零项目即为同类项</span></span><br><span class="line">        z = x * mask</span><br><span class="line">        <span class="comment"># 同类组余弦距离总和/同类组数量</span></span><br><span class="line">        <span class="comment"># 对所有非零项目求和=同类组距离总和</span></span><br><span class="line">        <span class="comment"># 非零项目个数=同类组数量</span></span><br><span class="line">        <span class="comment"># 两者相除则为同类组的平均组内距离</span></span><br><span class="line">        <span class="comment"># 1-testY时则为不同类组的平均组内距离</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(np.<span class="built_in">sum</span>(z) / np.count_nonzero(z))</span><br><span class="line">    </span><br><span class="line">    true_mean = part_mean(pre_y, testY)</span><br><span class="line">    false_mean = part_mean(pre_y, <span class="number">1</span>-testY)</span><br><span class="line">    <span class="built_in">print</span>(true_mean, false_mean)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 筛选出pre_y也就是余弦距离结果中，符合小于同类组+不同类组的平均组内距离的两者平均这一条件的项目，与testY中的对应项目进行比对</span></span><br><span class="line">    <span class="comment"># 由于testY中对应项目为1也就是True的元素代表两张图为同类，因此当pre_y中元素小于这一条件时，也代表为同类</span></span><br><span class="line">    <span class="comment"># 反之，pre_y中的元素大于这一条件时，代表非同类</span></span><br><span class="line">    <span class="comment"># 所以最终得到的矩阵是一个同类、非同类的预测值与测试集标签之间的对应关系，只有正确的才能留下来</span></span><br><span class="line">    <span class="comment"># 对此计算均值，即可获取模型在测试集上的准确率</span></span><br><span class="line">    <span class="built_in">print</span>(np.mean((pre_y &lt; (true_mean + false_mean)/<span class="number">2</span>) == testY.astype(<span class="built_in">bool</span>)))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    预测主函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 输入模型路径</span></span><br><span class="line">    predict(<span class="string">&#x27;/content/drive/My Drive/Colab Notebooks/deepid/checkpoint/30000.ckpt&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="预测服务搭建"><a href="#预测服务搭建" class="headerlink" title="预测服务搭建"></a>预测服务搭建</h3><p>对于已经训练好的Tensorflow模型的预测服务搭建，在网络上有许多的方法，事实上最好的方法是使用frozen_graph工具对checkpoint进行固化处理，笔者这里是直接调用了checkpoint来恢复现场，事实上效果类似。<br>笔者在这里使用的是docker进行预测服务搭建，具体使用的镜像是<code>yoanlin/opencv-python3-tensorflow</code>，自带python3、opencv和tensorflow1.x。由于tensorflow仅仅是使用1.14生成的模型，所以不存在兼容性问题。<br>具体命令如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">docker pull yoanlin/opencv-python3-tensorflow</span><br><span class="line"><span class="comment"># 生成容器，配置端口映射和文件夹映射</span></span><br><span class="line"><span class="comment"># 8888端口是tensorboard，8080是flask</span></span><br><span class="line"><span class="comment"># faces文件夹映射为人脸图像路径，我是使用软工项目中的Spring boot来接收图像的，所以flask就没写接收代码，直接从文件路径里面取，server文件夹映射为flask的程序文件</span></span><br><span class="line">docker run -itd --name=tf-cv -p 7777:8888 -p 8081:8080 -v /tf-cv/faces:/faces -v /tf-cv/server/:/server yoanlin/opencv-python3-tensorflow</span><br><span class="line"><span class="comment"># 若需要进入镜像内部安装flask等其他python库，运行以下命令</span></span><br><span class="line">docker <span class="built_in">exec</span> -it tf-cv bash</span><br><span class="line"><span class="comment"># flask无法独立启动守护进程，需要使用gunicorn，其中gunicorn.conf.py写有基本配置，此处可自行搜索相关教程</span></span><br><span class="line">gunicorn app:app -c gunicorn.conf.py -D</span><br></pre></td></tr></table></figure><p>若需要部署到服务器，可以使用以下命令<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将容器提交为新的镜像</span></span><br><span class="line">docker commit tf-cv tf-cv:server</span><br><span class="line"><span class="comment"># 将新的镜像打包为tar压缩文件，之后用scp命令传到服务器上</span></span><br><span class="line">docker save &gt; tf-cv.tar tf-cv:server</span><br><span class="line"><span class="comment"># 在服务器上解压镜像</span></span><br><span class="line">docker load &lt; tf-cv.tar</span><br><span class="line"><span class="comment"># 再次使用docker run命令生成新的容器，并在新的容器内部运行flask，参见以上命令</span></span><br></pre></td></tr></table></figure></p><h3 id="编写预测代码"><a href="#编写预测代码" class="headerlink" title="编写预测代码"></a>编写预测代码</h3><h4 id="OpenCV人脸检测"><a href="#OpenCV人脸检测" class="headerlink" title="OpenCV人脸检测"></a>OpenCV人脸检测</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  HAAR特征检测人脸</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  用opencv的方式（HAAR特征）检测人脸，效果不是很好。</span></span><br><span class="line"><span class="string">  最优方案是MTCNN，需要人脸特征点数据集多次训练，比较繁琐</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detect_face</span>(<span class="params">img_path</span>):</span><br><span class="line">    <span class="comment"># 获取训练好的人脸参数数据，此处引用GitHub上的opencv库中的默认值</span></span><br><span class="line">    face_cascade = cv2.CascadeClassifier(<span class="string">r&#x27;/root/haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取图片，并处理成灰度图</span></span><br><span class="line">    image = cv2.imread(img_path)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 未读取到图片，返回</span></span><br><span class="line">    <span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;提示：未读取到图片&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换为灰度图像</span></span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># haar模型检测人脸</span></span><br><span class="line">    faces = face_cascade.detectMultiScale(</span><br><span class="line">        gray,</span><br><span class="line">        scaleFactor = <span class="number">1.15</span>,</span><br><span class="line">        minNeighbors = <span class="number">5</span>,</span><br><span class="line">        minSize = (<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">        flags = cv2.CASCADE_SCALE_IMAGE</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 未检测到人脸，返回</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(faces) &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;提示：未检测到人脸&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 裁剪人脸图像</span></span><br><span class="line">    face_images = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">        face_img = image[y:y+h, x:x+w]</span><br><span class="line">        face_images.append(face_img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若有多个人脸，则选出面积最大（也就是最靠前）的人脸</span></span><br><span class="line">    face_images = <span class="built_in">sorted</span>(face_images, key=<span class="keyword">lambda</span> img:img.size, reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换图像</span></span><br><span class="line">    face = Image.fromarray(face_images[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 缩放为（55，47）</span></span><br><span class="line">    resize_face = face.resize((<span class="number">47</span>,<span class="number">55</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换为array</span></span><br><span class="line">    <span class="keyword">return</span> np.asarray(resize_face)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Tensorflow人脸特征比对"><a href="#Tensorflow人脸特征比对" class="headerlink" title="Tensorflow人脸特征比对"></a>Tensorflow人脸特征比对</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> detector <span class="keyword">as</span> dt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  预测</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">src_img_path, dst_img_path</span>):</span><br><span class="line">    <span class="comment"># 对输入的图像分别检测人脸</span></span><br><span class="line">    src_image = dt.detect_face(src_img_path)</span><br><span class="line">    dst_image = dt.detect_face(dst_img_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若返回了错误信息，不再检测</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(src_image, <span class="built_in">str</span>):</span><br><span class="line">        <span class="keyword">return</span> src_image</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(dst_image, <span class="built_in">str</span>):</span><br><span class="line">        <span class="keyword">return</span> dst_image</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 载入tensorflow模型，开始检测</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver=tf.train.import_meta_graph(<span class="string">&#x27;/root/50000.ckpt.meta&#x27;</span>)</span><br><span class="line">        saver.restore(sess,<span class="string">&quot;/root/50000.ckpt&quot;</span>)</span><br><span class="line">        graph = tf.get_default_graph()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算160维的人脸特征</span></span><br><span class="line">        h1 = sess.run(<span class="string">&quot;DeepID1/Relu:0&quot;</span>, feed_dict=&#123;<span class="string">&quot;input/x:0&quot;</span>: [src_image]&#125;)</span><br><span class="line">        h2 = sess.run(<span class="string">&quot;DeepID1/Relu:0&quot;</span>, feed_dict=&#123;<span class="string">&quot;input/x:0&quot;</span>: [dst_image]&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算人脸之间的余弦距离（事实上是1-余弦），范围0~1，越小越接近</span></span><br><span class="line">        pre_y = np.array([cosine(x, y) <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(h1, h2)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在测试集上测试模型的过程中，得到了余弦距离的阈值为0.47189</span></span><br><span class="line">        <span class="comment"># 因此，比该阈值小的即为同一个人，大的则不是同一个人</span></span><br><span class="line">        <span class="keyword">return</span> &#123; <span class="string">&#x27;msg&#x27;</span>: &#123; <span class="string">&#x27;isSame&#x27;</span>: <span class="built_in">bool</span>((pre_y &lt; <span class="number">0.47189</span>)[<span class="number">0</span>]), <span class="string">&#x27;predict&#x27;</span>: pre_y[<span class="number">0</span>] &#125; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Flask后端服务器主程序"><a href="#Flask后端服务器主程序" class="headerlink" title="Flask后端服务器主程序"></a>Flask后端服务器主程序</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> predict.main <span class="keyword">import</span> predict</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/face&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello</span>():</span><br><span class="line">    data = json.loads(request.get_data(as_text=<span class="literal">True</span>))</span><br><span class="line">    src_face = data[<span class="string">&#x27;src_face&#x27;</span>]</span><br><span class="line">    dst_face = data[<span class="string">&#x27;dst_face&#x27;</span>]</span><br><span class="line">    res = predict(src_face, dst_face)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回一下两个人脸图像的路径，便于验证是否正确</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(res, <span class="built_in">str</span>):</span><br><span class="line">      <span class="keyword">return</span> jsonify(&#123; <span class="string">&#x27;success&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;msg&#x27;</span>: res, <span class="string">&#x27;src_face&#x27;</span>: src_face, <span class="string">&#x27;dst_face&#x27;</span>: dst_face &#125;)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> jsonify(&#123; <span class="string">&#x27;success&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;msg&#x27;</span>: res[<span class="string">&#x27;msg&#x27;</span>], <span class="string">&#x27;src_face&#x27;</span>: src_face, <span class="string">&#x27;dst_face&#x27;</span>: dst_face &#125;)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(debug=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以上的flask服务器的业务流程是：</p><ul><li>在主程序中路由<code>/face</code>上接收POST请求，收到待比对的两张人脸图片的文件路径。</li><li>在detect_face函数中，使用OpenCV的HAAR模型，检测图片中的人脸，并且裁剪成当时训练时使用的(55,47)尺寸输入。若检测不到人脸，或者图片文件无法找到，直接返回错误信息。</li><li>在predict函数中，调用tensorflow恢复（restore）模型的参数，输入这两张人脸，获取每张人脸的特征值，计算两者特征值的余弦距离，与之前在测试集上获取的余弦距离阈值进行比对，判断出是否为同一个人，返回结果。</li></ul><p>最终，在前端小程序的手机前置摄像头调用和用户界面的配合下，该系统的最终效果如下所示：</p><p>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-1.jpeg" alt="weapp-1"><br>  <center>图2.12 地图定位界面</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-2.jpeg" alt="weapp-2"><br>  <center>图2.13 人脸识别成功，正在比对人脸</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-3.jpeg" alt="weapp-3"><br>  <center>图2.14 未检测到人脸</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-4.jpeg" alt="weapp-4"><br>  <center>图2.15 比对人脸为同一人后，打卡成功的结果</center></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本次项目实践了使用OpenCV、Tensorflow、Tensorboard以及docker、Jupyter Notebook等深度学习模型训练的常用工具，并尝试将训练得出的模型进行Python flask后端+小程序前端应用落地。在这一过程中，笔者不但熟悉了从数据集预处理、模型训练框架搭建、模型训练过程监控再到模型实际应用的全过程，也通过编写中文注释、以及对Tensorflow不同版本API的移植重写，进一步熟悉深度学习的常用术语和内在含义，可以说是一次收获颇丰的实践案例。</p><p>在此，特别感谢Google Colab免费提供的Nvidia GTX Tesla T4高性能GPU硬件资源以及在线训练平台，感谢他们为深度学习的推广和应用做出的无数努力和贡献。最后，感谢USTB的《机器学习》（自动化学院）、《人工智能》、《模式识别》、《软件工程》等相关课程老师的辛勤教学，是各位老师传授的宝贵知识和设置的一系列大作业帮助着我进一步理解、学习AI各个方向的知识并加以实践，为未来的研究和工作打下了知识基础。感谢大家！</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>GitHub上DeepID的Tensorflow实现（本文在此基础上修改了调用的TensorflowAPI到1.14，并添加中文注释）：<br><a href="https://github.com/jinze1994/DeepID1">https://github.com/jinze1994/DeepID1</a></li><li>DeepID1论文《Deep Learning Face Representation from Predicting 10,000 Classes》：<br><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf">https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf</a></li><li>Google Colab官网：<a href="https://colab.research.google.com">https://colab.research.google.com</a></li><li>DeepID1、2算法解读：<a href="https://www.cnblogs.com/venus024/p/5632243.html">https://www.cnblogs.com/venus024/p/5632243.html</a></li><li>人脸特征提取DeepID 1.0深度网络解读：<br><a href="https://blog.csdn.net/jiajinrang93/article/details/72566130/">https://blog.csdn.net/jiajinrang93/article/details/72566130/</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Different Deep Learning Methods for Image Classification on CIFAR 10</title>
      <link href="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/"/>
      <url>/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/</url>
      
        <content type="html"><![CDATA[<p>本文是2019年4月《人工智能》专业课的大作业报告摘录</p><p>主要内容是在同一数据集（CIFAR10）上使用不同的卷积神经网络模型<br>进行多分类问题训练以及识别效果的横向评估</p><span id="more"></span><blockquote><p>中文标题：基于不同神经网络的CIFAR10图像分类</p></blockquote><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/aistudio.png" alt="AI Studio"></p><center>图1.1 本次实验的AI Studio项目入口页面</center><h3 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h3><ol><li><a href="https://aistudio.baidu.com/aistudio/#/projectdetail/56694">百度 AI Studio</a>（需要登录AI Studio账号后访问，使用百度账号即可）</li><li>在AI Studio的“开发者共享项目”中搜索“CIFAR10图像”分类即可</li><li>GitHub（待发布）</li></ol><h3 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h3><ol><li><p>基于百度AI Studio平台提供的paddlepaddle深度学习框架、Jupyter Notebook线上python运行环境等基础设施，编程实现包括VGG、ResNet、GoogleNet（Inception-V1）、Inception-V4等多种图像分类神经网络。在编程实现的过程中，学习深度神经网络的基本理论和实践要点，了解上述不同神经网络的具体结构设计以及体现出的优秀设计理念和不足之处。</p></li><li><p>使用平台提供的CIFAR10图像识别数据集，在相同的训练环境条件下，训练上述不同神经网络并得出数据模型。收集训练模型过程中输出的训练参数数据，绘制统计图表，比较分析不同神经网络模型的在训练过程中的性能开销、数据指标变化等特点。</p></li><li><p>通过统一的测试图像对训练得出的模型分类图像内容的准确性进行测试，从而比较分析不同神经网络模型在实际应用中的效果。</p></li></ol><blockquote><p>笔者注：根据最后的评估结果以及对相关论文、资料的研读，我们发现这种类似单一变量法的横向对比实验事实上是存在问题的：</p><p>不同年代的卷积神经网络模型，对于训练时最佳效果的硬件要求应该是不同的，虽然不排除存在出现轻量级框架的可能，但是主流意义上的框架对于硬件资源的需求的确是逐年上升的。不应当对每一种模型在训练过程中给出相同的硬件环境，而是给出文献或其开源代码所要求的最佳硬件环境。</p><p>因此，本次实验出现的较新版本的模型最终的识别效果较差的情况，事实上仅仅是实验平台的硬件条件不足以在短时间内训练得出最佳效果的模型。</p></blockquote><h3 id="实验仪器"><a href="#实验仪器" class="headerlink" title="实验仪器"></a>实验仪器</h3><ul><li>本地设备：华硕K550-JX笔记本电脑、macOS Mojave 10.14.4</li><li>远程设备：百度AI Studio提供的通过Jupyter Notebook连接的CPU: 2 Cores 、Memory: 8GB的远程服务器（无GPU）</li></ul><h3 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h3><h4 id="实验项目概况"><a href="#实验项目概况" class="headerlink" title="实验项目概况"></a>实验项目概况</h4><p>本次实验的基本框架来自于paddlepaddle官网教程中的《深度学习基础教程》的《图像分类》章节（网页链接：<a href="http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html）。">http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html）。</a></p><p>该章节介绍了图像识别分类领域中包括VGG、ResNet和GoogleNet等常用模型的基本原理，并给出了paddlepaddle使用其框架自带的CIFAR10数据集以及VGG、ResNet训练模型并进行图像分类的基本步骤和代码实现。</p><p>我们在研读了该教程中的相关理论知识、各行代码实现的前提下，将该教程所述的数据预处理、训练模型、图像识别等完整的流程代码，移植到了同样搭载了最新版本的paddlepaddle的AI Studio在线项目环境中。该项目为新建的项目，而非直接fork在AI Studio上现有的项目，因此能够使用最新版本的paddlepaddle，避免了fork使用早期paddlepaddle版本项目所带来的一系列问题。</p><p>除此之外，我们也对代码进行了逐行的注释解读工作，来帮助使用者理解代码的基本含义和相关的理论知识。我们添加了训练过程中的数据统计图表绘制功能代码，能够在训练结束后将收集到的训练数据绘制成形象的图表并输出，有助于使用者对不同模型的性能进行综合的判断。</p><p>在此基础之上，我们更进一步，参考网络上的相关资料，将该教程中仅给出理论知识而无代码实践的GoogleNet（Inception-V1）、以及其同一系列的最新版本Inception-V4的模型代码移植实现到了百度AI Studio在线项目环境上（由于部分代码存在版本过低等问题，我们进行了相应的修改以确保代码能够正常运行），同样给出了详尽的代码注释解读。</p><p>现在，本项目已经公开在了百度AI Studio的“开发者共享项目”栏目中，欢迎大家fork本项目，也欢迎大家联系我们（邮箱：<a href="mailto:lmy98129@163.com">lmy98129@163.com</a>）提出建议。</p><h4 id="CIFAR数据集介绍"><a href="#CIFAR数据集介绍" class="headerlink" title="CIFAR数据集介绍"></a>CIFAR数据集介绍</h4><blockquote><p>注：以下实验原理介绍部分摘录自paddlepaddle官方教程以及其他网络资料，同时也添加了我们在理论学习和实践过程中对于数据集使用、神经网络模型设计的优缺点等方面的思考和理解，能力有限，如有偏差，敬请谅解。</p></blockquote><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/cifar.png" alt="cifar"></p><center>图1.2 CIFAR数据集局部<br>（图片摘自paddlepaddle官方教程）</center><p>CIFAR10数据集是主要用于通用图像分类而公开的标准数据集CIFAR的一个子集，包含60,000张32x32的彩色图片，10个类别（分别为：飞机airplane、轿车automobile、鸟类bird、猫cat、鹿deer、狗dog、蛙frog、马horse、船ship、卡车truck），每个类包含6,000张。其中50,000张图片作为训练集，10000张作为测试集。</p><p>之所以选用CIFAR而不是大量学术研究成果所基于的ImageNet，我们主要考虑到其体积的问题，在AI Studio的在线项目环境中使用的是CPU训练，而CPU的训练速度由于其核心数量、并行计算能力等原因一般要远远慢于GPU，因此选择一个较小的数据集能够较好地节省训练的时间，但也因此对模型的在小数据集条件下的训练效果提出了考验。</p><p>关于下载速度，由于AI Studio提供了可动态加载的数据集仓库，能够通过创建项目时进行设置、或者创建后修改项目设置等方式动态加载到项目中，因此不存在联网下载的问题。</p><h4 id="VGG基本介绍"><a href="#VGG基本介绍" class="headerlink" title="VGG基本介绍"></a>VGG基本介绍</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/vgg.png" alt="vgg"></p><center>图1.3 VGG模型结构<br>（图片摘自paddlepaddle官方教程）</center><p>相比以往的神经网络模型（例如CNN等），由牛津大学于2014年提出的VGG模型在神经网络的层数（深度）和卷积层的卷积核数目（宽度）上进行了增加。其核心结构是：五组不同卷积核数目的卷积层，以及每两组卷积层之间的max-pooling最大池化的降维操作，最后是全连接层和分类预测层。</p><p>关于VGG网络的设计，我们认为，加深神经网络能够进行更多次的特征提取，提高神经网络的表达能力，但是也增加了训练神经网络的时间和成本，过深的神经网络往往会因为带来梯度的损失而无法找到最优解，从而导致过拟合、准确度下降等一系列问题；加宽的神经网络能够输入更多的细节特征，但也导致了需要输入的参数过多，而同等深度下的神经网络，参数的个数对训练的结果没有明显的影响。</p><h4 id="ResNet基本介绍"><a href="#ResNet基本介绍" class="headerlink" title="ResNet基本介绍"></a>ResNet基本介绍</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/resnet.png" alt="resnet"></p><center>图1.4 残差模块示意图<br>（图片摘自paddlepaddle官方教程）</center><p>为了解决随着网络层数加深而导致准确度下降的问题，ResNet提出了残差学习方法来减轻训练深层网络的困难，在添加batchnorm、小卷积核、全卷积网络等特性基础上，引入了残差模块。</p><p>残差模块的其中一条路径是输入特征的直连通道（可以认为是输入特征中的普遍特征），另一条经过多次卷积的到特征的残差（可以认为是输入特征中的显著特征），最后将以上两条结果相加得到输出。通过这种输出的叠加，残差模块很好地提升了深层次网络训练结果的准确度和收敛速度。</p><p>我们对于以上提到的一些现有特性概念的理解是：batchnorm能够将每次输入的数据分布进行规范化，让其均匀分布在当前层上，从而加速神经网络的训练速度、防止过拟合。小卷积核的意思是指单个卷积核的长宽尺寸减小，能够减少训练参数，从而降低训练模型的性能开销。全卷积网络是指整个模型的主体部分完全使用卷积网络，全连接层使用增加步长的特定卷积层替换，这种替换在功能上是等价的。</p><h4 id="GoogleNet（Inception-V1）基本介绍"><a href="#GoogleNet（Inception-V1）基本介绍" class="headerlink" title="GoogleNet（Inception-V1）基本介绍"></a>GoogleNet（Inception-V1）基本介绍</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/googlenet.png" alt="googlenet"></p><center>图1.5 Inception模块示意图<br>右图为添加1*1卷积层进行降维之后的模块<br>（图片摘自paddlepaddle官方教程）</center><p>GoogleNet由多组Inception模块组成，Inception模块的主要特点是在同一层级上并行设置了多个不同尺寸的卷积层和一个最大池化层，根据资料以及我们的理解总结，这一特性解决了多个问题：</p><ol><li>卷积层的不同尺寸消除了信息分布的均匀程度对卷积核大小的选取影响 </li><li>并行的卷积层减缓了网络层数过深导致的梯度损失以及过拟合</li><li>并行的最大池化层对输入尺寸进行压缩并提取主要特征，也缓解了简单堆叠多层网络导致的计算资源的消耗 </li></ol><p>但是这个特点同样带来了缺陷：并行的池化层并不会改变整个Inception模块的通道数量，并行卷积层构成的Inception在将各个并行层结果拼接后，特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大。因此，Inception还在每一个并行分支上引入了1*1卷积层进行降维操作，减少通道数，解决了这一问题。</p><p>除此之外，GoogleNet的另一个显著特征就是采用了三个子网络，可以得到3个网络的损失率进行加权求和得出整个网络的损失，从而有利于使用优化器（optimizer）的训练程序计算更准确的梯度，加快收敛速度。</p><h4 id="Inception-V4基本介绍"><a href="#Inception-V4基本介绍" class="headerlink" title="Inception-V4基本介绍"></a>Inception-V4基本介绍</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/inception-v4.png" alt="inception-v4"></p><center>图1.6 inception-sterm模块示意图<br>（图片摘自论文《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》）<br></center><p>Inception-V4是Inception系列中的最新版本，经过V2版本添加batchnorm，V3版本对卷积层的调整，在Inception-V4中加入了同样基于卷积+池化并行理念的inception-sterm模块，并分化出了inception-A、B、C三种不同的模块类型。其设计的理念是要与添加了残差模块的Inception-ResNet具有相同的性能，因此使用了大量的经验性的结构设计，其对应的论文中没有对这些结构设计的由来做出进一步的解释说明。</p><p>此外，该模型还添加了reduction模块，起到了之前版本中的一层单层池化层的作用，同样采用了卷积+池化并行的结构设计。</p><h3 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h3><h4 id="项目初始化"><a href="#项目初始化" class="headerlink" title="项目初始化"></a>项目初始化</h4><h5 id="登录AI-Studio平台"><a href="#登录AI-Studio平台" class="headerlink" title="登录AI Studio平台"></a>登录AI Studio平台</h5><p>登录百度AI Studio首页并登录AI Studio账号，选择顶部导航栏中的“项目”，进入项目页面</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/init-step1.png" alt="登录 AI Studio"></p><center>图2.1 登录百度AI Studio进入AI Studio的项目页面</center><h5 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h5><p>点击“创建项目”，输入项目名称、描述并添加数据集。在数据集添加界面中搜索并选中“cifar10数据集”。这里之所以选择这一项“cifar10数据集”是因为该数据集与在调用paddlepaddle自带的cifar10数据集时需要自动联网下载的cifar10数据集格式相同，可以在项目建立后通过在Jupyter Notebook中执行shell命令的方式，将数据集自行放入paddlepaddle的缓存目录中，节省其下载时间。</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/init-step2-1.png" alt="创建项目"></p><center>图2.2 创建项目界面</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/init-step2-2.png" alt="选择数据集"></p><center>图2.3 选择“cifar10数据集”</center><h5 id="运行项目"><a href="#运行项目" class="headerlink" title="运行项目"></a>运行项目</h5><p>创建项目之后，进入项目界面，点击“运行项目”，进入Jupyter Notebook界面</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/init-step3.png" alt="Jupyter Notebook"></p><center>图2.4 Jupyter Notebook界面</center><h5 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h5><p>在第一个cell中输入将当前自动载入到项目当中的数据集cifar-10-python.tar.gz拷贝到paddlepaddle缓存目录的shell命令，如下所示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!cp data/data5752/cifar-10-python.tar.gz /home/aistudio/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz</span><br><span class="line">!ls -l /home/aistudio/.cache/paddle/dataset/cifar/</span><br></pre></td></tr></table></figure><p>执行该cell，若得到如下输出，则拷贝成功。</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/init-step4.png" alt="拷贝数据集"></p><center>图2.5 拷贝数据集成功的输出</center><p>至此，项目初始化完成。</p><h4 id="编写项目主体代码"><a href="#编写项目主体代码" class="headerlink" title="编写项目主体代码"></a>编写项目主体代码</h4><h5 id="导入系统模块代码"><a href="#导入系统模块代码" class="headerlink" title="导入系统模块代码"></a>导入系统模块代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入paddle模块以及一些系统模块</span></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.fluid <span class="keyword">as</span> fluid</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> paddle.fluid.param_attr <span class="keyword">import</span> ParamAttr</span><br></pre></td></tr></table></figure><p>如上所示，这些代码的主要导入了包括paddlepaddle、numpy、sys、math等运行环境内置的python库。</p><h5 id="训练模型所需的模块函数"><a href="#训练模型所需的模块函数" class="headerlink" title="训练模型所需的模块函数"></a>训练模型所需的模块函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inference_network</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="comment"># 图像是32 * 32的rgb格式，rgb格式每个像素应该是3位</span></span><br><span class="line">    data_shape = [<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>]</span><br><span class="line">    <span class="comment"># 设置图片格式</span></span><br><span class="line">    images = fluid.layers.data(name=<span class="string">&#x27;pixel&#x27;</span>, shape=data_shape, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;vgg&#x27;</span>:</span><br><span class="line">    <span class="comment"># 使用vgg模型进行预测</span></span><br><span class="line">        predict = vgg_bn_drop(images)</span><br><span class="line">    <span class="keyword">elif</span> model == <span class="string">&#x27;resnet&#x27;</span>:</span><br><span class="line">    <span class="comment"># 使用resnet模型进行预测</span></span><br><span class="line">        predict = resnet_cifar10(images, <span class="number">32</span>)</span><br><span class="line">    <span class="keyword">elif</span> model == <span class="string">&#x27;googlenet&#x27;</span>:</span><br><span class="line">    <span class="comment"># 使用googlenet模型进行预测</span></span><br><span class="line">        predict = googlenet(images, <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">elif</span> model == <span class="string">&#x27;inception_v4&#x27;</span>:</span><br><span class="line">    <span class="comment"># 使用inception_v4模型进行预测</span></span><br><span class="line">        inception_v4 = InceptionV4()</span><br><span class="line">        predict = inception_v4.net(images, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> predict</span><br></pre></td></tr></table></figure><p>预测程序是在训练或预测过程中实际调用各神经网络模型的最底层函数，这里可以看到不同的模型要求输入的参数类型、调用方式都各有不同。这些模型的具体实现代码在下文会详细给出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_network</span>(<span class="params">predict, model=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 首先从预测程序中获取预测结果</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置图片类别标签格式</span></span><br><span class="line">    label = fluid.layers.data(name=<span class="string">&#x27;label&#x27;</span>, shape=[<span class="number">1</span>], dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;googlenet&#x27;</span>:</span><br><span class="line">        <span class="comment"># 若为googlenet</span></span><br><span class="line">        out, out1, out2 = predict</span><br><span class="line">        <span class="comment"># 分别采用多类交叉熵作为损失函数</span></span><br><span class="line">        cost0 = fluid.layers.cross_entropy(<span class="built_in">input</span>=out, label=label)</span><br><span class="line">        cost1 = fluid.layers.cross_entropy(<span class="built_in">input</span>=out1, label=label)</span><br><span class="line">        cost2 = fluid.layers.cross_entropy(<span class="built_in">input</span>=out2, label=label)</span><br><span class="line">        <span class="comment"># 得到的平均损失用于在上一层中的训练主函数中计算梯度</span></span><br><span class="line">        avg_cost0 = fluid.layers.mean(x=cost0)</span><br><span class="line">        avg_cost1 = fluid.layers.mean(x=cost1)</span><br><span class="line">        avg_cost2 = fluid.layers.mean(x=cost2)</span><br><span class="line">        <span class="comment"># 最后加权求和</span></span><br><span class="line">        avg_cost = avg_cost0 + <span class="number">0.3</span> * avg_cost1 + <span class="number">0.3</span> * avg_cost2</span><br><span class="line">        <span class="comment"># 预测精度看第一个输出即可</span></span><br><span class="line">        accuracy = fluid.layers.accuracy(<span class="built_in">input</span>=out, label=label)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 对于其他模型</span></span><br><span class="line">        <span class="comment"># 在训练中采用多类交叉熵作为损失函数</span></span><br><span class="line">        cost = fluid.layers.cross_entropy(<span class="built_in">input</span>=predict, label=label)</span><br><span class="line">        <span class="comment"># 得到的平均损失用于在上一层中的训练主函数中计算梯度</span></span><br><span class="line">        avg_cost = fluid.layers.mean(cost)</span><br><span class="line">        <span class="comment"># 计算当前预测精度</span></span><br><span class="line">        accuracy = fluid.layers.accuracy(<span class="built_in">input</span>=predict, label=label)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回平均损失和预测精度</span></span><br><span class="line">    <span class="keyword">return</span> [avg_cost, accuracy]</span><br></pre></td></tr></table></figure><p>训练程序是在训练过程中通过模型返回的predict结果来计算损失率和预测精度的函数。这里特别处理了GoogleNet的三个损失率分量的加权求和计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优化器程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimizer_program</span>():</span><br><span class="line">    <span class="comment"># 输入学习率，也就是训练的速度，这里与网络的训练收敛速度有关</span></span><br><span class="line">    <span class="keyword">return</span> fluid.optimizer.Adam(learning_rate=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><p>优化器程序是在训练过程中通过设置学习率、也就是训练的速度后返回一个特定的Adam优化器实例的函数，这是python类的用法。Adam优化器是优化器的一种，对梯度的一阶矩估计和二阶矩估计进行综合考虑，计算出当前神经网络中各个神经元的参数更新的步长，以加快梯度下降速度。Adam优化器在当前深度学习优化器中被默认是相当优异的</p><h5 id="训练主函数"><a href="#训练主函数" class="headerlink" title="训练主函数"></a>训练主函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">use_cuda, model, params_dirname=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 事实上本次训练使用的是CPU，所以use_cuda应当固定为False</span></span><br><span class="line">    place = fluid.CUDAPlace(<span class="number">0</span>) <span class="keyword">if</span> use_cuda <span class="keyword">else</span> fluid.CPUPlace()</span><br><span class="line">    <span class="comment"># 每次训练所选取的样本数量，适当的batch_size可以使得数据并行化处理且梯度下降的方向更加明确</span></span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;inception_v4&#x27;</span>:</span><br><span class="line">        <span class="comment"># 针对inception_v4调整batch_size</span></span><br><span class="line">        BATCH_SIZE = <span class="number">256</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        BATCH_SIZE = <span class="number">128</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练集数据输入，这里使用了shuffle，是用来将读入的数据进行打乱操作的</span></span><br><span class="line">    <span class="comment"># 所以需要定义一个打乱缓冲区的大小buf_size</span></span><br><span class="line">    train_reader = paddle.batch(</span><br><span class="line">        paddle.reader.shuffle(</span><br><span class="line">            paddle.dataset.cifar.train10(), buf_size=<span class="number">128</span>*<span class="number">100</span>), </span><br><span class="line">        batch_size=BATCH_SIZE);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试集数据输入</span></span><br><span class="line">    test_reader = paddle.batch(</span><br><span class="line">        paddle.dataset.cifar.test10(), batch_size=BATCH_SIZE)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nstart training&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输入数据的先后顺序格式</span></span><br><span class="line">    feed_order = [<span class="string">&#x27;pixel&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成默认的训练主程序和启动程序</span></span><br><span class="line">    main_program = fluid.default_main_program()</span><br><span class="line">    star_program = fluid.default_startup_program()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出预测结果，这里没有传入数据是因为数据传入操作是之后的训练过程中设置的</span></span><br><span class="line">    predict = inference_network(model)</span><br><span class="line">    <span class="comment"># 获取训练结果</span></span><br><span class="line">    avg_cost, acc = train_network(predict, model)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 此处开始是测试程序</span></span><br><span class="line">    test_program = main_program.clone(for_test=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 优化器</span></span><br><span class="line">    optimizer = optimizer_program()</span><br><span class="line">    <span class="comment"># 告诉优化器在当前平均损失的基础上计算梯度以减少损失</span></span><br><span class="line">    optimizer.minimize(avg_cost)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行器，将以上操作放入CPU执行</span></span><br><span class="line">    exe = fluid.Executor(place)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># epoch意思为所有数据项目完成一次前向运算和反向传播的次数</span></span><br><span class="line">    <span class="comment"># 这里因为我们训练时间有限，还是1~3次就够了</span></span><br><span class="line">    EPOCH_NUM = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计图横纵坐标的列表</span></span><br><span class="line">    train_steps=[]</span><br><span class="line">    train_costs=[]</span><br><span class="line">    test_steps=[]</span><br><span class="line">    test_costs=[]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对训练结果进行损失率检测的函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_test</span>(<span class="params">program, reader</span>):</span><br><span class="line">        <span class="comment"># 检测次数count</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 输入数据的变量名列表，这里应该就是feed_order中的‘pixel’和‘label’</span></span><br><span class="line">        <span class="comment"># global_block经查应该是fluid的全局作用域</span></span><br><span class="line">        feed_var_list = [</span><br><span class="line">            program.global_block().var(var_name) <span class="keyword">for</span> var_name <span class="keyword">in</span> feed_order</span><br><span class="line">        ]</span><br><span class="line">        <span class="comment"># 数据喂入器DataFeeder负责将数据读取器的输入转换成一种特殊的数据结构中去</span></span><br><span class="line">        <span class="comment"># 从而能够将该数据结构的数据输入到执行器中</span></span><br><span class="line">        feeder_test = fluid.DataFeeder(feed_list=feed_var_list, place=place)</span><br><span class="line">        test_exe = fluid.Executor(place);</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这个变量是记录包括数据变量名在内的所有数据个数以及对应的损失率的</span></span><br><span class="line">        accumulated = <span class="built_in">len</span>([avg_cost, acc]) * [<span class="number">0</span>];</span><br><span class="line">        <span class="comment"># 将数据读取器reader中获取到的输入数据通过enumerate转换为索引序列</span></span><br><span class="line">        <span class="keyword">for</span> tid, test_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(reader()):</span><br><span class="line">            <span class="comment"># 执行训练结果损失率检测的执行器test_exe，喂入测试集数据test_data，得到当前的平均损失率avg_cost_np</span></span><br><span class="line">            avg_cost_np = test_exe.run(</span><br><span class="line">                program=program,</span><br><span class="line">                feed=feeder_test.feed(test_data),</span><br><span class="line">                fetch_list=[avg_cost, acc])</span><br><span class="line">            <span class="comment"># 记录当前的数据个数，这里使用的zip函数将accumulate和avg_cost_np打包成了一个元组进行记录</span></span><br><span class="line">            <span class="comment"># 其中x[1][0]应该是avg_cost_np中的第一项，也就是损失率loss</span></span><br><span class="line">            accumulated = [x[<span class="number">0</span>] + x[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(accumulated, avg_cost_np)]</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 返回的是accumulated中每一条记录中的x与count相除的结果，为平均每次检测得到的损失率</span></span><br><span class="line">        <span class="keyword">return</span> [x/count <span class="keyword">for</span> x <span class="keyword">in</span> accumulated]</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 训练循环函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_loop</span>():</span><br><span class="line">        <span class="comment"># 同样是输入数据的变量名列表，应该就是feed_order中的‘pixel’和‘label’</span></span><br><span class="line">        feed_var_list_loop = [</span><br><span class="line">            main_program.global_block().var(var_name) <span class="keyword">for</span> var_name <span class="keyword">in</span> feed_order</span><br><span class="line">        ]</span><br><span class="line">        feeder = fluid.DataFeeder(feed_list=feed_var_list_loop, place=place)</span><br><span class="line">        <span class="comment"># 开始运行启动程序</span></span><br><span class="line">        exe.run(star_program)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录训练次数</span></span><br><span class="line">        step = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练次数id为pass_id，range生成了一个以epoch次数的</span></span><br><span class="line">        <span class="keyword">for</span> pass_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">            <span class="comment"># 每次训练中的分组训练次数step_id，</span></span><br><span class="line">            <span class="keyword">for</span> step_id, train_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_reader()):</span><br><span class="line">                <span class="comment"># 执行训练执行器，喂入训练集数据train_data，得到当前的平均损失率avg_lost_value</span></span><br><span class="line">                avg_loss_value = exe.run(</span><br><span class="line">                    main_program,</span><br><span class="line">                    feed=feeder.feed(train_data),</span><br><span class="line">                    fetch_list=[avg_cost, acc])</span><br><span class="line">                <span class="comment"># 每50次输出一次训练结果，分别是训练次数，分组训练次数，损失率，预测精度</span></span><br><span class="line">                <span class="keyword">if</span> step_id % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;\nPass %d, Batch %d, Cost %f, Acc %f&quot;</span> % (</span><br><span class="line">                        step_id, pass_id, avg_loss_value[<span class="number">0</span>], avg_loss_value[<span class="number">1</span>]))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 否则单纯输出点表示正在训练</span></span><br><span class="line">                    sys.stdout.write(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">                    sys.stdout.flush()</span><br><span class="line">                    <span class="comment"># 并更新一次训练损失率统计图</span></span><br><span class="line">                    train_steps.append(step)</span><br><span class="line">                    train_costs.append(avg_loss_value[<span class="number">0</span>])</span><br><span class="line">                step += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 每次训练的全部分组训练结束后，进行一次损失率检测，</span></span><br><span class="line">            avg_cost_test, accuracy_test = train_test(test_program, reader=test_reader)</span><br><span class="line">            <span class="comment"># 输出损失率检测结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\nTest with Pass &#123;0&#125;, Loss &#123;1:2.2&#125;, Acc &#123;2:2.2&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                pass_id, avg_cost_test, accuracy_test))</span><br><span class="line">            <span class="comment"># 并更新一次检测损失率统计图</span></span><br><span class="line">            test_steps.append(step)</span><br><span class="line">            test_costs.append(avg_cost_test)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 若模型保存地址为有效，则自动保存本次训练的模型结果</span></span><br><span class="line">            <span class="comment"># 其中从第二个开始的变量意思为：</span></span><br><span class="line">            <span class="comment"># 喂入数据的基本格式（pixel）</span></span><br><span class="line">            <span class="comment"># 保存预测结果所使用的变量组（predict）</span></span><br><span class="line">            <span class="comment"># 执行预测程序（exe=fluid.Executor(place)）</span></span><br><span class="line">            <span class="keyword">if</span> params_dirname <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">if</span> model == <span class="string">&#x27;googlenet&#x27;</span>:</span><br><span class="line">                    model_out, _, _ = predict</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    model_out = predict</span><br><span class="line">                fluid.io.save_inference_model(params_dirname, [<span class="string">&quot;pixel&quot;</span>], [model_out], exe)</span><br><span class="line">                </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 在以上函数和变量定义全部结束后，即可开始训练</span></span><br><span class="line">    train_loop();</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练结束后绘制损失率统计图</span></span><br><span class="line">    %matplotlib inline</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    </span><br><span class="line">    train_title = <span class="string">&quot;Train cost&quot;</span></span><br><span class="line">    test_title = <span class="string">&quot;Test cost&quot;</span></span><br><span class="line">    title = <span class="string">&quot;Train cost/Test cost&quot;</span></span><br><span class="line">    <span class="comment"># 标题，横纵坐标</span></span><br><span class="line">    plt.title(title, fontsize=<span class="number">24</span>) </span><br><span class="line">    plt.xlabel(<span class="string">&quot;step&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;cost&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 设置图例</span></span><br><span class="line">    plt.plot(train_steps, train_costs, color=<span class="string">&#x27;blue&#x27;</span>, label=train_title)</span><br><span class="line">    plt.plot(test_steps, test_costs, color=<span class="string">&#x27;red&#x27;</span>, label=test_title)</span><br><span class="line">    plt.legend()</span><br><span class="line">    <span class="comment"># 显示统计图</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>训练主函数train相对较长，而且还内部声明了对训练结果进行损失率检测的train_test、训练循环函数train_loop几个函数，这里绘制了程序流程图以方便理解，如下图所示：</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/train-func.png" alt="训练主函数"></p><p>从代码和流程图中，我们可以看出训练主函数的主要工作是：</p><ul><li>对训练进行一系列的函数调用关系的绑定、变量的声明和初始化以及训练所需的主要元器件实例（执行器、启动函数、主函数、优化器、数据集）的生成</li><li>进行实际训练过程中的执行、模型生成、数据生成</li><li>训练结束后图表的绘制</li></ul><p>在这里需要说明的有以下几点：</p><ul><li><p>在paddlepaddle中损失率为均方差函数得出的，故没有固定单位，但是一般在训练过程中是呈现总体下降的趋势，损失率越低，模型的效果越好。</p></li><li><p>准确度较容易理解，就是当前模型能够准确识别的样本个数占当前训练样本或测试样本的百分比。</p></li><li><p>batch_size是指每次训练时输入的样本个数，合理的batch_size设置能够减缓在训练过程中的损失率上下震荡的趋势，使得模型的损失率下降速度更快，精确率提升更加明显。根据经验，过大的batch_size可能会导致损失率下降或精确度提升到某一点后停滞，并且导致每次训练的时间和性能开销增大，过小的batch_size则会导致损失率上下震荡，下降速度减慢。</p></li><li><p>epoch是指所有样本完成一次前向运算和反向传播的次数，也就是所有样本都参与过训练的次数。epoch决定了整个训练的总时长，如果使用的是GPU，则可以因为并行处理性能高、训练速度较快而将epoch定在30~50甚至更多，而使用CPU则建议1~5，否则将导致训练时间过长，无法及时生成模型文件。</p></li></ul><h5 id="预测主函数"><a href="#预测主函数" class="headerlink" title="预测主函数"></a>预测主函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测主程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">infer</span>(<span class="params">use_cuda, params_dirname=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">    <span class="comment"># 事实上本次训练使用的是CPU，所以use_cuda应当固定为False</span></span><br><span class="line">    place = fluid.CUDAPlace(<span class="number">0</span>) <span class="keyword">if</span> use_cuda <span class="keyword">else</span> fluid.CPUPlace()</span><br><span class="line">    <span class="comment"># 创建执行器</span></span><br><span class="line">    exe = fluid.Executor(place)</span><br><span class="line">    <span class="comment"># 创建用于预测的局部作用域</span></span><br><span class="line">    inference_scope = fluid.core.Scope()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用于装载需要预测的图片的子函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">infer_file</span>):</span><br><span class="line">        <span class="comment"># 打开图片</span></span><br><span class="line">        im = Image.<span class="built_in">open</span>(infer_file)</span><br><span class="line">        </span><br><span class="line">        %matplotlib inline</span><br><span class="line">        <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">        <span class="comment"># 清空plt输出</span></span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="comment"># 输出当前图片</span></span><br><span class="line">        plt.imshow(im)</span><br><span class="line">        plt.show()</span><br><span class="line">        <span class="comment"># 将图片拉伸为32 * 32，与训练图片相同的大小</span></span><br><span class="line">        im = im.resize((<span class="number">32</span>, <span class="number">32</span>), Image.ANTIALIAS)</span><br><span class="line">        <span class="comment"># 将图片转换为像素数组</span></span><br><span class="line">        im = numpy.array(im).astype(numpy.float32)</span><br><span class="line">        <span class="comment"># 注意，一般存储图片的像素数组格式为W（宽度）、H（高度）、C（像素通道）</span></span><br><span class="line">        <span class="comment"># 但是paddlepaddle需要将格式转换为CHW格式，所以使用了transpose函数</span></span><br><span class="line">        im = im.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 过滤值为255以上的颜色，也就是进行灰度变换</span></span><br><span class="line">        im = im/<span class="number">255.0</span></span><br><span class="line">        <span class="comment"># 向图片添加一个维度用来模拟为列表结构，事实上该维度只有这张图片一个元素</span></span><br><span class="line">        im = numpy.expand_dims(im, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 返回处理好的图片</span></span><br><span class="line">        <span class="keyword">return</span> im</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取程序所在的当前位置</span></span><br><span class="line">    cur_dir = os.path.dirname(os.path.realpath(<span class="string">&#x27;__file__&#x27;</span>))</span><br><span class="line">    <span class="comment"># 设置预测图片</span></span><br><span class="line">    img = load_image(cur_dir + <span class="string">&#x27;/image/dog.png&#x27;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 进入当前的局部作用域</span></span><br><span class="line">    <span class="keyword">with</span> fluid.scope_guard(inference_scope):</span><br><span class="line">        <span class="comment"># 使用fluid.io.load_inference_model去获取以下的信息</span></span><br><span class="line">        <span class="comment"># inference_program：当前的预测程序</span></span><br><span class="line">        <span class="comment"># feed_target_names：喂入数据需要的变量名称</span></span><br><span class="line">        <span class="comment"># fetch_targets：获取数据的目标，通过使用这个目标从而在exe.run中输入fetch_list</span></span><br><span class="line">        [inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输入到神经网络的维度数目一般为4D或5D，使用trainpiler这种编译方式可以将输入的数据结构进行转译</span></span><br><span class="line">        <span class="comment"># 转译的目的主要是能够将fluid生成的对应自有fluid解释器、</span></span><br><span class="line">        <span class="comment"># 而非Python解释器（这样速度更快）的protobuf message表示的程序翻译成 C++ 或其他语言的程序</span></span><br><span class="line">        inference_transpiler_program = inference_program.clone()</span><br><span class="line">        t = fluid.transpiler.InferenceTranspiler()</span><br><span class="line">        t.transpile(inference_transpiler_program, place)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将喂入得数据构造成如下结构&#123;feed_target_name: feed_target_data&#125;</span></span><br><span class="line">        <span class="comment"># 预测的结构带有与fetch_targets对应的一系列数据</span></span><br><span class="line">        <span class="comment"># 这里分别使用带有trainpiler转译和不带有转译的程序进行预测</span></span><br><span class="line">        results = exe.run(inference_program,</span><br><span class="line">            feed=&#123;feed_target_names[<span class="number">0</span>]: img&#125;,</span><br><span class="line">            fetch_list=fetch_targets)</span><br><span class="line">            </span><br><span class="line">        transpiler_results = exe.run(inference_transpiler_program,</span><br><span class="line">            feed=&#123;feed_target_names[<span class="number">0</span>]: img&#125;,</span><br><span class="line">            fetch_list=fetch_targets)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 断言，确定以上两次预测的结果(就1个，所以是[0])的长度是否相同</span></span><br><span class="line">        <span class="comment"># 若相同则继续比对结果中的各个项目是否相同</span></span><br><span class="line">        <span class="comment"># 总之，就是在比对转译前后结果是否能够相同</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(results[<span class="number">0</span>]) == <span class="built_in">len</span>(transpiler_results[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(results[<span class="number">0</span>])):</span><br><span class="line">            numpy.testing.assert_almost_equal(</span><br><span class="line">                results[<span class="number">0</span>][i], transpiler_results[<span class="number">0</span>][i], decimal=<span class="number">5</span>)</span><br><span class="line">        </span><br><span class="line">         <span class="comment"># 预测标签，这个顺序一般是和训练的模型数据的顺序相同的</span></span><br><span class="line">        label_list = [</span><br><span class="line">            <span class="string">&quot;airplane&quot;</span>, <span class="string">&quot;automobile&quot;</span>, <span class="string">&quot;bird&quot;</span>, <span class="string">&quot;cat&quot;</span>, <span class="string">&quot;deer&quot;</span>, <span class="string">&quot;dog&quot;</span>, <span class="string">&quot;frog&quot;</span>,</span><br><span class="line">            <span class="string">&quot;horse&quot;</span>, <span class="string">&quot;ship&quot;</span>, <span class="string">&quot;truck&quot;</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出预测结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;infer results: %s&quot;</span> % label_list[numpy.argmax(results[<span class="number">0</span>])])</span><br></pre></td></tr></table></figure><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/predict-func.png" alt="预测主函数"></p><center>图2.7 预测主函数predict的程序流程图</center><h5 id="程序主函数"><a href="#程序主函数" class="headerlink" title="程序主函数"></a>程序主函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">use_cuda</span>):</span><br><span class="line">    <span class="comment"># 如果需要使用GPU的CUDA函数库，则需要判断fluid是否根据cuda进行了编译</span></span><br><span class="line">    <span class="keyword">if</span> use_cuda <span class="keyword">and</span> <span class="keyword">not</span> fluid.core.is_compiled_with_cuda():</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意：更改训练模型请更改此处的model变量</span></span><br><span class="line">    model=<span class="string">&#x27;googlenet&#x27;</span></span><br><span class="line">    <span class="comment"># 模型文件保存路径</span></span><br><span class="line">    save_path = <span class="string">&#x27;image_classification_&#x27;</span>+model+<span class="string">&#x27;.inference.model&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练</span></span><br><span class="line">    train(use_cuda=use_cuda, model=model, params_dirname=save_path)</span><br><span class="line">    <span class="comment"># 注意：如果报出optimzer相关的错误，可以尝试在kernel操作中“重启”，之后再从头开始重新运行</span></span><br><span class="line">    <span class="comment"># 这一错误可能是在对部分函数中途修改并重新运行后optimizer不再识别其输入导致的问题</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测，如果训练已经得出了save_path指定的模型文件</span></span><br><span class="line">    <span class="comment"># 预测程序则可以独立运行，否则不可以运行</span></span><br><span class="line">    infer(use_cuda=use_cuda, params_dirname=save_path)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 根据当前测试环境，使用CPU</span></span><br><span class="line">    main(use_cuda=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>程序主函数main的主要功能是先确定环境变量：使用CPU/GPU、当前使用的模型名称、模型文件保存路径等，再执行训练主函数和预测主函数，是整个程序的最顶层模块。</p><h4 id="编写神经网络模型代码"><a href="#编写神经网络模型代码" class="headerlink" title="编写神经网络模型代码"></a>编写神经网络模型代码</h4><p>注：由于在“实验原理”章节中，对于各神经网络模型的关键技术原理和关键模块结构已经进行了说明，此处代码部分对于这些内容不再重复解释。</p><p>在整体上，神经网络模型的实现主要是基于paddlepaddle提供的卷积层、池化层、全连接层等函数API以及层与层之间的连接来实现的，各神经网络的共性的地方在于以下2点：</p><ul><li>经过若干个卷积、池化层结构之后，在最后输出结果之前的一层全连接层中都要经历一次softmax归一化，通过softmax归一化得到每个类别的概率，softmax能够将输入映射为0-1之间的实数，作为取到某个分类的概率，作为最终的输出结果。</li><li>在每一组神经网络之间，常用dropout层对结果按照一定概率随机丢弃一些特征，以防止过拟合；同时也常用batchnorm，将每次输入的数据分布进行规范化，让其均匀分布在当前层上，从而加速神经网络的训练速度、同样防止过拟合。</li></ul><h5 id="VGG模型"><a href="#VGG模型" class="headerlink" title="VGG模型"></a>VGG模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vgg模型定义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码来自：http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_bn_drop</span>(<span class="params"><span class="built_in">input</span></span>):</span><br><span class="line">    <span class="comment"># 创建神经网络的公用函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv_block</span>(<span class="params">ipt, num_filter, groups, dropouts</span>):</span><br><span class="line">        <span class="comment"># 返回根据传入参数创建的神经网络</span></span><br><span class="line">        <span class="keyword">return</span> fluid.nets.img_conv_group(</span><br><span class="line">            <span class="comment"># 图像输入</span></span><br><span class="line">            <span class="built_in">input</span>=ipt,</span><br><span class="line">            <span class="comment"># 池化窗口大小为2*2</span></span><br><span class="line">            pool_size=<span class="number">2</span>,</span><br><span class="line">            <span class="comment"># 池化窗口移动的步长</span></span><br><span class="line">            pool_stride=<span class="number">2</span>,</span><br><span class="line">            <span class="comment"># 该神经网络层组的过滤器数量，可以认为是神经元个数</span></span><br><span class="line">            conv_num_filter=[num_filter] * groups,</span><br><span class="line">            <span class="comment"># 过滤器大小，默认值为3</span></span><br><span class="line">            conv_filter_size=<span class="number">3</span>,</span><br><span class="line">            <span class="comment"># 激活函数的类型，这里选用RELU</span></span><br><span class="line">            conv_act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            <span class="comment"># 在每一层后使用batchnorm以加速神经网络训练速度</span></span><br><span class="line">            <span class="comment"># batchnorm能够将每次输入的数据分布进行规范化</span></span><br><span class="line">            conv_with_batchnorm=<span class="literal">True</span>,</span><br><span class="line">            <span class="comment"># 对于每一层进行batchnorm后的dropout概率</span></span><br><span class="line">            <span class="comment"># dropout是避免过拟合的手段，按照一定概率随机丢弃一些特征</span></span><br><span class="line">            conv_batchnorm_drop_rate=dropouts,</span><br><span class="line">            <span class="comment"># 池化类型为最大池化，提取每个池化窗口中的最显著特征</span></span><br><span class="line">            pool_type=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 以下各函数中最后一个列表为每一层结束后dropout的概率</span></span><br><span class="line">    <span class="comment"># 一般在两组卷积层之间不使用dropout</span></span><br><span class="line">    <span class="comment"># 第1组卷积层，2次连续卷积，卷积核数目64</span></span><br><span class="line">    conv1 = conv_block(<span class="built_in">input</span>, <span class="number">64</span>, <span class="number">2</span>, [<span class="number">0.3</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 第2组卷积层，2次连续卷积，卷积核数目128</span></span><br><span class="line">    conv2 = conv_block(conv1, <span class="number">128</span>, <span class="number">2</span>, [<span class="number">0.4</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 第3组卷积层，3次连续卷积，卷积核数目为256</span></span><br><span class="line">    conv3 = conv_block(conv2, <span class="number">256</span>, <span class="number">3</span>, [<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 第4组卷积层，3次连续卷积，卷积核数目为512</span></span><br><span class="line">    conv4 = conv_block(conv3, <span class="number">512</span>, <span class="number">3</span>, [<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 第5组卷积层，3次连续卷积，卷积核数目为512</span></span><br><span class="line">    conv5 = conv_block(conv4, <span class="number">512</span>, <span class="number">3</span>, [<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 最后一层结束后添加一层概率为0.5的dropout层</span></span><br><span class="line">    drop = fluid.layers.dropout(x=conv5, dropout_prob=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># 添加全连接层，维度数为512</span></span><br><span class="line">    fc1 = fluid.layers.fc(<span class="built_in">input</span>=drop, size=<span class="number">512</span>, act=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 在全连接层结束后添加batchnorm防止过拟合</span></span><br><span class="line">    bn = fluid.layers.batch_norm(<span class="built_in">input</span>=fc1, act=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    <span class="comment"># 添加概率为0.5的dropout层</span></span><br><span class="line">    drop2 = fluid.layers.dropout(x=bn, dropout_prob=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># 添加全连接层，维度数为512</span></span><br><span class="line">    fc2 = fluid.layers.fc(<span class="built_in">input</span>=drop2, size=<span class="number">512</span>, act=<span class="literal">None</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 最后，添加预测用的全连接层，映射到类别维度大小的向量，本次数据类别一共10种</span></span><br><span class="line">    <span class="comment"># 通过softmax归一化得到每个类别的概率，softmax是将输入映射为0-1之间的实数，作为取到某个分类的概率</span></span><br><span class="line">    <span class="comment"># 可以认为是一个分类器</span></span><br><span class="line">    predict = fluid.layers.fc(<span class="built_in">input</span>=fc2, size=<span class="number">10</span>, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出最终的结果</span></span><br><span class="line">    <span class="keyword">return</span> predict</span><br></pre></td></tr></table></figure><h5 id="ResNet模型"><a href="#ResNet模型" class="headerlink" title="ResNet模型"></a>ResNet模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># resnet模型定义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码来自：http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为resnet_cifar10需要用到的工具函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># conv_bn_layer为自带batchnorm的神经网络层</span></span><br><span class="line"><span class="comment"># input为输入，ch_out为滤波器个数，该个数与输出图像通道相同，故赋值为channel_out=ch_out</span></span><br><span class="line"><span class="comment"># filter_size为过滤器大小，stride为窗口移动的步长</span></span><br><span class="line"><span class="comment"># padding为填充格式，VALID对于多出来的数据直接丢弃，SAME将多出来的数据继续填充到下一层的额外行和列</span></span><br><span class="line"><span class="comment"># act为激活函数，这里使用RELU函数</span></span><br><span class="line"><span class="comment"># bias_attr为False，说明不需要得到单个卷积核卷积图片的结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_bn_layer</span>(<span class="params"><span class="built_in">input</span>,</span></span><br><span class="line"><span class="params">                  ch_out,</span></span><br><span class="line"><span class="params">                  filter_size,</span></span><br><span class="line"><span class="params">                  stride,</span></span><br><span class="line"><span class="params">                  padding,</span></span><br><span class="line"><span class="params">                  act=<span class="string">&#x27;relu&#x27;</span>,</span></span><br><span class="line"><span class="params">                  bias_attr=<span class="literal">False</span></span>):</span><br><span class="line">    tmp = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        filter_size=filter_size,</span><br><span class="line">        num_filters=ch_out,</span><br><span class="line">        stride=stride,</span><br><span class="line">        padding=padding,</span><br><span class="line">        act=<span class="literal">None</span>,</span><br><span class="line">        bias_attr=bias_attr)</span><br><span class="line">    <span class="keyword">return</span> fluid.layers.batch_norm(<span class="built_in">input</span>=tmp, act=act)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shortcut为残差模块的“直连路径”</span></span><br><span class="line"><span class="comment"># 在resnet中引入残差模块后，解决了网络层数加深导致准确度下降的问题</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shortcut</span>(<span class="params"><span class="built_in">input</span>, ch_in, ch_out, stride</span>):</span><br><span class="line">    <span class="comment"># 残差模块输入和输出特征通道数不等时，采用1x1卷积的升维操作</span></span><br><span class="line">    <span class="keyword">if</span> ch_in != ch_out:</span><br><span class="line">        <span class="keyword">return</span> conv_bn_layer(<span class="built_in">input</span>, ch_out, <span class="number">1</span>, stride, <span class="number">0</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 残差模块输入和输出通道相等时，采用直连操作</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># basicblock为基础残差模块，由两组3x3卷积组成的路径和一条&quot;直连&quot;路径组成</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">basicblock</span>(<span class="params"><span class="built_in">input</span>, ch_in, ch_out, stride</span>):</span><br><span class="line">    <span class="comment"># 由两组3x3卷积组成的路径</span></span><br><span class="line">    tmp = conv_bn_layer(<span class="built_in">input</span>, ch_out, <span class="number">3</span>, stride, <span class="number">1</span>)</span><br><span class="line">    tmp = conv_bn_layer(tmp, ch_out, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, act=<span class="literal">None</span>, bias_attr=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 一条“直连”路径</span></span><br><span class="line">    short = shortcut(<span class="built_in">input</span>, ch_in, ch_out, stride)</span><br><span class="line">    <span class="comment"># 使用fluid自动在每一层后添加这一残差模块的输入</span></span><br><span class="line">    <span class="keyword">return</span> fluid.layers.elementwise_add(x=tmp, y=short, act=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layer_warp为一组残差模块，由若干个残差模块堆积而成</span></span><br><span class="line"><span class="comment"># 这里的block_func事实上指的就是basicblock</span></span><br><span class="line"><span class="comment"># ch_in和ch_out分别为输入输出通道</span></span><br><span class="line"><span class="comment"># count为残差模块的个数，stride为窗口移动步长</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">layer_warp</span>(<span class="params">block_func, <span class="built_in">input</span>, ch_in, ch_out, count, stride</span>):</span><br><span class="line">    tmp = block_func(<span class="built_in">input</span>, ch_in, ch_out, stride)</span><br><span class="line">    <span class="comment"># 每组中第一个残差模块滑动窗口大小与其他可以不同，以用来减少特征图在垂直和水平方向的大小</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, count):</span><br><span class="line">        tmp = block_func(tmp, ch_out, ch_out, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> tmp</span><br><span class="line"></span><br><span class="line"><span class="comment"># resnet_cifar10模型主函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_cifar10</span>(<span class="params">ipt, depth=<span class="number">32</span></span>):</span><br><span class="line">    <span class="comment"># 除第一层卷积层和最后一层全连接层之外</span></span><br><span class="line">    <span class="comment"># 要求三组 layer_warp 总的含参层数能够被6整除</span></span><br><span class="line">    <span class="comment"># 即 resnet_cifar10 的 depth 要满足 (depth−2) </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 因此深度的可能取值： 20, 32, 44, 56, 110, 1202</span></span><br><span class="line">    <span class="keyword">assert</span> (depth - <span class="number">2</span>) % <span class="number">6</span> == <span class="number">0</span></span><br><span class="line">    n = (depth - <span class="number">2</span>) // <span class="number">6</span></span><br><span class="line">    nStages = &#123;<span class="number">16</span>, <span class="number">64</span>, <span class="number">128</span>&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 底层输入连接一层带batchnorm的卷积层</span></span><br><span class="line">    conv1 = conv_bn_layer(ipt, ch_out=<span class="number">16</span>, filter_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 连接3组残差模块</span></span><br><span class="line">    res1 = layer_warp(basicblock, conv1, <span class="number">16</span>, <span class="number">16</span>, n, <span class="number">1</span>)</span><br><span class="line">    res2 = layer_warp(basicblock, res1, <span class="number">16</span>, <span class="number">32</span>, n, <span class="number">2</span>)</span><br><span class="line">    res3 = layer_warp(basicblock, res2, <span class="number">32</span>, <span class="number">64</span>, n, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对网络做均值池化，可以看到pool_type=‘avg’表示均值池化</span></span><br><span class="line">    pool = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=res3, pool_size=<span class="number">8</span>, pool_type=<span class="string">&#x27;avg&#x27;</span>, pool_stride=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 添加全连接层作为预测层，通过softmax归一化得到每个类别的概率</span></span><br><span class="line">    predict = fluid.layers.fc(<span class="built_in">input</span>=pool, size=<span class="number">10</span>, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> predict</span><br></pre></td></tr></table></figure><h5 id="GoogleNet模型"><a href="#GoogleNet模型" class="headerlink" title="GoogleNet模型"></a>GoogleNet模型</h5><p>我们获得的初始GoogleNet模型代码使用的是早期的paddlepaddle版本，因此我们花费了一些时间查阅了paddlepaddle官网的API文档，研究了不同版本之间的API对应关系和调用方式上的差异。最终，我们成功地将该模型代码移植到了AI Studio在线项目平台上的paddlepaddle V1.4版本上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># googlenet模型定义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码来自：https://www.cnblogs.com/charlotte77/p/8066867.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为googlenet需要用到的工具函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># inception为一个inceoption网络，目前已经发展到了inceptionV4和inception-resnet</span></span><br><span class="line"><span class="comment"># inception主要的特点是在同一层级上运行多个不同尺寸的卷积层，这一特性解决了多个问题</span></span><br><span class="line"><span class="comment"># 1. 消除了信息分布的均匀程度对卷积核大小的选取影响</span></span><br><span class="line"><span class="comment"># 2. 减缓了网络层数过深导致的梯度损失以及过拟合</span></span><br><span class="line"><span class="comment"># 3. 缓解了简单堆叠多层网络导致的计算资源的消耗</span></span><br><span class="line"><span class="comment"># 但是这个特点同样带来了缺陷：</span></span><br><span class="line"><span class="comment"># 池化层不会改变特征通道数，拼接后会导致特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大</span></span><br><span class="line"><span class="comment"># 因此，inception还通过引入3个1*1卷积层进行降维，减少通道数</span></span><br><span class="line"><span class="comment"># 下面的版本是inceptionv1版本，v2引入batchnorm，v3对卷积层进一步分解，v4引入了res-net</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这些参数的意思为：</span></span><br><span class="line"><span class="comment"># name：整个inception的名称</span></span><br><span class="line"><span class="comment"># channels：通道个数</span></span><br><span class="line"><span class="comment"># filter1、filter3R、filter3、filter5R、filter5、proj：各个卷积层的过滤器数量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inception</span>(<span class="params">name, <span class="built_in">input</span>, channels, filter1, filter3R, filter3, filter5R,</span></span><br><span class="line"><span class="params">              filter5, proj</span>):</span><br><span class="line">    <span class="comment"># 1*1卷积层_1</span></span><br><span class="line">    cov1 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=filter1,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1*1卷积层_3r</span></span><br><span class="line">    cov3r = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=filter3R,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 1*1卷积层_3r的下一层3*3卷积层</span></span><br><span class="line">    cov3 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=cov3r,</span><br><span class="line">        filter_size=<span class="number">3</span>,</span><br><span class="line">        num_filters=filter3,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1*1卷积层_5r</span></span><br><span class="line">    cov5r = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=filter5R,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 1*1卷积层_5r的下一层5*5卷积层</span></span><br><span class="line">    cov5 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=cov5r,</span><br><span class="line">        filter_size=<span class="number">5</span>,</span><br><span class="line">        num_filters=filter5,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3*3最大池化层</span></span><br><span class="line">    pool1 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        pool_size=<span class="number">3</span>,</span><br><span class="line">        pool_type=<span class="string">&quot;max&quot;</span>,</span><br><span class="line">        pool_stride=<span class="number">1</span>,</span><br><span class="line">        pool_padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 3*3最大池化层的下一层1*1卷积层</span></span><br><span class="line">    covprj = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=pool1,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=proj,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全连接层将以上的结果汇总处理</span></span><br><span class="line">    cat = fluid.layers.concat(<span class="built_in">input</span>=[cov1, cov3, cov5, covprj], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> cat</span><br><span class="line"></span><br><span class="line"><span class="comment"># googlenet模型主函数</span></span><br><span class="line"><span class="comment"># class_dim为当前类别的维度个数，这里一共有10个类，因此填10</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">googlenet</span>(<span class="params"><span class="built_in">input</span>, class_dim</span>):</span><br><span class="line">    <span class="comment"># stage 1 </span></span><br><span class="line">    <span class="comment"># 7*7卷积层</span></span><br><span class="line">    conv1 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=<span class="built_in">input</span>,</span><br><span class="line">        filter_size=<span class="number">7</span>,</span><br><span class="line">        num_filters=<span class="number">64</span>,</span><br><span class="line">        stride=<span class="number">2</span>,</span><br><span class="line">        padding=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 3*3最大池化层</span></span><br><span class="line">    pool1 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=conv1, pool_size=<span class="number">3</span>, pool_type=<span class="string">&quot;max&quot;</span>, pool_stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stage 2</span></span><br><span class="line">    <span class="comment"># 1*1卷积层</span></span><br><span class="line">    conv2_1 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=pool1,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=<span class="number">64</span>,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 3*3卷积层</span></span><br><span class="line">    conv2_2 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=conv2_1,</span><br><span class="line">        filter_size=<span class="number">3</span>,</span><br><span class="line">        num_filters=<span class="number">192</span>,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 3*3最大池化层</span></span><br><span class="line">    pool2 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=conv2_2, pool_size=<span class="number">3</span>, pool_type=<span class="string">&#x27;max&#x27;</span>, pool_stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stage 3</span></span><br><span class="line">    <span class="comment"># 2组inception+1个3*3最大池化层</span></span><br><span class="line">    ince3a = inception(<span class="string">&quot;ince3a&quot;</span>, pool2, <span class="number">192</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    ince3b = inception(<span class="string">&quot;ince3b&quot;</span>, ince3a, <span class="number">256</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">    pool3 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=ince3b, pool_size=<span class="number">3</span>, pool_type=<span class="string">&#x27;max&#x27;</span>, pool_stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stage 4</span></span><br><span class="line">    <span class="comment"># 5组inception+1个3*3最大池化层</span></span><br><span class="line">    ince4a = inception(<span class="string">&quot;ince4a&quot;</span>, pool3, <span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">    ince4b = inception(<span class="string">&quot;ince4b&quot;</span>, ince4a, <span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    ince4c = inception(<span class="string">&quot;ince4c&quot;</span>, ince4b, <span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    ince4d = inception(<span class="string">&quot;ince4d&quot;</span>, ince4c, <span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    ince4e = inception(<span class="string">&quot;ince4e&quot;</span>, ince4d, <span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    pool4 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=ince4e, pool_size=<span class="number">3</span>, pool_type=<span class="string">&#x27;max&#x27;</span>, pool_stride=<span class="number">2</span>, pool_padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stage 5</span></span><br><span class="line">    <span class="comment"># 2组inception+1个7*7最大池化层</span></span><br><span class="line">    ince5a = inception(<span class="string">&quot;ince5a&quot;</span>, pool4, <span class="number">832</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    ince5b = inception(<span class="string">&quot;ince5b&quot;</span>, ince5a, <span class="number">832</span>, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    pool5 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=ince5b,</span><br><span class="line">        pool_size=<span class="number">7</span>,</span><br><span class="line">        pool_stride=<span class="number">7</span>,</span><br><span class="line">        pool_type=<span class="string">&quot;avg&quot;</span>)</span><br><span class="line">    <span class="comment"># 添加丢弃概率为0.4的dropout层避免过拟合</span></span><br><span class="line">    drop1 = fluid.layers.dropout(x=pool5, dropout_prob=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># 最后一层全连接层进行主损失率out的输出，softmax归一化每个类别的概率</span></span><br><span class="line">    out = fluid.layers.fc(</span><br><span class="line">        <span class="built_in">input</span>=drop1, size=class_dim, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于计算损失率分量out1的第一个辅助的分类器</span></span><br><span class="line">    <span class="comment"># 5*5均值池化，注意这里的输入为ince4a的输出，也就是在生成out中途的输出</span></span><br><span class="line">    pool_o1 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=ince4a,</span><br><span class="line">        pool_size=<span class="number">5</span>,</span><br><span class="line">        pool_stride=<span class="number">3</span>,</span><br><span class="line">        pool_type=<span class="string">&quot;avg&quot;</span>,</span><br><span class="line">        pool_padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 1*1卷积</span></span><br><span class="line">    conv_o1 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=pool_o1,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=<span class="number">128</span>,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 带有激活函数RELU的全连接</span></span><br><span class="line">    fc_o1 = fluid.layers.fc(</span><br><span class="line">        <span class="built_in">input</span>=conv_o1,</span><br><span class="line">        size=<span class="number">1024</span>,</span><br><span class="line">        act=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    <span class="comment"># 添加丢弃概率为0.4的dropout层避免过拟合</span></span><br><span class="line">    drop2 = fluid.layers.dropout(x=fc_o1, dropout_prob=<span class="number">0.7</span>)</span><br><span class="line">    <span class="comment"># 最后一层全连接层softmax归一化后输出的out1</span></span><br><span class="line">    out1 = fluid.layers.fc(</span><br><span class="line">        <span class="built_in">input</span>=drop2, size=class_dim, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于计算损失率分量out2的第二个辅助的分类器</span></span><br><span class="line">    <span class="comment"># 5*5均值池化，这里的输入为ince4d的输出，同样是在生成out中途的输出</span></span><br><span class="line">    pool_o2 = fluid.layers.pool2d(</span><br><span class="line">        <span class="built_in">input</span>=ince4d,</span><br><span class="line">        pool_size=<span class="number">5</span>,</span><br><span class="line">        pool_stride=<span class="number">3</span>,</span><br><span class="line">        pool_type=<span class="string">&quot;avg&quot;</span>,</span><br><span class="line">        pool_padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 1*1卷积</span></span><br><span class="line">    conv_o2 = fluid.layers.conv2d(</span><br><span class="line">        <span class="built_in">input</span>=pool_o2,</span><br><span class="line">        filter_size=<span class="number">1</span>,</span><br><span class="line">        num_filters=<span class="number">128</span>,</span><br><span class="line">        stride=<span class="number">1</span>,</span><br><span class="line">        padding=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 带有激活函数RELU的全连接</span></span><br><span class="line">    fc_o2 = fluid.layers.fc(</span><br><span class="line">        <span class="built_in">input</span>=conv_o2,</span><br><span class="line">        size=<span class="number">1024</span>,</span><br><span class="line">        act=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    <span class="comment"># 添加丢弃概率为0.4的dropout层避免过拟合</span></span><br><span class="line">    drop3 = fluid.layers.dropout(x=fc_o2, dropout_prob=<span class="number">0.7</span>)</span><br><span class="line">    <span class="comment"># 最后一层全连接层softmax归一化后输出的out1</span></span><br><span class="line">    out2 = fluid.layers.fc(</span><br><span class="line">        <span class="built_in">input</span>=drop3, size=class_dim, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出损失率的三个分量</span></span><br><span class="line">    <span class="keyword">return</span> out, out1, out2</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="Inception-V4模型"><a href="#Inception-V4模型" class="headerlink" title="Inception-V4模型"></a>Inception-V4模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inception_v4模型定义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码来自：https://github.com/PaddlePaddle/models/blob/43cdafbb97e52e6d93cc5bbdc6e7486f27665fc8/PaddleCV/image_classification/models/inception_v4.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用了面向对象的封装</span></span><br><span class="line"><span class="comment"># 因为不同的inception版本中的同名函数例如conv_bn_layer（带batchnorm的卷积层）的具体实现是不同的</span></span><br><span class="line"><span class="comment"># 所以为了防止同名函数定义的互相覆盖，使用类的封装思想比较合理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionV4</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;using inception v4.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型主函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">self, <span class="built_in">input</span>, class_dim=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="comment"># STEP 1 inception_sterm模块</span></span><br><span class="line">        <span class="comment"># stem模块其实就是多次卷积＋２次池化，采用了Inception论文里提到的卷积＋池化并行的结构</span></span><br><span class="line">        <span class="comment"># 在同时也使用了多个1*1卷积，之前的googlenet（inception_v1）中也提到过</span></span><br><span class="line">        <span class="comment"># 这是一种降维操作，能够通过减少通道数从而减少因为并行结构带来的巨大计算量</span></span><br><span class="line">        x = self.inception_stem(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># STEP 2 4层inception_A模块+1层reduction模块</span></span><br><span class="line">        <span class="comment"># inception_A、B、C模块之间内在结构各有不同，在该算法论文中没有详细的解答，应该是一种经验性的结构</span></span><br><span class="line">        <span class="comment"># reduction起到了作为之前版本中的一层单层池化层的作用，同样采用了卷积+池化并行的结构</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            x = self.inceptionA(x, name=<span class="built_in">str</span>(i + <span class="number">1</span>))</span><br><span class="line">        x = self.reductionA(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># STEP 3 7层inception_B模块+1层reduction模块</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>):</span><br><span class="line">            x = self.inceptionB(x, name=<span class="built_in">str</span>(i + <span class="number">1</span>))</span><br><span class="line">        x = self.reductionB(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># STEP 4 3层inception_C模块+1层reduction模块</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            x = self.inceptionC(x, name=<span class="built_in">str</span>(i + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 平均池化，不同于最大池化提取特征，这是在保留背景信息</span></span><br><span class="line">        pool = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=x, pool_size=<span class="number">8</span>, pool_type=<span class="string">&#x27;avg&#x27;</span>, global_pooling=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># dropout操作用来减少过拟合</span></span><br><span class="line">        drop = fluid.layers.dropout(x=pool, dropout_prob=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里做了一次运算，stdv是标准差的意思</span></span><br><span class="line">        stdv = <span class="number">1.0</span> / math.sqrt(drop.shape[<span class="number">1</span>] * <span class="number">1.0</span>)</span><br><span class="line">        <span class="comment"># 这里传入的initializer.Uniform是随机均匀分布初始化器的意思</span></span><br><span class="line">        <span class="comment"># 这里的全连接层的各个神经元权重使用了随机均匀分布初始化的方式</span></span><br><span class="line">        <span class="comment"># 一般的初始化方式有正态分布和随机均匀分布两种，两者优劣没有定论，但经验上看，均匀分布的随机数能够让更多的权重接近于0</span></span><br><span class="line">        out = fluid.layers.fc(</span><br><span class="line">            <span class="built_in">input</span>=drop,</span><br><span class="line">            size=class_dim,</span><br><span class="line">            param_attr=ParamAttr(</span><br><span class="line">                initializer=fluid.initializer.Uniform(-stdv, stdv),</span><br><span class="line">                name=<span class="string">&quot;final_fc_weights&quot;</span>),</span><br><span class="line">            bias_attr=ParamAttr(</span><br><span class="line">                initializer=fluid.initializer.Uniform(-stdv, stdv),</span><br><span class="line">                name=<span class="string">&quot;final_fc_offset&quot;</span>),</span><br><span class="line">            act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 带batchnorm的卷积层函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv_bn_layer</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                      data,</span></span><br><span class="line"><span class="params">                      num_filters,</span></span><br><span class="line"><span class="params">                      filter_size,</span></span><br><span class="line"><span class="params">                      stride=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                      padding=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                      groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                      act=<span class="string">&#x27;relu&#x27;</span>,</span></span><br><span class="line"><span class="params">                      name=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 和之前resnet使用的卷积层定义基本一致，只是添加了一些name名称，此处不再赘述</span></span><br><span class="line">        conv = fluid.layers.conv2d(</span><br><span class="line">            <span class="built_in">input</span>=data,</span><br><span class="line">            num_filters=num_filters,</span><br><span class="line">            filter_size=filter_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            padding=padding,</span><br><span class="line">            groups=groups,</span><br><span class="line">            act=<span class="literal">None</span>,</span><br><span class="line">            param_attr=ParamAttr(name=name + <span class="string">&quot;_weights&quot;</span>),</span><br><span class="line">            bias_attr=<span class="literal">False</span>,</span><br><span class="line">            name=name)</span><br><span class="line">        bn_name = name + <span class="string">&quot;_bn&quot;</span></span><br><span class="line">        <span class="comment"># batchnorm也是如此，基本一致</span></span><br><span class="line">        <span class="keyword">return</span> fluid.layers.batch_norm(</span><br><span class="line">            <span class="built_in">input</span>=conv,</span><br><span class="line">            act=act,</span><br><span class="line">            name=bn_name,</span><br><span class="line">            param_attr=ParamAttr(name=bn_name + <span class="string">&quot;_scale&quot;</span>),</span><br><span class="line">            bias_attr=ParamAttr(name=bn_name + <span class="string">&quot;_offset&quot;</span>),</span><br><span class="line">            moving_mean_name=bn_name + <span class="string">&#x27;_mean&#x27;</span>,</span><br><span class="line">            moving_variance_name=bn_name + <span class="string">&#x27;_variance&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inception_stem层，具体结构可以参考论文中的图像，</span></span><br><span class="line">    <span class="comment"># 基本原理还是和googlenet一样，并行处理的卷积+池化以及1*1卷积降维</span></span><br><span class="line">    <span class="comment"># 具体到结构为什么这么设计可以认为是经验性的，论文没有深入讨论</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inception_stem</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        conv = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">2</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;conv1_3x3_s2&quot;</span>)</span><br><span class="line">        conv = self.conv_bn_layer(conv, <span class="number">32</span>, <span class="number">3</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;conv2_3x3_s1&quot;</span>)</span><br><span class="line">        conv = self.conv_bn_layer(</span><br><span class="line">            conv, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;conv3_3x3_s1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=conv, pool_size=<span class="number">3</span>, pool_stride=<span class="number">2</span>, pool_type=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            conv, <span class="number">96</span>, <span class="number">3</span>, stride=<span class="number">2</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem1_3x3_s2&quot;</span>)</span><br><span class="line">        concat = fluid.layers.concat([pool1, conv2], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            concat, <span class="number">64</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem2_3x3_reduce&quot;</span>)</span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            conv1, <span class="number">96</span>, <span class="number">3</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem2_3x3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            concat, <span class="number">64</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem2_1x7_reduce&quot;</span>)</span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            conv2,</span><br><span class="line">            <span class="number">64</span>, (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">3</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_stem2_1x7&quot;</span>)</span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            conv2,</span><br><span class="line">            <span class="number">64</span>, (<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_stem2_7x1&quot;</span>)</span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            conv2, <span class="number">96</span>, <span class="number">3</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem2_3x3_2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([conv1, conv2], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            concat, <span class="number">192</span>, <span class="number">3</span>, stride=<span class="number">2</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_stem3_3x3_s2&quot;</span>)</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=concat, pool_size=<span class="number">3</span>, pool_stride=<span class="number">2</span>, pool_type=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([conv1, pool1], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inception_A模块，同样不再赘述</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inceptionA</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=data, pool_size=<span class="number">3</span>, pool_padding=<span class="number">1</span>, pool_type=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            pool1, <span class="number">96</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_1x1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">96</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_1x1_2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">64</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_3x3_reduce&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">96</span>,</span><br><span class="line">            <span class="number">3</span>,</span><br><span class="line">            padding=<span class="number">1</span>,</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_3x3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            data,</span><br><span class="line">            <span class="number">64</span>,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_3x3_2_reduce&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">96</span>,</span><br><span class="line">            <span class="number">3</span>,</span><br><span class="line">            padding=<span class="number">1</span>,</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_3x3_2&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">96</span>,</span><br><span class="line">            <span class="number">3</span>,</span><br><span class="line">            padding=<span class="number">1</span>,</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_a&quot;</span> + name + <span class="string">&quot;_3x3_3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([conv1, conv2, conv3, conv4], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reduction_A模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reductionA</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=data, pool_size=<span class="number">3</span>, pool_stride=<span class="number">2</span>, pool_type=<span class="string">&#x27;max&#x27;</span>, pool_padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">384</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_a_3x3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">192</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_a_3x3_2_reduce&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3, <span class="number">224</span>, <span class="number">3</span>, padding=<span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_a_3x3_2&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3, <span class="number">256</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_a_3x3_3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([pool1, conv2, conv3], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inception_B模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inceptionB</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=data, pool_size=<span class="number">3</span>, pool_padding=<span class="number">1</span>, pool_type=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            pool1, <span class="number">128</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">384</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x1_2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">192</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x7_reduce&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">224</span>, (<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x7&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">3</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_7x1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            data,</span><br><span class="line">            <span class="number">192</span>,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_7x1_2_reduce&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">192</span>, (<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x7_2&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">224</span>, (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">3</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_7x1_2&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">224</span>, (<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_1x7_3&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">3</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_b&quot;</span> + name + <span class="string">&quot;_7x1_3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([conv1, conv2, conv3, conv4], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reduction_B模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reductionB</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=data, pool_size=<span class="number">3</span>, pool_stride=<span class="number">2</span>, pool_type=<span class="string">&#x27;max&#x27;</span>, pool_padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">192</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_b_3x3_reduce&quot;</span>)</span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            conv2, <span class="number">192</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_b_3x3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">256</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="number">1</span>,name=<span class="string">&quot;reduction_b_1x7_reduce&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;reduction_b_1x7&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">320</span>, (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">3</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;reduction_b_7x1&quot;</span>)</span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            conv3, <span class="number">320</span>, <span class="number">3</span>, stride=<span class="number">2</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;reduction_b_3x3_2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat([pool1, conv2, conv3], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inception_C模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inceptionC</span>(<span class="params">self, data, name=<span class="literal">None</span></span>):</span><br><span class="line">        pool1 = fluid.layers.pool2d(</span><br><span class="line">            <span class="built_in">input</span>=data, pool_size=<span class="number">3</span>, pool_padding=<span class="number">1</span>, pool_type=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">        conv1 = self.conv_bn_layer(</span><br><span class="line">            pool1, <span class="number">256</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv2 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">256</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x1_2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">384</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x1_3&quot;</span>)</span><br><span class="line">        conv3_1 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x3&quot;</span>)</span><br><span class="line">        conv3_2 = self.conv_bn_layer(</span><br><span class="line">            conv3,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_3x1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            data, <span class="number">384</span>, <span class="number">1</span>, act=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x1_4&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">448</span>, (<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x3_2&quot;</span>)</span><br><span class="line">        conv4 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">512</span>, (<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_3x1_2&quot;</span>)</span><br><span class="line">        conv4_1 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">            padding=(<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_1x3_3&quot;</span>)</span><br><span class="line">        conv4_2 = self.conv_bn_layer(</span><br><span class="line">            conv4,</span><br><span class="line">            <span class="number">256</span>, (<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">            padding=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            act=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">            name=<span class="string">&quot;inception_c&quot;</span> + name + <span class="string">&quot;_3x1_3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        concat = fluid.layers.concat(</span><br><span class="line">            [conv1, conv2, conv3_1, conv3_2, conv4_1, conv4_2], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> concat</span><br></pre></td></tr></table></figure><h4 id="训练和预测"><a href="#训练和预测" class="headerlink" title="训练和预测"></a>训练和预测</h4><p>为了能够更好地评价不同神经网络模型的训练性能、实际预测效果等，我们采用控制变量法，使用相同的训练和预测流程设计，训练使用的参数统一为batch_size=128、epoch=3，预测使用的待预测图像为一张狗的照片。运行程序、进行训练和预测的主要流程如下所示：</p><ul><li>首先，我们需要保证项目之前的输出被全部清空，且在“Kernel操作”中进行过至少一次的“重启”操作。</li><li>之后，在最后一个cell的程序主函数中的model变量中确定对应模型的名称，若只需要使用已生成的模型文件进行预测而不需要再次训练，可以注释掉train训练主函数，只运行predict预测主函数。</li><li>最后，选中第一个cell，点击“Notebook操作”中的“运行当前及下方所有”，开始程序的运行。</li></ul><p>各模型的具体运行结果截图可以参见下一章节“实验数据”。</p><h3 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h3><p>在训练和预测流程执行完毕后，对于各个模型程序输出的原始数据结果截图如下所示：</p><h4 id="VGG模型-1"><a href="#VGG模型-1" class="headerlink" title="VGG模型"></a>VGG模型</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/data-vgg.png" alt="VGG 模型的运行结果"></p><center>图 3.1 VGG模型的运行结果（仅训练数据输出）</center><p>可能是由于最终训练结果的精确度过低，在预测过程中出现了报错的情况，因此此处没有预测结果。</p><h4 id="ResNet模型-1"><a href="#ResNet模型-1" class="headerlink" title="ResNet模型"></a>ResNet模型</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/data-resnet.png" alt="ResNet 模型的运行结果"></p><center>图3.2 ResNet模型的训练和预测结果</center><h4 id="GoogleNet模型-1"><a href="#GoogleNet模型-1" class="headerlink" title="GoogleNet模型"></a>GoogleNet模型</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/data-googlenet.png" alt="GoogleNet 模型的运行结果"></p><center>图3.3 GoogleNet模型的训练和预测结果</center><h4 id="Inception-V4模型-1"><a href="#Inception-V4模型-1" class="headerlink" title="Inception-V4模型"></a>Inception-V4模型</h4><p>由于在理论上Inception-V4模型应当是GoogleNet（Inception-V1）的改进，但是首次训练和预测后的结果都完全差于GoogleNet，于是我们查询了该模型代码来源的GitHub仓库上的参数设置，发现batch_size应当由128改为256。</p><p>在针对该模型设置该特有参数值之后，我们进行了第二次的额外训练和预测。两次训练和预测的原始数据如下所示：</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/data-inception-v4-1.png" alt="Inception-v4 模型的首次运行结果"></p><center>图3.4 Inception-V4模型首次运行时的训练和预测结果</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/data-inception-v4-2.png" alt="Inception-v4 模型修改后的运行结果"></p><center>图3.5 Inception-V4模型修改batch_size之后<br>再次运行时的训练和预测结果</center><h3 id="实验数据处理"><a href="#实验数据处理" class="headerlink" title="实验数据处理"></a>实验数据处理</h3><h4 id="VGG模型数据图表"><a href="#VGG模型数据图表" class="headerlink" title="VGG模型数据图表"></a>VGG模型数据图表</h4><p>由于在“实验数据”环节所述的程序报错的关系，未能够通过python代码自动生成损失率图表，此处使用Excel生成相关图表：</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-vgg-1.png" alt="vgg 训练数据图表"></p><center>图4.1 VGG训练数据图表</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-vgg-2.png" alt="VGG 测试数据图表"></p><center>图4.2 VGG测试数据图表</center><p>可以看出，VGG模型在当前训练环境下，训练过程中损失率震荡较大，下降速率较慢，准确率同样在上下波动且上升速率较慢，而使用测试数据集生成的测试数据基本保持不变。而且准确率相当低，在10%左右徘徊，说明VGG模型在当前环境下的综合性能较差。</p><h4 id="ResNet模型数据图表"><a href="#ResNet模型数据图表" class="headerlink" title="ResNet模型数据图表"></a>ResNet模型数据图表</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-resnet-1.png" alt="vgg 损失率数据图表"></p><center>图4.3 实验程序生成的ResNet的训练和测试损失率图表</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-resnet-2.png" alt="vgg 准确率数据图表"></p><center>图4.4 ResNet的训练和测试准确率图表</center><p>ResNet模型在当前训练环境下，训练过程中损失率震荡较小，下降速率在训练初期较快，之后趋于平缓。虽然测试过程中的损失率虽然震荡较大，但是参照训练过程，确实维持在一个合理的区间内。</p><p>在训练和测试过程中，ResNet模型的准确率都保持着不断升高的趋势，最终的准确率接近70%。</p><p>但是，在实际的预测过程中，ResNet模型却将带预测的图片分类为了horse马，说明在实际应用过程中，该模型仍存在可以提升的空间。</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/dog-resnet.png" alt="restnet 实际预测结果"></p><center>图4.5 ResNet模型实际预测结果</center><h4 id="GoogleNet模型数据图表"><a href="#GoogleNet模型数据图表" class="headerlink" title="GoogleNet模型数据图表"></a>GoogleNet模型数据图表</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-googlenet-1.png" alt="googlenet 损失率数据图表"></p><center>图4.6 实验程序生成的GoogleNet的训练和测试损失率图表</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-googlenet-2.png" alt="googlenet 准确率数据图表"></p><center>图4.7 GoogleNet的训练和测试准确率图表</center><p>GoogleNet模型在当前训练环境下，训练过程中损失率几乎没有震荡，下降速率在训练初期极快，之后趋于平缓且不断逼近0。测试过程中的损失率曲线与训练过程曲线近乎重合。以上现象说明了在当前环境下，该模型的训练效果相当出色。</p><p>在训练和测试过程中，GoogleNet模型的准确率都保持着不断升高的趋势，最终的准确率在60%左右。</p><p>除了下降速率曲线之外，该模型还有如下2点令人印象深刻之处：</p><ul><li>训练速度快：相比其他模型，该模型的训练耗时相当少，当其他模型需要5~10秒才能训练完一个pass时，该模型只需1秒左右的时间，因此训练速度极快。我们认为训练速度快的主要原因是：该模型的网络层数相较于其他模型更少，且3个子网络分别输出损失率并加权求和的操作有助于优化器更加精确地计算出当前梯度，从而更准确地调整网络中各层神经元的权重参数。</li><li>模型实际预测结果精准：如下图所示，在实际预测的过程中，该模型是唯一一个将该图片正确分类为dog狗的，可以看出该模型在实际应用方面的准确度相当高，虽然数据层面的准确率60%略逊于ResNet的70%。</li></ul><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/dog-googlenet.png" alt="GoogleNet 模型实际预测结果"></p><center>图4.8 GoogleNet模型实际预测结果</center><h4 id="Inception-V4模型数据图表"><a href="#Inception-V4模型数据图表" class="headerlink" title="Inception-V4模型数据图表"></a>Inception-V4模型数据图表</h4><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-inception-v4-1.png" alt="inception-v4 损失率数据图表"></p><center>图4.9 实验程序生成的Inception-V4的训练和测试损失率图表</center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-inception-v4-2.png" alt="inception-v4 损失率数据图表"></p><center>图4.10 Inception-V4的训练和测试准确率图表</center><p>Inception-V4模型在当前训练环境下，训练过程中损失率震荡严重，下降速率缓慢。测试过程中的损失率曲线与训练过程曲线同样近乎重合。以上现象说明了在当前环境下该模型训练效果较差。</p><p>在训练和测试过程中，Inception-V4模型的准确率都保持着不断升高的趋势，但是最终的准确率在30%左右。</p><p>在实际预测中，该模型将带预测图片分类为了truck卡车，说明其模型准确度确实不高。</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/dog-inception-v4-1.png" alt="Inception-v4 模型实际预测结果"></p><center>图4.11 Inception-v4 模型实际预测结果</center><p>我们在“实验数据”环节就已经根据程序输出的实验数据提出了“为何作为GoogleNet的迭代版本，Inception-V4反而在性能和实际效果上不如GoogleNet”的疑问并根据相关资料修改了batch_size为256，并进行了第二次的训练和预测。实验数据处理如下所示：</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-inception-v4-3.png" alt="修改后inception-v4 损失率数据图表"></p><center>图4.12 调整参数第二次训练后<br><br>实验程序生成的Inception-V4的训练和测试损失率图表<br></center><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/graph-inception-v4-4.png" alt="修改后inception-v4 准确率数据图表"></p><center>图4.13 调整参数第二次训练后<br><br>Inception-V4的训练和测试准确率图表<br></center><p>可以看出，Inception-V4模型在修改参数后的训练环境下，训练过程中损失率震荡有所收敛，但下降速率依旧缓慢。测试过程中的损失率曲线与训练过程曲线同样近乎重合。以上现象说明了在当前环境下该模型训练效果仍然较差。</p><p>在训练和测试过程中，Inception-V4模型的准确率都保持着不断升高的趋势，但是最终的准确率还是在30%左右。<br>在实际预测中，该模型将带预测图片分类为了automobile轿车，说明其模型准确度仍然不高</p><p><img src="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/dog-inception-v4-2.png" alt="修改后Inception-v4 模型实际预测结果"></p><center>图4.11 调整参数第二次训练后<br><br>GoogleNet模型实际预测结果<br></center><p>我们初步怀疑调整参数后效果仍然较差的原因有如下两点：</p><ul><li>epoch的次数仍然偏少，因为Inception_V4的网络层数明显多于GoogleNet，因此需要更长时间的训练才能够获得一个较好的模型，但由于使用CPU训练速度较慢，实验时间有限，暂时不考虑进行更多次的实验。</li><li>据Inception_V4对应的论文《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》中的描述，该模型的设计主要考虑到了TensorFlow等框架在内存分配等方面的优化设计，因此也存在着paddlepaddle不支持这些特性导致的模型性能表现的不佳。</li></ul><h3 id="实验结果与分析"><a href="#实验结果与分析" class="headerlink" title="实验结果与分析"></a>实验结果与分析</h3><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><p>针对在“实验数据处理”章节中对实验数据的图表绘制处理和初步分析，我们能够得出以下综合分析结果：</p><ul><li>使用控制变量法在相同环境（尤其是采用相同参数）下的不同模型进行的性能评价结果，这一方法存在着很大的局限性。本次实验尤为突出的表现正是Inception系列的V1（GoogleNet）和V4之间的可以称之为逆转性的结果。在batch_size=128、epoch=3的条件下，V1在训练速度、训练数据展示的效果、实际预测效果上都优于V4。而出于对这一反常问题的好奇，我们将batch_size按照V4代码的初始来源处的参数改为了batch_size=256，结果效果改善程度有限。这些说明了控制变量法并不能够全面地衡量不同模型之间的性能和实际效果。</li><li>在当前环境下，GoogleNet和ResNet在各项实验数据指标上优于其他模型，而GoogleNet为最优。ResNet仅在准确率的数据层面上的70%略胜于GoogleNet的60%，而GoogleNet无论是在训练所需时间、损失率曲线的震荡程度、损失率曲线的下降速率、以及实际预测的准确程度都明显优于ResNet，且是唯一一个正确分类了带预测图片的模型。</li><li>但是这并不意味着Inception系列的Inception模块设计不存在缺陷，也并不意味着Inception系列不应该引入ResNet的结构设计，相反，ResNet的残差模块的结构设计在实际研究和应用过程中，确实有其“提升深层次网络训练结果的准确度和收敛速度”的独到之处。只不过由于实验时间的关系，我们并未继续引入Inception-ResNet-V1、Inception-ResNet-V2等两者相结合的模型，并进行进一步的实验和分析。</li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><h5 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h5><p>本次实验基于百度AI Stuido平台的在线项目平台，使用了包括VGG、ResNet、GoogleNet（Inception-V1）、Inception-V4等图像分类神经网络模型以及CIFAR10数据集，对相同环境条件下的不同模型在训练和预测过程中的性能开销、数据指标变化情况、实际预测情况等进行了详细的分析讨论。尽管通过实验表明，本次实验所使用的控制变量法存在着一定的局限性，但是本次实验仍然得出了GoogleNet（代表Inception系列）、ResNet在性能指标和实际效果上较为优秀的结论，这肯定了Inception模块、残差模块的结构设计在模型训练、实际预测等多方面相较于传统的多层神经网络存在着相当大的优势。</p><p>本次实验目的步骤明确、实验过程较为顺利、对实验结果的也进行了较为细致的处理和分析，是一次虽然存在问题，但在一定程度上较为成功的人工智能课程实验。</p><h5 id="成果收获"><a href="#成果收获" class="headerlink" title="成果收获"></a>成果收获</h5><p>经过本次实验，我们团队成员收获了以下成果：</p><ul><li>通过研读paddlepaddle官方教程和文档以及其他网上相关资料、编写、移植以及逐行注释不同模型代码、处理分析实验数据等方式，我们锻炼了团队合作完成“查阅人工智能相关文献、理解相关基本概念、使用代码实现相应模型的结构设计、对实验数据进行处理和分析”的一整套人工智能领域研究流程的实战能力。</li><li>通过对paddlepaddle框架的学习，我们初步掌握了深度学习框架、以及其他辅助用途的python库的基本使用方式，了解了使用深度学习框架的需要进行的“数据处理、参数设置、模型训练、测试集测试、结果输出”等一般流程。</li><li>通过这次实验，我们也巩固了团队合作的情况下完成实验的任务分配、进度协调、成员沟通等综合能力。</li></ul><h5 id="待改进的地方"><a href="#待改进的地方" class="headerlink" title="待改进的地方"></a>待改进的地方</h5><p>经过本次实验，我们认为仍然存在以下待改进的地方：</p><ul><li>实验对不同模型的评估比较方法存在问题。控制单一变量法并不能够全面地让不同模型发挥出应有的性能效果，应当考虑给予不同模型以其目前研究水平下最佳的环境配置，通过基于单一测试数据的多次实际预测效果测试来衡量不同模型的性能，其结果会更好。</li><li>未能引入更多较为新型的图像分类模型例如Inception-ResNet系列模型等，进行范围更加广泛的比较和分析。</li></ul><h3 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h3><p>最后，在整篇文章的结尾，我还是要一如既往地感谢本次与我合作完成这一项目的搭档：Jet Lian，他主要负责本次项目的相关文献资料的查阅和汇总，VGG、ResNet、Inception-V4模型代码的编写、注释，实验程序执行和实验数据结果的处理、分析，“实验内容与步骤”之后的实验报告的撰写。</p><p>在他的合作之下，我才能够完成我自己的工作内容：实验方案选取、实验环境初始化、项目训练和预测函数等模块结构的搭建，基于paddlepaddle早期版本GoogleNet模型代码的移植、编写和注释，“实验内容与步骤”及之前的实验报告撰写。</p><p>作为室友兼搭档，我个人是十分敬佩他分析问题、解决问题和实际编码的强大综合能力的，像他这样成绩优秀且技术能力过硬的同学，在USTB的CS专业中乃至SCCE学院中都是罕见的。真的十分荣幸，能够在这三年的时光中与他为友，在技术成长的道路上并肩前行。</p><p>同时，我也十分感谢《人工智能》专业选修课的任课老师王睿老师、以及本次和AI专选课合作的百度AI Studio在线实验平台，正是老师和工作人员们的通力合作和不懈努力，为我们本届CS学生创造了一次实际体验深度学习训练到预测全过程的宝贵机会。希望这样的机会在未来的SCCE学院乃至整个行业会越来越多，再次感谢这些为技术知识的传播做出贡献的人们！</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>百度paddlepaddle官网教程《深度学习基础教程》的《图像分类》章节：<br><a href="http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html">http://paddlepaddle.org/documentation/docs/zh/1.4/beginners_guide/basics/image_classification/index.html</a></li><li>基于paddlepaddle的inception-v4模型代码：<br><a href="https://github.com/PaddlePaddle/models/blob/43cdafbb97e52e6d93cc5bbdc6e7486f27665fc8/PaddleCV/image_classification/models/inception_v4.py">https://github.com/PaddlePaddle/models/blob/43cdafbb97e52e6d93cc5bbdc6e7486f27665fc8/PaddleCV/image_classification/models/inception_v4.py</a></li><li>基于paddlepaddle旧版的googlenet模型（本文中展示的是基于该项目移植到新版paddlepaddle后的代码）：<br><a href="https://www.cnblogs.com/charlotte77/p/8066867.html">https://www.cnblogs.com/charlotte77/p/8066867.html</a></li><li>Google Inception系列论文《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》：<br><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPDFInterstitial/14806/14311">https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPDFInterstitial/14806/14311</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Training Configuration for Yolo-darknet</title>
      <link href="/2018/11/28/Training-Configuration-for-Yolo-darknet/"/>
      <url>/2018/11/28/Training-Configuration-for-Yolo-darknet/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Everything’s coming up roses.</p></blockquote><p>续上次的笔记<br>分享yolo-darknet神经网络训练全过程的配置经验</p><span id="more"></span><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于本文中描述的yolo-darknet训练配置流程来源较多，而且训练配置时间为今年暑期，距离本文完稿时间较远，因此本文不可避免地会存在一定的失误和错漏。恳请发现问题的读者不吝赐教，通过首页的联系方式向作者提出宝贵意见。</p><h2 id="数据集的标注、修改"><a href="#数据集的标注、修改" class="headerlink" title="数据集的标注、修改"></a>数据集的标注、修改</h2><p>数据集的采集来源以及采集方式属于项目内容，此处暂时不便叙述。对于采集得到的数据集，尤其是针对yolo-darknet的图片数据集，应当至少满足如下的要求：</p><ul><li>文件名称中不应当出现中文</li><li>多次采集得到的文件应当分开命名前缀，否则存在同名文件覆盖的问题</li><li>最好是同一种后缀格式，例如jpg格式。后缀大写JPG和小写jpg，darknet不会认为是同一种文件类型而报错。另外，png格式比较灵活，可以强行改成jpg后缀且内容仍可以读取</li></ul><p>本项目中除了采集了原始数据之外，也通过python脚本对图片素材进行翻转、随机颜色等基本变换来对数据集规模进行扩充。此为额外操作，不影响yolo-darknet训练过程。</p><p>数据集的标注采用的是基于python的ImageLabel，标注界面是可视化的，流程基本上是：</p><ul><li>设置你标注的物体对应的标签，例如dog，cat等，可以设置默认标签</li><li>打开素材文件夹到程序中，设置当前的标签，对图片进行逐个画框标注</li><li>标注后自动生成数个xml文件，xml文件的内容一般如下</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">folder</span>&gt;</span>图片文件夹<span class="tag">&lt;/<span class="name">folder</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filename</span>&gt;</span>图片名称<span class="tag">&lt;/<span class="name">filename</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">path</span>&gt;</span>图片路径<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">database</span>&gt;</span>Unknown<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">width</span>&gt;</span>600<span class="tag">&lt;/<span class="name">width</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">height</span>&gt;</span>338<span class="tag">&lt;/<span class="name">height</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">segmented</span>&gt;</span>0<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>标签名字<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">pose</span>&gt;</span>Unspecified<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">truncated</span>&gt;</span>0<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmin</span>&gt;</span>291<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymin</span>&gt;</span>76<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmax</span>&gt;</span>412<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymax</span>&gt;</span>192<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br></pre></td></tr></table></figure><p>基本上就是对于标注的方框的位置和大小的记录。标注生成的是整个VOC数据集文件夹，一般有两个文件夹：图片文件夹Image和标记文件夹xml。标记文件夹中每一个xml文件的文件名基本上都对应了的图片文件夹中的图片文件。</p><p>应当注意的是，一旦移动了xml文件夹或整个数据集文件夹，必须将所有xml文件中的图片文件夹、图片路径改成对应的新文件夹、新路径，否则必然报错。</p><p>但问题是，一旦数据集规模像本项目一样巨大时，人工逐个更改xml就十分困难。所以需要python脚本进行批量文件处理。此处摘录一部分代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">&#x27;utf8&#x27;</span>) </span><br><span class="line"></span><br><span class="line">path = <span class="string">&quot;/home/blean/VOC/validateImage/&quot;</span></span><br><span class="line">oldpath = <span class="string">&quot;/home/blean/VOC/pos/&quot;</span></span><br><span class="line">newpath = <span class="string">&quot;/home/blean/VOC/Image/&quot;</span></span><br><span class="line">filelist = os.listdir(path)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> files <span class="keyword">in</span> filelist:</span><br><span class="line">    <span class="keyword">if</span> os.path.splitext(files)[<span class="number">1</span>] != <span class="string">&quot;.jpg&quot;</span> <span class="keyword">and</span> os.path.splitext(files)[<span class="number">1</span>] != <span class="string">&quot;.txt&quot;</span>:</span><br><span class="line">        tmp = os.path.splitext(files)[<span class="number">0</span>]</span><br><span class="line">        os.rename(path+files, path+tmp+<span class="string">&quot;.jpg&quot;</span>)</span><br><span class="line">        <span class="comment"># 强行将非jpg的后缀，例如JPG大写后缀或png后缀更改成jpg</span></span><br><span class="line">        <span class="built_in">print</span> path+files</span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    tree = ET.parse(path+files)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    filename = root.findall(<span class="string">&#x27;filename&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    tmp = os.path.splitext(filename)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 寻找xml文件中对应的文件名</span></span><br><span class="line">    <span class="built_in">print</span> path+tmp+<span class="string">&quot;.xml&quot;</span></span><br><span class="line">    os.rename(path+files, path+tmp+<span class="string">&quot;.xml&quot;</span>)</span><br><span class="line">    <span class="comment"># 同样地将xml文件名改成后缀修改后的图片文件名</span></span><br><span class="line">    root.findall(<span class="string">&#x27;path&#x27;</span>)[<span class="number">0</span>].text = tmp.replace(oldpath, newpath)</span><br><span class="line">    <span class="comment"># 修改路径</span></span><br><span class="line">    tmp = root.findall(<span class="string">&#x27;filename&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">    <span class="keyword">if</span> tmp.find(<span class="string">&quot;捕获&quot;</span>) != -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span> tmp</span><br><span class="line">        root.findall(<span class="string">&#x27;filename&#x27;</span>)[<span class="number">0</span>].text = tmp.replace(<span class="string">&quot;捕获&quot;</span>, <span class="string">&quot;buhuo&quot;</span>)</span><br><span class="line">        tree.write(path+files)</span><br><span class="line">    <span class="comment"># 修改某些中文文件名</span></span><br><span class="line">    root.findall(<span class="string">&#x27;folder&#x27;</span>)[<span class="number">0</span>].text = tmp.replace(<span class="string">&quot;pos&quot;</span>, <span class="string">&quot;Image&quot;</span>)</span><br><span class="line">    <span class="comment"># 修改图片文件夹名称</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> i</span><br><span class="line"><span class="comment"># 打印总数</span></span><br></pre></td></tr></table></figure><p>注：以上代码是本人为了修正数据集格式自行编写的，具有很强的临时性，是不同功能的python代码之间的整合，如果不需要某些功能，可以将对应代码手动注释掉</p><h2 id="训练数据集和验证数据集的拆分"><a href="#训练数据集和验证数据集的拆分" class="headerlink" title="训练数据集和验证数据集的拆分"></a>训练数据集和验证数据集的拆分</h2><p>数据集应当分成训练集和验证集，以便于对训练效果进行评估。<br>这里作者直接参考了这篇CSDN上的文章<a href="https://blog.csdn.net/qq_34484472/article/details/73135354">《YOLO训练自己的数据集》</a>中的python脚本，内容摘录如下：</p><blockquote></blockquote><pre><code>下载链接：http://pan.baidu.com/s/1hs22I7U 密码：wdv0运行traindata.py：生成trainImage文件夹，存放训练图片；生成trainImageXML文件夹，存放训练图片xml标签；生成validateImage文件夹，存放验证集图片；生成validateImageXML文件夹，存放验证集图片的xml标签。运行trans.py，生成trainImageLabelTxt文件夹，存放训练图片通过xml标签转化得到的txt文件（若在训练过程提示txt文件找不到，则把此文件夹下的txt文件夹移动到trainImage文件夹）；生成validateImageLabelTxt文件夹，道理一样。另外得到的trainImagePath.txt和validateImagePath.txt存放着训练图片和验证图片的路径。</code></pre><blockquote></blockquote><p>下载好的python脚本一般不能立即用，根据运行python脚本出现的报错，应当对其进行相应的修改，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classes = [<span class="string">&quot;cat&quot;</span>] <span class="comment">#把这个标签改成你自己的数据集中标记的标签</span></span><br><span class="line"><span class="comment">#那个sets看起来很奇怪，但是不用改也能用。python研究的少，暂时不知道具体原因</span></span><br></pre></td></tr></table></figure><h2 id="对darknet的配置和更改"><a href="#对darknet的配置和更改" class="headerlink" title="对darknet的配置和更改"></a>对darknet的配置和更改</h2><p>darknet本身并非完全开箱即用的图像识别训练框架，因此需要对它进行有针对性的配置和必要的更改。此处同样是根据<a href="https://blog.csdn.net/qq_34484472/article/details/73135354">《YOLO训练自己的数据集》</a>以及其他几篇文章的指导和建议进行配置的，主要有以下几点：</p><p>首先，对darknet的cfg/voc.data进行配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">classes= 标签类别总数</span><br><span class="line">train = 填之前脚本生成的训练集文件列表trainImageId.txt</span><br><span class="line">valid = 填之前脚本生成的验证集文件列表validateImagePath.txt</span><br><span class="line">names = data/xxx.names</span><br><span class="line">backup = 存放训练结果模型的路径</span><br></pre></td></tr></table></figure><p>在data文件夹下的names文件中，每行写一条标签名称</p><p>其次，对要使用的神经网络版本yolo2-voc对应的配置文件yolo2-voc.cfg，应当更改以下几处：</p><ul><li>将最后的[region]层神经网络的配置中的classes改为1（即标记类别的总数）</li><li>将最后一个[convolutional]卷积层中的filter改为30（filter的公式filters=(classes+ coords+ 1)<em> (NUM) ，我的是(1+4+1)</em> 5=30）</li></ul><p>注：这里coords可以认为是坐标，设置的标记是一个方框则取4。NUM是神经网络的层数。filter公式的来源请参见国外开发者们的讨论：<a href="https://groups.google.com/forum/#!topic/darknet/B4rSpOo84yg">https://groups.google.com/forum/#!topic/darknet/B4rSpOo84yg</a></p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>在yolo的官网下载预训练模型，地址：<a href="http://pjreddie.com/media/files/darknet53.conv.74">http://pjreddie.com/media/files/darknet53.conv.74</a></p><p>并执行训练命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector train cfg/voc.data cfg/yolov2-voc.cfg darknet53.conv.74</span><br></pre></td></tr></table></figure><p>之后便开始了对神经网络的训练，在1000次训练之内，每100次就在backup文件夹中生成一次权重模型，在1000次训练以上，每10000次生成一次权重模型。本项目的最终训练次数达到了50000次。</p><p><img src="/2018/11/28/Training-Configuration-for-Yolo-darknet/training3.png" alt="训练过程截图"></p><p>上图为训练到500次左右时的结果截图</p><p><img src="/2018/11/28/Training-Configuration-for-Yolo-darknet/training4.png" alt="训练过程截图"></p><p>训练生成的模型文件</p><h2 id="批量测试、评估以及需要对darknet进行的相应修改"><a href="#批量测试、评估以及需要对darknet进行的相应修改" class="headerlink" title="批量测试、评估以及需要对darknet进行的相应修改"></a>批量测试、评估以及需要对darknet进行的相应修改</h2><p>本人<a href="https://lmy98129.github.io/2018/02/20/Environment-Configuration-for-Yolo-darknet">之前的笔记</a>中曾经提到了使用单张图片测试，以及连接计算机摄像头、网络视频推流进行实时识别的命令，命令内容大致如下：</p><p>单张图片：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detect cfg/yolo.cfg yolo.weight data/horses.jpg</span><br></pre></td></tr></table></figure></p><p>电脑摄像头：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector demo cfg/voc.data cfg/tiny-yolo-voc.cfg weights/tiny-yolo-voc.weights</span><br></pre></td></tr></table></figure></p><p>手机摄像头（通过网络视频实时推流，使用工具为IP摄像头APP）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector demo data/coco.data yolo.cfg yolo.weights http://192.168.191.2:8080/video</span><br></pre></td></tr></table></figure><p>得到的效果大致如下：</p><p>实地场景：</p><p><img src="/2018/11/28/Training-Configuration-for-Yolo-darknet/testing7.png" alt="测试过程截图"></p><p>网络图片：</p><p><img src="/2018/11/28/Training-Configuration-for-Yolo-darknet/testing1.png" alt="测试过程截图"></p><p>但是，可以看出这样手动输入命令进行逐个测试的方法，在测试上文中提到的从标记数据集中拆分出来的有一定数量图片的验证集时十分地不友好。而且必须手工收集每次测试中得到的准确度信息、手工进行统计计算。</p><p>所以这里参考了CSDN上的另一篇文章<a href="https://blog.csdn.net/mieleizhi0522/article/details/79989754">《YOLOv3批量测试图片并保存在自定义文件夹下》</a>以及简书上的一篇文章<a href="https://blog.csdn.net/mieleizhi0522/article/details/79989754">《Darknet 评估训练好的网络的性能》</a>对darknet中的example文件夹下的detector.c文件中的代码进行更改，以便于进行批量测试、统计、评估模型在验证集上的准确度，并输出结果：</p><ol><li>修改validate_detector_recall函数定义和调用为：</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">validate_detector_recall</span><span class="params">(<span class="type">char</span> *datacfg, <span class="type">char</span> *cfgfile, <span class="type">char</span> *weightfile)</span></span></span><br><span class="line"><span class="function"><span class="title">validate_detector_recall</span><span class="params">(datacfg, cfg, weights)</span></span>;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改validate_detector_recall的初始化代码</li></ol><p>修改前：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list *plist = <span class="built_in">get_paths</span>(<span class="string">&quot;data/voc.2007.test&quot;</span>);</span><br><span class="line"><span class="type">char</span> **paths = (<span class="type">char</span> **)<span class="built_in">list_to_array</span>(plist);</span><br></pre></td></tr></table></figure></p><p>修改后：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list *options = <span class="built_in">read_data_cfg</span>(datacfg);</span><br><span class="line"><span class="type">char</span> *valid_images = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;valid&quot;</span>, <span class="string">&quot;/home/blean/VOC/validateImagePath.txt&quot;</span>);</span><br><span class="line">list *plist = <span class="built_in">get_paths</span>(valid_images);</span><br><span class="line"><span class="type">char</span> **paths = (<span class="type">char</span> **)<span class="built_in">list_to_array</span>(plist);</span><br></pre></td></tr></table></figure></p><ol start="3"><li>修改结束后需要重新编译darknet主程序，命令如下</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure><p>在完成上述修改后即可使用darknet的recall命令进行评估测试并输出结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector recall cfg/voc.data cfg/yolov2-voc.cfg backup/yolov2-voc_50000.weights -out drowning_recall.txt</span><br></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> Number Correct Total Rps/Img IOU Recall </span><br><span class="line"> 0     1     1RPs/Img: 23.00IOU: 71.42%Recall:100.00%</span><br><span class="line"> 1     2     2RPs/Img: 19.00IOU: 66.04%Recall:100.00%</span><br><span class="line"> 2     3     3RPs/Img: 31.00IOU: 65.52%Recall:100.00%</span><br><span class="line"> 3     4     4RPs/Img: 31.75IOU: 65.22%Recall:100.00%</span><br><span class="line"> 4     5     5RPs/Img: 29.40IOU: 65.55%Recall:100.00%</span><br><span class="line"> 5     6     6RPs/Img: 29.67IOU: 67.34%Recall:100.00%</span><br><span class="line"> 6     6     7RPs/Img: 32.00IOU: 60.25%Recall:85.71%</span><br><span class="line"> 7     7     8RPs/Img: 35.12IOU: 59.75%Recall:87.50%</span><br><span class="line"> 8     8     9RPs/Img: 33.11IOU: 60.55%Recall:88.89%</span><br><span class="line"> 9     8    10RPs/Img: 33.20IOU: 59.48%Recall:80.00%</span><br><span class="line">10     9    11RPs/Img: 34.00IOU: 59.27%Recall:81.82%</span><br><span class="line">11    10    12RPs/Img: 33.00IOU: 59.65%Recall:83.33%</span><br><span class="line">12    11    13RPs/Img: 32.00IOU: 60.33%Recall:84.62%</span><br><span class="line">13    12    14RPs/Img: 30.64IOU: 60.85%Recall:85.71%</span><br><span class="line">14    12    14RPs/Img: 29.60IOU: 60.85%Recall:85.71%</span><br><span class="line">15    13    15RPs/Img: 29.62IOU: 61.41%Recall:86.67%</span><br></pre></td></tr></table></figure><p>其中各项参数的解释如下：</p><ul><li>Number表示处理到第几张图片。</li><li>Correct表示正确的识别出了多少bbox（即标记目标物体的方框）。这个值算出来的步骤是这样的，丢进网络一张图片，网络会预测出很多bbox，每个bbox都有其置信概率，概率大于threshold的bbox与实际的bbox，也就是labels中txt的内容计算IOU，找出IOU最大的bbox，如果这个最大值大于预设的IOU的threshold，那么correct加1。</li><li>Total表示实际有多少个bbox。</li><li>Rps/img表示平均每个图片会预测出来多少个bbox。</li><li>IOU： 这个是预测出的bbox和实际标注的bbox的交集 除以 他们的并集。显然，这个数值越大，说明预测的结果越好。</li><li>Recall召回率， 意思是检测出物体的个数 除以 标注的所有物体个数。通过代码我们也能看出来就是Correct除以Total的值。</li></ul><p>可以从最后一条代表处理了全部验证集的统计结果看出，经过验证集的检验，训练得出的模型识别目标物体的总正确率大致在86%左右，可以说训练效果较为理想。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>YOLO-darknet官网<br><a href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a></li><li>YOLO训练自己的数据集：<br><a href="https://blog.csdn.net/qq_34484472/article/details/73135354">https://blog.csdn.net/qq_34484472/article/details/73135354</a></li><li>YOLOv3批量测试图片并保存在自定义文件夹下：<br><a href="https://blog.csdn.net/mieleizhi0522/article/details/79989754">https://blog.csdn.net/mieleizhi0522/article/details/79989754</a></li><li>Darknet 评估训练好的网络的性能：<br><a href="https://blog.csdn.net/mieleizhi0522/article/details/79989754">https://blog.csdn.net/mieleizhi0522/article/details/79989754</a></li><li>Environment-Configuration-for-Yolo-darknet | NeXT （就是之前的那篇笔记）<br><a href="https://lmy98129.github.io/2018/02/20/Environment-Configuration-for-Yolo-darknet">https://lmy98129.github.io/2018/02/20/Environment-Configuration-for-Yolo-darknet</a></li></ol><blockquote><p>最后，这是本站的第八篇正式发文，感谢阅读。<br>如有意见和建议，欢迎通过首页的联系方式联系作者，<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes About Recent Projects 3</title>
      <link href="/2018/06/28/Notes-About-Recent-Projects-3/"/>
      <url>/2018/06/28/Notes-About-Recent-Projects-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>The most stupid work<br>might be the most important one to cherish.</p></blockquote><p>此处收录一些近期的项目笔记，<br>这次真的是最近正在干的事情了。</p><span id="more"></span><p>没上锁的原因？<br>是因为我从校会网络部光荣退休了吧。。。<br>讲点别的项目。</p><h2 id="贝壳计通讲师团"><a href="#贝壳计通讲师团" class="headerlink" title="贝壳计通讲师团"></a>贝壳计通讲师团</h2><p>项目访问方式：</p><p><img src="https://raw.githubusercontent.com/lmy98129/weapp-ustb/master/QRCODE.jpg" alt="QRCODE"></p><ol><li>扫描上方的小程序码</li><li>微信小程序搜索“贝壳计通讲师团”</li><li><a href="https://github.com/lmy98129/weapp-ustb">Github</a></li></ol><h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP1.PNG" alt="WEAPP1"></p><p><center>小程序主界面，更多预览请直接打开小程序或阅读本文后续内容</center><br></p><p>这是北京科技大学计算机与通信工程学院学生讲师团的官方小程序，管理方是北京科技大学计算机与通信工程学院学生讲师团，开发和维护方是北京科技大学计算机与通信工程学院的计算机科学与技术专业大二学生本人以及我的搭档fafnir，<strong>本人作为小程序的主要开发者之一，完成了本小程序的数据库结构设计、前端小程序开发、Node.js后端开发工作，并进行了多次版本迭代</strong>。搭档fafnir完成的工作主要为开发基于Python的Django Xadmin搭建的小程序后台管理网站。</p><p>项目创建的具体时间应与本博客的创建时间相差不多，开发时间长达3个月，上线时间已达1个月，经历两次大改。目前最新版本为v0.4.1。<br><strong>小程序前端基于腾讯微信小程序开发工具的原生组件，后端基于Node.js框架Express，数据库使用MySQL，数据库访问使用Node.js的MySQL库。其中，前端的通信模块以及后端的数据库访问模块均采用Promise异步编程封装。</strong></p><blockquote><p>注：我们计划在将本程序进行适当重构后，将本程序的前后端代码适时发布至GitHub。<br>当前程序内的敏感信息较多，公布后风险较大故暂不考虑。</p><p>后续：前端代码已发布至<a href="https://github.com/lmy98129/weapp-ustb">Github</a></p></blockquote><h3 id="项目技术细节"><a href="#项目技术细节" class="headerlink" title="项目技术细节"></a>项目技术细节</h3><p>本项目的最初需求来源是：在2017秋季学期计通学院学生讲师团旧有线上预约平台网站开发维护人员即将毕业离校，讲师团负责人员联系辅导员提出了寻找学生进行下一代线上辅导预约平台的开发和维护工作的需求，最终确定采用小程序的形式进行开发，并招募了开发人员。原定计划为寒假一个多月时间内完成开发任务，但由于人员技术水平有限，以及在开发过程中遇到的种种挫折，我们前后花费了将近3个月的时间，经历两次大改才将目前接近成品的版本v0.4.1付诸上线使用。</p><h4 id="项目第一版"><a href="#项目第一版" class="headerlink" title="项目第一版"></a>项目第一版</h4><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP2.PNG" alt="WEAPP2"></p><p><center>第一版小程序主界面，更多预览请阅读本文后续内容</center><br></p><p>项目的第一版完成了基本的需求分析、技术选型、数据库表设计、设备部署以及初步的技术实现等工作。其中需求分析与数据库表设计均由我来完成，并根据MySQL的通行命名规范，编写了本项目的第一份需求分析以及数据库表结构稿件。<strong>出于安全考虑，不在此处公布数据库各表的具体字段。</strong>由于我们与需求方之间初期的沟通较少，导致我们对于需求方的理解有一定的偏差，但根据我们之后的需求更改情况，可以看出大方向上是无误的。</p><h5 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h5><p>我们在第一版设计时的具体需求（大部分为开发方在开发过程中，帮助需求方总结的需求）为：</p><ul><li>小程序前端搭载学生端和讲师端两套代码，在用户登录过程中，使用微信提供的用户id查询数据库结果决定显示哪一界面，普通用户默认为学生用户。（虽然在历次提交审查中，<strong>微信方面的小程序测试人员并未对此提出任何疑问</strong>，但可以说确实是一种逃避审查的潜在手段，希望微信方面改进审查机制加以防范）</li><li>讲师发布课程内容，包括课程名称、日期、时间、地点、人数上限、备注等，其中人数上限、地点、备注为选填项。（<strong>早期版本中未考虑到人数上限问题，是后期加入的字段</strong>）</li><li>学生可以进入课程列表对讲师发布的课程进行预约或取消预约，其中达到人数上限、课程取消等情况下提示学生不得预约，课程列表发生的更改将在触发课程列表本身更改的同时，实时触发首页列表的刷新。（<strong>课程超时不得预约的功能较为复杂，也是后期加入的字段</strong>）</li><li>学生端以及讲师端首页均显示自己已预约的课程或已发布的课程情况，以及对课程进行相应的编辑操作：学生可以取消课程预约，讲师可以取消、删除、编辑课程，讲师的编辑操作也将触发其首页列表的刷新。</li><li>在课程列表以及首页中点击单个课程卡片可以查看课程详情。</li><li>“我的”页面中普通学生用户可以申请成为讲师，需提交真实姓名以及电话号码，通过后台管理网站的管理员核对后通过认证成为讲师。</li><li>后台管理网站应该能自由编辑、删除任何讲师发布的课程，应在开发后期对讲师每月授课情况统计，并进行展示（<strong>截至文章发布，授课情况统计功能暂未全部完成</strong>）。</li></ul><h5 id="数据库表"><a href="#数据库表" class="headerlink" title="数据库表"></a>数据库表</h5><p>根据以上的需求分析，大致能够分成以下的数据库表（具体字段不予公布）</p><ol><li>用户预约总表</li><li>讲师课程列表</li><li>管理员认证讲师资格列表</li><li>管理员账户列表</li></ol><h5 id="程序功能"><a href="#程序功能" class="headerlink" title="程序功能"></a>程序功能</h5><p>从这些数据库表可以分析得出的功能表如下：</p><ol><li>用户<ol><li>查看当前可预约课程列表</li><li>提交预约</li><li>取消预约</li><li>查看自己当前的预约</li><li>提交讲师认证申请</li></ol></li><li>讲师<ol><li>查看当前已发布课程以及预约情况（预约人数）</li><li>提交课程</li><li>取消课程</li><li>修改课程</li></ol></li><li>管理员<ol><li>查看并编辑当前所有课程以及预约</li><li>操作讲师认证申请</li><li>查看当前所有讲师每月的授课情况</li></ol></li></ol><h5 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h5><p>项目第一版的技术选型由fafnir完成，总体情况是采用了腾讯云提供的<a href="https://github.com/tencentyun/wafer">wafer小程序一站式解决方案</a>，具体来说应该是wafer1，选择的理由是相比于wafer2中服务器无法取得完整访问权的形式，wafer1可以直接在服务器上部署后台管理网站。（<strong>虽然后来的经费结算显示，使用wafer2方案可能会更经济一些</strong>，而且截至文章发布，腾讯云已经不再主推wafer1，并撤换下了多个wafer小程序一站式解决方案的访问入口，当前能够全新购买的解决方案的只剩下基于开发者工具的wafer2方案，两者之间的不同以及基本架构可以<a href="https://cloud.tencent.com/developer/article/1007109">看这里</a>）当时的具体项目选型如下：</p><table><thead><tr><th>技术模块</th><th>采用技术</th><th>备注</th></tr></thead><tbody><tr><td>小程序前端</td><td>wafer小程序一站式解决方案小程序demo</td><td><a href="https://github.com/tencentyun/wafer-client-demo">项目地址</a>，与后端通信采用的是<a href="https://github.com/tencentyun/wafer-client-sdk">wafer自带的腾讯云SDK</a>，采用的是基于socket的全双工信道通信，部分界面元素直接复用了demo中的界面</td></tr><tr><td>服务器后端</td><td>wafer小程序站式解决方案Node.js后端demo</td><td><a href="https://github.com/tencentyun/wafer-node-server-demo">项目地址</a>，部署于wafer一站式解决方案的业务服务器上，基于Node.js框架Express，与前端通信采用的同样是<a href="https://github.com/tencentyun/wafer-node-server-sdk">wafer自带的腾讯云SDK</a>，采用的是基于socket的全双工信道通信，前后端的会话通信可以直接通过API地址进行，但是信道通信必须经过一站式解决方案的信道服务器进行（<strong>请记住这一点，在之后的版本迭代中就发生了问题</strong>），与数据库通信采用的是Node.js的MySQL库的线程池模式（<strong>此时并未对其进行任何的封装</strong>）</td></tr><tr><td>数据库</td><td>MySQL 5.6</td><td>部署于wafer一站式解决方案的云数据库上，通过wafer一站式解决方案的信道服务器进行远程访问</td></tr><tr><td>后台管理网站</td><td>基于Python的Django Xadmin</td><td>部署于wafer一站式解决方案的业务服务器上，与后端访问操作同一数据库</td></tr></tbody></table><h5 id="开发难点及笔记"><a href="#开发难点及笔记" class="headerlink" title="开发难点及笔记"></a>开发难点及笔记</h5><h6 id="JavaScript的异步单线程特性"><a href="#JavaScript的异步单线程特性" class="headerlink" title="JavaScript的异步单线程特性"></a>JavaScript的异步单线程特性</h6><p>由于对Node.js乃至JavaScript的异步单线程的特性，尤其是回调函数的理解还较为浅薄（可能也是在之前并未直接接触过前后端通信以及数据库通信的原因造成的。是的我之前的工作真的就是改改开源PHP项目的代码，没怎么认真研读过代码以及文档），所以在设计后端服务器与数据库通信模块时，仍然将思路停留在C/C++之类的线性思路上，例如有如下代码：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> res = <span class="string">&#x27;nothing&#x27;</span>;</span><br><span class="line">connection.<span class="title function_">query</span>(<span class="string">&quot;USE &quot;</span>+database);</span><br><span class="line">connection.<span class="title function_">query</span>(<span class="string">&#x27;SELECT * FROM &#x27;</span>+databaseForm, <span class="keyword">function</span> (<span class="params">error, results, fields</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (error) <span class="keyword">throw</span> error;</span><br><span class="line">    <span class="keyword">if</span> (results) &#123;</span><br><span class="line">        res = results;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(res);</span><br></pre></td></tr></table></figure><br>其执行结果按照我的想象应该是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nothing</span><br><span class="line">(查询的结果)</span><br><span class="line">(查询的结果)</span><br></pre></td></tr></table></figure><br>结果是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nothing</span><br><span class="line">(查询的结果)</span><br><span class="line">nothing</span><br></pre></td></tr></table></figure><br>相当于查询结果并未真正传给变量<code>res</code>，若我想在第二个<code>console.log(res);</code>的位置进行查询结果向前端的回传，则回传的结果将仍是<code>nothing</code>。具体原因？简单来说就是JavaScript作为一种在浏览器引擎中工作的语言，在大多数情况下只能单线程运行，此时只能先将一些阻塞整个线程运行的工作进行挂起处理（就例如前后端通信，若后端在某次查询时迟迟不回传，不应该将这个查询之外的其他工作全部停止，选择等待查询结果的到来，而是将其挂起，当后端查询结果回传时，再回过头来进行查询结果的处理等与查询结果相关的工作），这个挂起处理就是通过回调函数<code>callback</code>实现的，也就是上面第二个<code>connection.query</code>中的<code>function</code>函数。因此，正确的实现应该是:<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">connection.<span class="title function_">query</span>(<span class="string">&quot;USE &quot;</span>+database);</span><br><span class="line">connection.<span class="title function_">query</span>(<span class="string">&#x27;SELECT * FROM &#x27;</span>+databaseForm, <span class="keyword">function</span> (<span class="params">error, results, fields</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (error) <span class="keyword">throw</span> error;</span><br><span class="line">    <span class="keyword">if</span> (results) &#123;</span><br><span class="line">        <span class="title class_">TunnelService</span>.<span class="title function_">emit</span>(tunnelId, messageId, results); <span class="comment">//直接在回调函数中进行回传</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><h6 id="Node-js中MySQL库的单语句查询、参数化查询等防注入机制"><a href="#Node-js中MySQL库的单语句查询、参数化查询等防注入机制" class="headerlink" title="Node.js中MySQL库的单语句查询、参数化查询等防注入机制"></a>Node.js中MySQL库的单语句查询、参数化查询等防注入机制</h6><p>后端服务器与MySQL通信使用的库为Node.js通用的MySQL库，安装命令为<code>npm install mysql</code>。根据我们后期的开发经验，事实上不应该使用该库而应该使用更加专业的ORM框架（<a href="https://baike.baidu.com/item/ORM/3583252">ORM的定义</a>）来方便我们对数据库操作命令进行js化的直接编写，而非只用SQL语句进行直接查询，虽然学习SQL语句也不是一件坏事。是的，本项目基本上用到的也就是增删改查、左联右联内联、COUNT计数、建表建库等基本SQL语句。</p><p>但是，问题在于该MySQL库本身的最佳实践中提到了其参数化查询、单语句查询的等防注入攻击的机制。其中参数化查询并非开发难点，此处可以略过，但是其默认单语句查询的功能实在是增加了开发难度。也就是必须在单条SQL语句当中完成所有查询，不允许进行多次查询后通过中间变量进行合并得到最终结果。这一设定的出发点是好的，万一API接口被传入一些带“;”的参数，且允许多语句查询，我们并不知道这些参数是否会导致SQL注入攻击的发生。</p><p>诚然，大多数查询通过本人的努力都实现了单语句查询的效果，虽然SQL语句看起来又臭又长，外人难以读懂（这也是我反思之后决定日后学习ORM的主要原因之一）。但是若出现某些根据上一次查询结果进行分支操作的情况，单语句查询就显得十分吃力了。例如，我们遇到了这一种情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@startuml</span><br><span class="line">    &quot;开始查询&quot;--&gt;&quot;查询某记录是否存在&quot;</span><br><span class="line">    if &quot;该记录存在吗？&quot; then</span><br><span class="line">        --&gt; [yes] &quot;将原记录的删除状态解除并修改其内容&quot;</span><br><span class="line">        --&gt; &quot;返回结果&quot;</span><br><span class="line">    else</span><br><span class="line">        --&gt; [no] &quot;新增一条记录&quot;</span><br><span class="line">        --&gt; &quot;返回结果&quot;</span><br><span class="line">    endif</span><br><span class="line">@enduml</span><br></pre></td></tr></table></figure><p><center>如果因SSL证书问题无法查看上方的流程图，可以使用其他非Chrome内核的浏览器或使用桌面端浏览器阅读本文</center><br></p><p>所以在项目的第一版中，我们采用了Node.js的<code>async</code>库中的<code>waterfall</code>进行同步顺序编程，<br><strong>之后的版本我发现了Promise是个好东西（虽然理解起来有难度）</strong><br><strong>然后就把通信模块统统重写了个遍</strong><br>在MySQL通信模块中解决这一问题的一个库函数实例如下：<br>也可以看出采用了参数化查询的防注入机制，以及MySQL的线程池。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="title function_">mysqlReserveClassStu</span>(<span class="params">tunnelId, messageId, openId, classId, nickName</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> tasks = [<span class="keyword">function</span>(<span class="params">callback</span>) &#123;</span><br><span class="line">    pool.<span class="title function_">getConnection</span>(<span class="keyword">function</span>(<span class="params">error,connection</span>) &#123;</span><br><span class="line">      connection.<span class="title function_">query</span>(<span class="string">&quot;SELECT * FROM user_reserve WHERE class_id=? AND user_id=?&quot;</span>, [classId, openId], <span class="keyword">function</span> (<span class="params">error, results_1, fields</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (error) <span class="keyword">throw</span> error;</span><br><span class="line">        <span class="keyword">if</span> (results_1) &#123;</span><br><span class="line">          connection.<span class="title function_">release</span>();</span><br><span class="line">          <span class="title function_">callback</span>(error, results_1);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;, <span class="keyword">function</span>(<span class="params">results_1, callback</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(results_1[<span class="number">0</span>] == <span class="literal">null</span>)&#123;</span><br><span class="line">      pool.<span class="title function_">getConnection</span>(<span class="keyword">function</span>(<span class="params">error,connection</span>) &#123;</span><br><span class="line">        connection.<span class="title function_">query</span>(<span class="string">&quot;INSERT INTO user_reserve (user_id,user_nickname,class_id,submission_date) VALUES(?,?,?,NOW())&quot;</span>,</span><br><span class="line">        [openId,nickName,classId], <span class="keyword">function</span>(<span class="params">error, results_2, fields</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span>(error) <span class="keyword">throw</span> error;</span><br><span class="line">          <span class="keyword">if</span>(results_2) &#123;</span><br><span class="line">            connection.<span class="title function_">release</span>();</span><br><span class="line">            <span class="title class_">TunnelService</span>.<span class="title function_">emit</span>(tunnelId, messageId, results_2);</span><br><span class="line">            <span class="title function_">callback</span>(error);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      pool.<span class="title function_">getConnection</span>(<span class="keyword">function</span>(<span class="params">error,connection</span>) &#123;</span><br><span class="line">        connection.<span class="title function_">query</span>(<span class="string">&quot;UPDATE user_reserve SET status=1 WHERE class_id=? AND user_id=?&quot;</span>,</span><br><span class="line">        [classId,openId], <span class="keyword">function</span>(<span class="params">error,results_3, fields</span>)&#123;</span><br><span class="line">          <span class="keyword">if</span>(error) <span class="keyword">throw</span> error;</span><br><span class="line">          <span class="keyword">if</span>(results_3) &#123;</span><br><span class="line">            connection.<span class="title function_">release</span>();</span><br><span class="line">            <span class="title class_">TunnelService</span>.<span class="title function_">emit</span>(tunnelId, messageId, results_3);</span><br><span class="line">            <span class="title function_">callback</span>(error);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;];</span><br><span class="line"></span><br><span class="line">  <span class="keyword">async</span>.<span class="title function_">waterfall</span>(tasks, <span class="keyword">function</span>(<span class="params">error, results</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(error) <span class="keyword">throw</span> error;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>这个代码块确定没把数据库表的字段抖出来了吗。。。<br>emmmm，还好吧。各位高抬贵手，高抬贵手。。。</p></blockquote><h6 id="前端、后端、数据库三者之间的时间不统一以及时间格式的处理问题"><a href="#前端、后端、数据库三者之间的时间不统一以及时间格式的处理问题" class="headerlink" title="前端、后端、数据库三者之间的时间不统一以及时间格式的处理问题"></a>前端、后端、数据库三者之间的时间不统一以及时间格式的处理问题</h6><p>这里由于我自己也记不大清楚当初的处理思路（尤其是小程序前端在处理过程中使用的“幻数”），<br>很可能都是我无意识情况下的“瞎调试”的成果。<br><strong>这个说实话我是极其不提倡这么干的，虽然有的时候的确有用</strong><br>此处提供各模块的关键代码供大家参阅：<br>服务器后端MySQL通信模块上的初始化操作，关键就是设置时区到正确的时间<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">process.<span class="property">env</span>.<span class="property">TZ</span> = <span class="string">&#x27;Asia/Shanghai&#x27;</span>;</span><br><span class="line"><span class="keyword">var</span> pool;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MysqlExecute</span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="title function_">mysqlInit</span>(<span class="params"></span>) &#123;</span><br><span class="line">    pool = mysql.<span class="title function_">createPool</span>(&#123;</span><br><span class="line">    <span class="attr">connectionLimit</span>: <span class="number">10</span>,</span><br><span class="line">    host     : mysqlHost,</span><br><span class="line">    user     : mysqlUser,</span><br><span class="line">    password : mysqlPassword,</span><br><span class="line">    database : mysqlDatabase,</span><br><span class="line">    timezone : process.<span class="property">env</span>.<span class="property">TZ</span></span><br><span class="line">    &#125;)  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>小程序前端的时间处理相关代码format，关键就是正则表达式+暴力剪切+暴力连接<br>（其中用了微信开发者工具的默认小程序demo里面的util.js时间处理函数）<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> utils = <span class="built_in">require</span>(<span class="string">&#x27;./util&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> currentDate = utils.<span class="title function_">formatTime</span>(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line"><span class="keyword">var</span> currentDateAnnual = <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line"><span class="keyword">var</span> classContentStr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">timeFormat</span> = (<span class="params">str</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; str.<span class="property">length</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">var</span> start = str[i].<span class="property">class_timestart</span>;</span><br><span class="line">        <span class="keyword">var</span> end = str[i].<span class="property">class_timend</span>;</span><br><span class="line">        <span class="keyword">var</span> date = <span class="keyword">new</span> <span class="title class_">Date</span>(str[i].<span class="property">class_date</span>.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">10</span>));</span><br><span class="line">        date = date.<span class="title function_">getFullYear</span>() + <span class="string">&quot;年&quot;</span> +</span><br><span class="line">        (<span class="built_in">parseInt</span>(date.<span class="title function_">getMonth</span>()) + <span class="number">1</span>).<span class="title function_">toString</span>() + <span class="string">&quot;月&quot;</span> +</span><br><span class="line">        date.<span class="title function_">getDate</span>() + <span class="string">&quot;日&quot;</span>;</span><br><span class="line">        start = start.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="keyword">if</span> (start.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">1</span>) == <span class="string">&quot;0&quot;</span>) &#123;</span><br><span class="line">            start = start.<span class="title function_">slice</span>(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">        &#125;</span><br><span class="line">            end = end.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="keyword">if</span> (end.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">1</span>) == <span class="string">&quot;0&quot;</span>) &#123;</span><br><span class="line">            end = end.<span class="title function_">slice</span>(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        str[i].<span class="property">class_date</span> = date;</span><br><span class="line">        str[i].<span class="property">class_timestart</span> = start;</span><br><span class="line">        str[i].<span class="property">class_timend</span> = end</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> str;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">dateFormat</span> = (<span class="params">options, that</span>) =&gt; &#123;</span><br><span class="line">    that.<span class="title function_">setData</span>(&#123; </span><br><span class="line">        <span class="attr">dateIndex</span>: currentDate,</span><br><span class="line">        <span class="attr">ateLimitStart</span>: currentDate,</span><br><span class="line">    &#125;);</span><br><span class="line">    currentDateAnnual.<span class="title function_">setFullYear</span>(currentDateAnnual.<span class="title function_">getFullYear</span>() + <span class="number">1</span>);</span><br><span class="line">    currentDateAnnual.<span class="title function_">setDate</span>(currentDateAnnual.<span class="title function_">getDate</span>() - <span class="number">1</span>);</span><br><span class="line">    that.<span class="title function_">setData</span>(&#123; <span class="attr">dateLimitEnd</span>: currentDateAnnual &#125;);</span><br><span class="line">    <span class="keyword">if</span> (options.<span class="property">class_content</span> != <span class="literal">null</span>) &#123;</span><br><span class="line">        classContentStr = <span class="title class_">JSON</span>.<span class="title function_">parse</span>(options.<span class="property">class_content</span>);</span><br><span class="line">        <span class="keyword">if</span> (classContentStr.<span class="property">student_limit</span> == <span class="string">&#x27;0&#x27;</span>) &#123;</span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">studentLimit</span>: <span class="string">&#x27;&#x27;</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">studentLimit</span>: classContentStr.<span class="property">student_limit</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">        classContentStr.<span class="property">class_date</span> = classContentStr.<span class="property">class_date</span>.<span class="title function_">replace</span>(<span class="string">&quot;年&quot;</span>, <span class="string">&quot;-&quot;</span>);</span><br><span class="line">        classContentStr.<span class="property">class_date</span> = classContentStr.<span class="property">class_date</span>.<span class="title function_">replace</span>(<span class="string">&quot;月&quot;</span>, <span class="string">&quot;-&quot;</span>);</span><br><span class="line">        classContentStr.<span class="property">class_date</span> = classContentStr.<span class="property">class_date</span>.<span class="title function_">replace</span>(<span class="string">&quot;日&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">            <span class="attr">className</span>: classContentStr.<span class="property">class_name</span>,</span><br><span class="line">            <span class="attr">classIntro</span>: classContentStr.<span class="property">class_intro</span>,</span><br><span class="line">            <span class="attr">dateIndex</span>: classContentStr.<span class="property">class_date</span>,</span><br><span class="line">            <span class="attr">classPlace</span>: classContentStr.<span class="property">class_place</span>,</span><br><span class="line">            <span class="attr">timeEndIndex</span>: classContentStr.<span class="property">class_timend</span>,</span><br><span class="line">            <span class="attr">timeStartIndex</span>: classContentStr.<span class="property">class_timestart</span>,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> classContentStr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">timeFormat</span>: timeFormat,</span><br><span class="line">    <span class="attr">dateFormat</span>: dateFormat</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>看着相当的难受啊，这x一样的代码风格😂<br>没毛病，（下一版）会改的会改的🙏<br>（没错，之后的版本我直接把那个又臭又长的<code>classContentStr</code>给改了。。。）</p></blockquote><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> date = <span class="keyword">new</span> <span class="title class_">Date</span>(str[i].<span class="property">class_date</span>.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">10</span>));</span><br><span class="line"> <span class="comment">//这里得到的结果格式应该类似于yyyy-mm-dd</span></span><br><span class="line">date = date.<span class="title function_">getFullYear</span>() + <span class="string">&quot;年&quot;</span> +</span><br><span class="line">        (<span class="built_in">parseInt</span>(date.<span class="title function_">getMonth</span>()) + <span class="number">1</span>).<span class="title function_">toString</span>() + <span class="string">&quot;月&quot;</span> +</span><br><span class="line">        date.<span class="title function_">getDate</span>() + <span class="string">&quot;日&quot;</span>;</span><br></pre></td></tr></table></figure><p>想看幻数的同学看上面，我把它截取下来了。<br>是这样的：月份数诡异地被我加了一个1，然后居然就对了。。。<br>我也不知道这个到底是怎么一回事，在JavaScript里有什么奇异的原理导致了这个结果，有人知道的话可以告诉我吗?</p><blockquote><p>后续：我查到了，因为getMonth()是以数组形式来存储月份的，下标是0~11</p></blockquote><h6 id="人数上限的数据格式转换，以及人数已满等状态下阻止用户预约"><a href="#人数上限的数据格式转换，以及人数已满等状态下阻止用户预约" class="headerlink" title="人数上限的数据格式转换，以及人数已满等状态下阻止用户预约"></a>人数上限的数据格式转换，以及人数已满等状态下阻止用户预约</h6><blockquote><p>你还别说，我一边写这个笔记，一边还在最新版本的小程序里发现各种蜜汁有趣的bug呢😂</p></blockquote><p>人数上限作为讲师发布课程时的一个选填项，可以说是本项目数据处理的一个难点，其处理方式在本项目中也起到了一种模范的形式<br>难点在于：人数上限分为两种情况：“无上限”和存在数字上限，我们只能利用0这个数字来表示“无上限”，因为基本上不可能开设一个人也没有的课程，至少的人数上限也应该是1。但是反过来说，用户在填写表单时不可能特别将无上限填写为0，这在用户体验上只有留空才更加符合一般的表单填写习惯。</p><p>所以我们在用户点击上传按钮触发的函数中就将人数上限进行处理转换：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> studentLimitFormat;</span><br><span class="line"><span class="keyword">if</span>(<span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">studentLimit</span> == <span class="string">&#x27;&#x27;</span>)&#123;</span><br><span class="line">    studentLimitFormat = <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    studentLimitFormat = <span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">studentLimit</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//之后传到后端的就是studentLimitFormat</span></span><br></pre></td></tr></table></figure></p><p>并在从后端回传的过程中也一样进行相应的处理，这里以课程内容页代码为例：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(classContentStr.<span class="property">student_limit</span> == <span class="string">&#x27;0&#x27;</span>)&#123;</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">    <span class="attr">studentLimit</span>: <span class="string">&#x27;无上限&#x27;</span></span><br><span class="line">  &#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">    <span class="attr">studentLimit</span>: classContentStr.<span class="property">student_limit</span></span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>同时，也应当在人数已满时阻止用户预约。在微信小程序中，我们使用<code>&lt;block wx:if&gt;</code>的wxml标签形式进行分类，通过条件判断来决定显示何种按钮，并只在“预约”和“取消预约”按钮上添加相应的函数钩子，这里以课程列表的上传按钮为例：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:if</span>=<span class="string">&quot;&#123;&#123;item.student_sum &gt;= item.student_limit &amp;&amp; item.student_limit &gt; 0&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;reserve-button&quot;</span> <span class="attr">data-content</span>=<span class="string">&#x27;&#123;&#123;item&#125;&#125;&#x27;</span>&gt;</span></span><br><span class="line">        人数已满</span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:elif</span>=<span class="string">&quot;&#123;&#123;item.status == 0&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;reserve-button&quot;</span> <span class="attr">data-content</span>=<span class="string">&#x27;&#123;&#123;item&#125;&#125;&#x27;</span>&gt;</span></span><br><span class="line">        已取消</span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:elif</span>=<span class="string">&quot;&#123;&#123;item.reserve_status == null || item.reserve_status != 1&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;reserve-button&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;bindReserve&quot;</span> <span class="attr">data-content</span>=<span class="string">&#x27;&#123;&#123;item&#125;&#125;&#x27;</span>&gt;</span></span><br><span class="line">        预约</span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:elif</span>=<span class="string">&quot;&#123;&#123;item.reserve_status == 1&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;reserve-button&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;bindCancelReserve&quot;</span> <span class="attr">data-content</span>=<span class="string">&#x27;&#123;&#123;item&#125;&#125;&#x27;</span>&gt;</span>          </span><br><span class="line">        取消预约</span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>当然，我们也在后端数据库表的设计中，将讲师课程表的人数上限字段的默认值设置为0。这算是最后一道防线吧，防止其他非法输入对数据的影响。</p><h6 id="提交表单前的各种格式检查"><a href="#提交表单前的各种格式检查" class="headerlink" title="提交表单前的各种格式检查"></a>提交表单前的各种格式检查</h6><p>是的，以人数上限的数据上传前进行处理为范本，我们普遍采用了<code>if() &#123; return; &#125;</code>的形式对非法输入进行检查，而这些非法输入的多样性之丰富，远远超出了我们的想象。例如：<br>有时间的非法输入，直接用正则表达式替换掉时间中的冒号+暴力的数字比较（<code>new Date</code>说实话多此一举了）：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(<span class="keyword">new</span> <span class="title class_">Date</span>(<span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">timeStartIndex</span>.<span class="title function_">replace</span>(<span class="regexp">/:/g</span>, <span class="string">&quot;&quot;</span>)) &gt; <span class="keyword">new</span> <span class="title class_">Date</span>(<span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">timeEndIndex</span>.<span class="title function_">replace</span>(<span class="regexp">/:/g</span>, <span class="string">&quot;&quot;</span>)))&#123;</span><br><span class="line">    wx.<span class="title function_">showModal</span>(&#123;</span><br><span class="line">        <span class="attr">title</span>: <span class="string">&#x27;提示&#x27;</span>,</span><br><span class="line">        <span class="attr">content</span>: <span class="string">&#x27;开始时间应小于结束时间&#x27;</span>,</span><br><span class="line">        <span class="attr">showCancel</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">confirmColor</span>: <span class="string">&#x27;#17abe3&#x27;</span>,</span><br><span class="line">        <span class="attr">confirmText</span>: <span class="string">&#x27;好的&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>有人数上限输入非数字时，调用<code>isNaN()</code>函数的同时防止将留空代表“无上限”也拦截：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">isNaN</span>(<span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">studentLimit</span>) &amp;&amp; !(<span class="variable language_">this</span>.<span class="property">data</span>.<span class="property">studentLimit</span> == <span class="literal">undefined</span>)) &#123;</span><br><span class="line">    wx.<span class="title function_">showModal</span>(&#123;</span><br><span class="line">        <span class="attr">title</span>: <span class="string">&#x27;提示&#x27;</span>,</span><br><span class="line">        <span class="attr">content</span>: <span class="string">&#x27;人数上限应输入数字&#x27;</span>,</span><br><span class="line">        <span class="attr">showCancel</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">confirmColor</span>: <span class="string">&#x27;#17abe3&#x27;</span>,</span><br><span class="line">        <span class="attr">confirmText</span>: <span class="string">&#x27;好的&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>甚至对是否产生了无效的预约时间也进行了合法性检查：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ((currentDate &gt; selectedDate) || ((currentDate == selectedDate) &amp;&amp; (currentTime &gt; selectedTime)) &#123;</span><br><span class="line">    wx.<span class="title function_">showModal</span>(&#123;</span><br><span class="line">        <span class="attr">title</span>: <span class="string">&#x27;提示&#x27;</span>,</span><br><span class="line">        <span class="attr">content</span>: <span class="string">&#x27;预约时间应大于当前时间&#x27;</span>,</span><br><span class="line">        <span class="attr">showCancel</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">confirmColor</span>: <span class="string">&#x27;#17abe3&#x27;</span>,</span><br><span class="line">        <span class="attr">confirmText</span>: <span class="string">&#x27;好的&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们在合法性检查上花费了大量的时间，但也只能够对非法情况进行枚举性质的检测，若有一些我们不了解的业界最佳实践，欢迎联系我们探讨这一问题。</p><h5 id="程序测试"><a href="#程序测试" class="headerlink" title="程序测试"></a>程序测试</h5><p>程序测试确实是开发过程当中的重要一环，由于团队资源有限，且微信账号确实具有不可模拟性，所以我们在不足以拿到足够的微信测试账号以及测试机时，借助微信开发者工具和自己的手机号，建立了一个仅有两个核心测试账号、一台安卓测试机的测试体系（后期在发现iOS独有bug时，我们也找了临时的iPhone测试机和测试微信账号）。</p><ul><li>两个测试账号一个默认为普通学生用户，另一个通过后台管理网站通过讲师认证注册为讲师（在后台管理网站还未部署时，其实是通过手工向数据库表加入记录实现的），两号均在微信公众平台上注册为开发者</li><li>一般情况下，在PC端微信开发者工具上登录其中一个用户，手机端也登录这一用户，以测试学生端或讲师端在开发者工具的模拟器和实机上效果是否一致，也可以通过远程调试定位实机上的bug</li><li>若想测试讲师端与学生端的数据互动效果，可以在开发者工具登录一个用户，另一个用户在手机上通过微信最新版本的“切换用户”功能登录小程序</li><li>若想测试多个教师或多个学生产生数据的效果，可以通过后台管理网站同时认证讲师或取消讲师认证来实现身份上的同一性。</li><li>若想在临时的iPhone测试机上进行远程调试，记得先将该机的测试微信号加入开发者列表，如此方能远程调试成功，测试结束后记得再删除即可。</li></ul><h5 id="小程序最终界面"><a href="#小程序最终界面" class="headerlink" title="小程序最终界面"></a>小程序最终界面</h5><p>UI设计上大量采用了腾讯云一站式小程序解决方案小程序demo的配色和界面元素。<br>（其实就是没精力去设计UI啦。。。）<br>基本设计思想更偏向WP式的平面风格</p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP2.PNG" alt="WEAPP2"></p><p><center>第一版小程序主界面（此时小程序名称还没改）</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP3.PNG" alt="WEAPP3"></p><p><center>第一版小程序主界面（无预约时显示的欢迎+提示语）</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP4.JPEG" alt="WEAPP4"></p><p><center>第一版小程序课程列表</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP5.JPEG" alt="WEAPP5"></p><p><center>第一版小程序讲师端主界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP6.JPEG" alt="WEAPP6"></p><p><center>第一版小程序讲师端编辑课程界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP7.JPEG" alt="WEAPP7"></p><p><center>第一版小程序“我的”页面</center><br></p><h4 id="项目第二版"><a href="#项目第二版" class="headerlink" title="项目第二版"></a>项目第二版</h4><p>项目第二版的迭代原因是十分偶然的。由于<a href="https://developers.weixin.qq.com/blogdetail?action=get_post_info&amp;lang=zh_CN&amp;token=&amp;docid=000aee01f98fc0cbd4b6ce43b56c01">微信官方对于小程序用户登录API的调整</a>影响了wafer1一站式解决方案中的腾讯云小程序SDK以及Node.js服务器端SDK通过信道服务器对用户身份进行认证的正常操作进行，导致了SDK提供的信道全双工通信对于新注册用户不再可用，最终使小程序的大多数功能处于不可用状态。（据悉，wafer2的SDK信道登录方式暂未受到影响，估计是腾讯方面在wafer1逐渐下架的情况下忽视了使用wafer1的老用户，测试不全面而导致这一情况发生）</p><p>为了解决这一重大bug，我们团队仔细研读了微信官方的登录API调整公告以及腾讯云SDK文档，最终采用了“添加首次登录用户认证界面+全面弃用信道通信方式并采用原生通信方式全面重写”的改进方案。<strong>值得一提的是，在重写过程中我们着重采用了JavaScript中的异步Promise编程，对小程序前端通信模块、后端服务器MySQL通信模块进行封装重写。在开发过程中，本人收获了更多的JS异步编程经验，并对Promise为代表的异步编程解决方案有了更加深刻的理解</strong></p><p>由于第二版着重于bug的修复和代码的重写，并未对UI界面设计做出太多调整，所以此处不再展示小程序主界面截图。若想知道第一版与最新版UI变化为何如此之大，请继续往下阅读，感谢您的理解！</p><h5 id="开发难点及笔记-1"><a href="#开发难点及笔记-1" class="headerlink" title="开发难点及笔记"></a>开发难点及笔记</h5><h6 id="微信登录API调整后小程序前端后端相应的修复解决方案"><a href="#微信登录API调整后小程序前端后端相应的修复解决方案" class="headerlink" title="微信登录API调整后小程序前端后端相应的修复解决方案"></a>微信登录API调整后小程序前端后端相应的修复解决方案</h6><p>根据微信官方的说法，若想像之前那样获得完备的用户基本信息:</p><blockquote><p>必须使用<code>&lt;button&gt;</code>组件，并将<code>open-type</code>指定为<code>getUserInfo</code>类型，用户允许授权后，可获取用户基本信息。</p></blockquote><p>而另一种使用<code>&lt;open-data&gt;</code>组件展示用户信息的方式，就真的只有展示功能了。。。可能也是我太菜，根本没办法在JS获取到组件内部加载出来的用户信息。</p><p>所以就相当于只能让用户点击一次按钮来完成整个用户信息获取的工作。根据我们当初设计的数据库表结构，用户信息，尤其是其唯一标识码openId，在本项目中起到了相当关键的作用，若不能获取这些信息，则根本无法正常使用小程序的各项基本功能，所以我们在小程序的首页设计了一个遮罩层，若未进行用户信息授权的话，用户看见的只有遮罩层上的提示和用户授权登录的按钮。</p><p>我们具体的实现结果如下所示:<br>wxml代码：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:if</span>=<span class="string">&quot;&#123;&#123;!hasUserInfo&#125;&#125;&quot;</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;auth-page&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;auth-page-note&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">image</span> <span class="attr">src</span>=<span class="string">&quot;../../images/reserve-hl.png&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">text</span>&gt;</span>请允许微信授权登录后\n继续使用小程序<span class="tag">&lt;/<span class="name">text</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;auth-page-button&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">button</span> <span class="attr">wx:if</span>=<span class="string">&quot;&#123;&#123;canIUse&#125;&#125;&quot;</span> <span class="attr">open-type</span>=<span class="string">&quot;getUserInfo&quot;</span> <span class="attr">bindgetuserinfo</span>=<span class="string">&quot;bindGetUserInfo&quot;</span>&gt;</span></span><br><span class="line">                授权登录</span><br><span class="line">            <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;auth-page-uncomp-note&quot;</span> <span class="attr">wx:else</span>&gt;</span></span><br><span class="line">                不支持授权登录，请升级微信版本</span><br><span class="line">            <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>JS代码（index页面内的钩子函数）：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">bindGetUserInfo</span>: <span class="keyword">function</span> (<span class="params">e</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span>(e.<span class="property">detail</span>.<span class="property">userInfo</span>)&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> userInfo = e.<span class="property">detail</span>.<span class="property">userInfo</span>;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;用户授权：&#x27;</span>, userInfo);</span><br><span class="line"></span><br><span class="line">    wx.<span class="title function_">setStorageSync</span>(<span class="string">&#x27;nickName&#x27;</span>,userInfo.<span class="property">nickName</span>);</span><br><span class="line">    wx.<span class="title function_">setStorageSync</span>(<span class="string">&#x27;avatarUrl&#x27;</span>, userInfo.<span class="property">avatarUrl</span>);</span><br><span class="line">    auth.<span class="title function_">showAuthPage</span>(<span class="variable language_">this</span>);   </span><br><span class="line"></span><br><span class="line">    wx.<span class="title function_">showToast</span>(&#123;</span><br><span class="line">      <span class="attr">title</span>: <span class="string">&quot;正在登录&quot;</span>,</span><br><span class="line">      <span class="attr">icon</span>: <span class="string">&quot;loading&quot;</span>,</span><br><span class="line">      <span class="attr">duration</span>: <span class="number">1500</span>,</span><br><span class="line">      <span class="attr">mask</span>: <span class="literal">true</span></span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//说实话有点蠢这里，设置了一个硬性的1.5s时间，主要是因为貌似有点bug，</span></span><br><span class="line">    <span class="comment">//我如果设置wx.showToast一直显示，然后在用户信息拿到后再调用wx.hideToast，</span></span><br><span class="line">    <span class="comment">//经常性失灵，很绝望。可能真的是只能在当前页面中的js调用。但是很奇怪的是，wx.stopPullDownRefresh就不用这么干。。。</span></span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;用户授权：拒绝&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><p>JS代码（上面调用的auth所在的auth.js）：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">showAuthPage</span> = that =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span>(wx.<span class="property">getSetting</span>) &#123;</span><br><span class="line">        wx.<span class="title function_">getSetting</span>(&#123;</span><br><span class="line">            <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="keyword">var</span> auth = res.<span class="property">authSetting</span>,</span><br><span class="line">                nickName = wx.<span class="title function_">getStorageSync</span>(<span class="string">&#x27;nickName&#x27;</span>),</span><br><span class="line">                hasUserInfo;</span><br><span class="line">                <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;授权情况：&quot;</span>, auth);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (auth[<span class="string">&#x27;scope.userInfo&#x27;</span>] &amp;&amp; nickName)</span><br><span class="line">                    hasUserInfo = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">else</span> </span><br><span class="line">                    hasUserInfo = <span class="literal">false</span>;</span><br><span class="line">                </span><br><span class="line">                <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;授权标记：&quot;</span>, hasUserInfo);                    </span><br><span class="line">                that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                    <span class="attr">hasUserInfo</span>: hasUserInfo</span><br><span class="line">                &#125;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">showAuthPage</span>: showAuthPage</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>感觉上小程序的底层应该也是像Vue、Angular、React那样写了一个有DOM更新之类功能的前端引擎，基本上hasUserInfo更新了之后，那个遮罩层直接就消失了，DOM更新的速度相当快。也有人吐槽小程序的JS风格就像Vue+React。。。</p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP8.PNG" alt="WEAPP8"></p><p><center>第二版小程序用户登录授权页面（请忽略那个远程调试用的黑框😂）</center><br></p><h6 id="前端通信模块以及后端MySQL通信模块的重写和Promise封装"><a href="#前端通信模块以及后端MySQL通信模块的重写和Promise封装" class="headerlink" title="前端通信模块以及后端MySQL通信模块的重写和Promise封装"></a>前端通信模块以及后端MySQL通信模块的重写和Promise封装</h6><p>有人说，你们不是又重新实现了用户信息获取了吗？为什么还是不能用原来的信道通信方式？而且再不济重新写一个socket类型的通信方式岂不美哉（可以实现全局广播，这样可以及时通知用户是否有数据发生了更改）？</p><blockquote><p>emmmm，技术菜，只是主要原因之一。（我承认我确实还不会写socket。。。）</p></blockquote><p>关键是那个腾讯云SDK它就是用<strong>原来的登录方式</strong>（划重点）获取用户信息的啊，现在微信方面彻头彻尾地改了，你不去重写它，还有其他办法吗？</p><p>第一步，先别急着把采用信道通信的代码全删了，至少通信时数据的格式你得看看吧。</p><p>然后，我确实菜，所以只能在前端通信模块乖乖地上原生wx.request请求了。。。真的，我就觉得这就是AJAX啊。<br>首先还是先写一个简单的<code>post</code>函数，把wx.request定制化封装一下。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">post</span> = (<span class="params">obj</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">        wx.<span class="title function_">request</span>(&#123;</span><br><span class="line">            <span class="attr">url</span>: config.<span class="property">service</span>.<span class="property">testUrl</span>,</span><br><span class="line">            <span class="attr">data</span>: obj,</span><br><span class="line">            <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(res.<span class="property">data</span>.<span class="property">results</span>) &#123;</span><br><span class="line">                    <span class="title function_">resolve</span>(res.<span class="property">data</span>.<span class="property">results</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="title function_">reject</span>(res.<span class="property">data</span>.<span class="property">error</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">error</span>: <span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="title function_">reject</span>(<span class="string">&#x27;网络出错&#x27;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么要用promise对wx.request进行封装呢？理由很简单，依然是我们之前提到的JavaScript的单线程特性，需要使用回调函数<code>callback()</code>对一些可能阻塞整个JS代码执行的操作进行封装，让它们先挂起，让代码先继续执行下去，等需要进行这些操作的时候再回过头来执行——这就是<strong>异步非阻塞的编程模式</strong>。而大部分可以调用的函数都提供了回调的使用方法，以及你自己定义的函数也可以提供回调。</p><p>回调作为一种异步编程的解决方法，看起来很美好。但如果在这样的一种场景下你估计就笑不出来了：</p><blockquote><p>例如，你向后端的一个API请求一个数据。好，数据拿到了，现在你要根据这个数据再去请求后端的另一个API的数据……<br>如此下去，你请求了3个API，OK，你终于拿到了想要的最终数据，然后你还要将这个数据处理一下才能展示到界面里面</p></blockquote><p>这样的话，你写的代码大概像这样：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">wx.<span class="title function_">request</span>(&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">        wx.<span class="title function_">request</span>(&#123;</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">            <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="comment">//...</span></span><br><span class="line">                wx.<span class="title function_">request</span>(&#123;</span><br><span class="line">                    <span class="comment">//...</span></span><br><span class="line">                    <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">                        <span class="comment">//format your final data.</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>如果再多几次回调函数的嵌套，估计你自己看这代码也差不多要阵亡了。没错，这就是所谓的<strong>回调地狱</strong>。<br>后端与MySQL之类的数据库通信也同理，你输入了一条SQL语句的结果是下一条SQL语句的内容……</p><p>那么除了疯狂地筑起一个回调金字塔之外，还有什么别的办法能够解决异步非阻塞编程问题呢？Promise就是其中之一。当然我之前用的async也是一种，但是那个写起来说实话更加别扭，至少Promise允许你用封装函数的方式进行编程，显然比写一些蜜汁有趣的函数数组正常多了。</p><p>好了，我之前提到了我用Promise封装了一个<code>post</code>函数，现在我就展示一个使用Promise解决异步问题的实例：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">initUserInfo</span> = (<span class="params">that</span>) =&gt; &#123;</span><br><span class="line">  wx.<span class="title function_">login</span>(&#123;</span><br><span class="line">    <span class="attr">success</span>: <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span>(res.<span class="property">code</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取用户登录凭证：&#x27;</span>, res.<span class="property">code</span>);</span><br><span class="line"></span><br><span class="line">        <span class="title function_">post</span>(&#123;</span><br><span class="line">          <span class="string">&#x27;msgType&#x27;</span>: <span class="string">&#x27;wxAuth&#x27;</span>, </span><br><span class="line">          <span class="string">&quot;code&quot;</span>: res.<span class="property">code</span></span><br><span class="line">        &#125;).<span class="title function_">then</span>(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;收到消息：&quot;</span>, res);</span><br><span class="line">          <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">openId</span> = res;</span><br><span class="line"></span><br><span class="line">          <span class="keyword">return</span> <span class="title function_">post</span>(&#123;</span><br><span class="line">            <span class="string">&#x27;msgType&#x27;</span>: <span class="string">&#x27;checkIsTeachAuth&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;openId&#x27;</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">openId</span></span><br><span class="line">          &#125;)</span><br><span class="line"></span><br><span class="line">        &#125;).<span class="title function_">then</span>(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;收到消息：&quot;</span>, res);</span><br><span class="line">          <span class="keyword">if</span> (res.<span class="property">isTeachAuth</span> == <span class="literal">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isTeachmodeGlobal</span> = <span class="number">2</span>;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">teacherRealName</span> = res.<span class="property">realName</span>;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">teacherAuthId</span> = res.<span class="property">teacherId</span>;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">teachAuthStatus</span> = res.<span class="property">status</span>;</span><br><span class="line"></span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">              <span class="attr">isTeachMode</span>: <span class="number">2</span></span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="title function_">post</span>(&#123;</span><br><span class="line">              <span class="string">&#x27;msgType&#x27;</span>: <span class="string">&#x27;getClassDataTeach&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;openId&#x27;</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">openId</span></span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isTeachmodeGlobal</span> = <span class="number">1</span>;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">teachAuthStatus</span> = res.<span class="property">status</span>;</span><br><span class="line"></span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">              <span class="attr">isTeachMode</span>: <span class="number">1</span></span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="title function_">post</span>(&#123;</span><br><span class="line">              <span class="string">&#x27;msgType&#x27;</span>: <span class="string">&#x27;getReservedClass&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;openId&#x27;</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">openId</span></span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        &#125;).<span class="title function_">then</span>(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;收到消息：&quot;</span>, res);</span><br><span class="line">          <span class="keyword">if</span> (<span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isTeachmodeGlobal</span> == <span class="number">1</span>)&#123;</span><br><span class="line"></span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">              <span class="attr">reserveArray</span>: format.<span class="title function_">timeFormat</span>(res).<span class="title function_">reverse</span>(),</span><br><span class="line">              <span class="attr">emptyNote</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">              <span class="attr">emptyIntro</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">              <span class="attr">emptyUserName</span>: <span class="literal">true</span></span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="keyword">if</span> (res[<span class="number">0</span>] == <span class="literal">null</span>) &#123;</span><br><span class="line">              that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">emptyNote</span>: welcomeQuote,</span><br><span class="line">                <span class="attr">emptyIntro</span>: userWelcomeIntro,</span><br><span class="line">                <span class="attr">emptyUserName</span>: <span class="literal">false</span></span><br><span class="line">              &#125;)</span><br><span class="line">            &#125;</span><br><span class="line">            wx.<span class="title function_">stopPullDownRefresh</span>();  </span><br><span class="line"></span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">              <span class="attr">classArray</span>: format.<span class="title function_">timeFormat</span>(res).<span class="title function_">reverse</span>(),</span><br><span class="line">              <span class="attr">emptyNote</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">              <span class="attr">emptyIntro</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">              <span class="attr">emptyUserName</span>: <span class="literal">true</span></span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="keyword">if</span> (res[<span class="number">0</span>] == <span class="literal">null</span>) &#123;</span><br><span class="line">              that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">emptyNote</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">teacherRealName</span> + <span class="string">&quot; 欢迎！&quot;</span>,</span><br><span class="line">                <span class="attr">emptyIntro</span>: teacherWelcomeIntro,</span><br><span class="line">                <span class="attr">emptyUserName</span>: <span class="literal">false</span></span><br><span class="line">              &#125;)</span><br><span class="line">            &#125;</span><br><span class="line">            wx.<span class="title function_">stopPullDownRefresh</span>();</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;).<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;发生错误：&#x27;</span>, error);</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取用户登录态失败：&#x27;</span>, res.<span class="property">errMsg</span>);        </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>是不是超长无比。。。再联想一下刚才我演示的回调地狱，用回调不知道要套多少层了。。。<br>而且一个<code>post</code>函数可以反复使用，因为其传入的参数只有一个obj，就是发送到后端的json数据包，除此之外其他的操作都可以快速的复用，并且从后端返回的数据结果也可以由Promise传到下一个<code>.then</code>函数中。</p><p>除了<code>post</code>之外，我也仿造了信道通信方式，搞了一个<code>emit</code>函数。信道通信方式其实更加地先进，它是将所有的信道监听函数在初始化页面的时候就规定好了，也就是说把所有接收到后端数据之后的<code>success</code>操作都先写好了，之后再到需要向后端服务器发送数据的地方调用<code>emit</code>函数，这样也更加地灵活，发送数据时只管输入数据的格式和内容就OK了。</p><p>但是，本项目基本上除了用户在初始化数据或表单时需要将后端返回的数据进行存储和展示操作外，其他的通信操作基本上属于更新数据的范畴，也就是后端返回数据更新成功的结果后，只需调用一下数据刷新函数让服务器将更新好的数据回传即可。既然<code>emit</code>函数的功能如此确定，我也就直接将它封装好了，当然也得用用Promise了，既然都写好了，再多写个回调版本的函数就浪费了：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">emit</span> = (<span class="params">obj,that</span>) =&gt; &#123;</span><br><span class="line">    <span class="title function_">post</span>(obj).<span class="title function_">then</span>(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;收到消息：&#x27;</span>, res);</span><br><span class="line">        <span class="keyword">if</span> (<span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isTeachModeGlobal</span> == <span class="number">2</span>)</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isTeachDataUpdated</span> = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isStuDataUpdated</span> = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (obj.<span class="property">msgType</span> == <span class="string">&#x27;reserveClass&#x27;</span> || obj.<span class="property">msgType</span> == <span class="string">&#x27;editClass&#x27;</span> </span><br><span class="line">        || obj.<span class="property">msgType</span> == <span class="string">&#x27;classDataUpload&#x27;</span>) &#123;</span><br><span class="line">            wx.<span class="title function_">showToast</span>(&#123;</span><br><span class="line">                <span class="attr">icon</span>: <span class="string">&#x27;success&#x27;</span>,</span><br><span class="line">                <span class="attr">title</span>: <span class="string">&#x27;数据上传成功&#x27;</span>,</span><br><span class="line">                <span class="attr">duration</span>: <span class="number">3000</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">        wx.<span class="title function_">startPullDownRefresh</span>(&#123;</span><br><span class="line">            <span class="attr">success</span>: that.<span class="property">onPullDownRefresh</span></span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;).<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;发生错误：&#x27;</span>, error);</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>emit</code>函数实际用起来也就是这样的，多传了一个this指针而已：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">req.<span class="title function_">emit</span>(&#123;</span><br><span class="line">  <span class="string">&#x27;msgType&#x27;</span>: <span class="string">&#x27;reserveClass&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;openId&#x27;</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">openId</span>,</span><br><span class="line">  <span class="string">&#x27;nickName&#x27;</span>: wx.<span class="title function_">getStorageSync</span>(<span class="string">&#x27;nickName&#x27;</span>),</span><br><span class="line">  <span class="string">&#x27;classId&#x27;</span>: e.<span class="property">currentTarget</span>.<span class="property">dataset</span>.<span class="property">content</span>.<span class="property">id</span></span><br><span class="line">&#125;,<span class="variable language_">this</span>);</span><br></pre></td></tr></table></figure></p><p>既然后端MySQL通信模块也要Promise封装，那么肯定也是要先定义一个用Promise封装的函数<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="title function_">queryProm</span>(<span class="params">sql, params</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">        pool.<span class="title function_">getConnection</span>(<span class="function">(<span class="params">error,connection</span>) =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(error) &#123; <span class="title function_">reject</span>(error); <span class="keyword">throw</span> error; &#125; </span><br><span class="line">            connection.<span class="title function_">query</span>(sql, params, <span class="function">(<span class="params">error, results, fields</span>) =&gt;</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(results) &#123;</span><br><span class="line">                    <span class="title function_">resolve</span>(results);</span><br><span class="line">                    connection.<span class="title function_">release</span>();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>当然，我后来也发现其实大部分的操作其实都只需要一步回调就能解决问题了，所以我也写了一个回调版本的<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="title function_">query</span>(<span class="params">sql, params, callback</span>) &#123;</span><br><span class="line">    pool.<span class="title function_">getConnection</span>(<span class="function">(<span class="params">error,connection</span>) =&gt;</span> &#123;</span><br><span class="line">      connection.<span class="title function_">query</span>(sql, params, <span class="function">(<span class="params">error, results, fields</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (error) <span class="keyword">throw</span> error;</span><br><span class="line">        <span class="keyword">if</span> (results) &#123;</span><br><span class="line">          <span class="title function_">callback</span>(error, results);</span><br><span class="line">          connection.<span class="title function_">release</span>();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>然后这里也有一个比较模棱两可的经验，就是前端传到后端的json数据包内定义了<code>msgType</code>，可以在传入后端的地址是同一个时，根据msgType消息的类型进行不同的操作。<br>具体操作在后端是怎样分类的，我这里用了比较原始的switch-case语句，但是说实话，这样会造成代码整体的可读性下降。因为消息类型一多，全挤在一层switch里面了，修改和查找都相当困难，这也是我需要改进的地方——代码的合理化、层次化和结构化。</p><p>最后用Promise的效果就是这样的（这个就是之前在项目第一版中用async写过的那个操作）：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="string">&#x27;reserveClass&#x27;</span>: </span><br><span class="line">    sql.<span class="title function_">queryProm</span>(<span class="string">&quot;SELECT * FROM user_reserve WHERE class_id=? AND user_id=?&quot;</span>, </span><br><span class="line">            [req.<span class="property">query</span>.<span class="property">classId</span>, req.<span class="property">query</span>.<span class="property">openId</span>]</span><br><span class="line">        ).<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(response[<span class="number">0</span>] == <span class="literal">null</span>) </span><br><span class="line">                <span class="keyword">return</span> sql.<span class="title function_">queryProm</span>(</span><br><span class="line">                    <span class="string">&quot;INSERT INTO user_reserve (user_id,user_nickname,class_id,submission_date) VALUES(?,?,?,NOW())&quot;</span>,</span><br><span class="line">                    [req.<span class="property">query</span>.<span class="property">openId</span>, req.<span class="property">query</span>.<span class="property">nickName</span>, req.<span class="property">query</span>.<span class="property">classId</span>]</span><br><span class="line">                );</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">return</span> sql.<span class="title function_">queryProm</span>(</span><br><span class="line">                    <span class="string">&quot;UPDATE user_reserve SET status=1 WHERE class_id=? AND user_id=?&quot;</span>,</span><br><span class="line">                    [req.<span class="property">query</span>.<span class="property">classId</span>, req.<span class="property">query</span>.<span class="property">openId</span>]</span><br><span class="line">                );</span><br><span class="line">        &#125;).<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">            res.<span class="title function_">send</span>(&#123;<span class="attr">results</span>: response&#125;);</span><br><span class="line">        &#125;).<span class="title function_">catch</span>(<span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">            res.<span class="title function_">send</span>(&#123;<span class="attr">error</span>: err&#125;);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//不要啥都写res，想啥呢</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure></p><p>这个“想啥呢”的注释是这样的，Express框架本身有一个回传数据功能的对象参数叫res，然后我写函数也习惯把数据本身叫res，这下好了，相当于我用回传的数据去调用他的成员函数send()，这一个数据哪儿来的send()函数啊？当然前端就没有收到任何回传的数据了。我纳闷了很久怎么Promise好好的就不能用了呢，最后登了服务器上去翻了翻log才发现问题，这也充分说明log在debug中的极端重要性。</p><p>当然用回调的效果是这样的： </p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="string">&#x27;cancelReserve&#x27;</span>:</span><br><span class="line">    sql.<span class="title function_">query</span>(<span class="string">&quot;UPDATE user_reserve SET status=0 WHERE class_id=? AND user_id=?&quot;</span>,[req.<span class="property">query</span>.<span class="property">classId</span>, req.<span class="property">query</span>.<span class="property">openId</span>], <span class="function">(<span class="params">error, results</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(error) </span><br><span class="line">            res.<span class="title function_">send</span>(&#123;<span class="attr">error</span>: error&#125;);</span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">            res.<span class="title function_">send</span>(&#123;<span class="attr">results</span>: results&#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure><p>那么既然也在服务器后端弃用了信道通信所在的腾讯云SDK，我也采用了Express原生的路由方式来将请求定位到以上MySQL通信模块所在的文件上。</p><h5 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h5><blockquote><p>别看我，我就是凑个小节数的，要不然就一个笔记太尴尬了。。。</p></blockquote><p>本次版本迭代，通过添加用户授权登录界面、从底层用原生请求方式重写前端通信模块和后端MySQL通信模块，并使用Promise进行异步编程封装，基本上修复了信道通信因登录API调整而无法使用，导致整个程序无法正常运行的bug。</p><h4 id="项目第三版"><a href="#项目第三版" class="headerlink" title="项目第三版"></a>项目第三版</h4><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP1.PNG" alt="WEAPP1"></p><p><center>小程序第三版主界面，更多预览请直接打开小程序或阅读本文后续内容</center><br></p><p>项目第三版的迭代原因是需求方提议加入普通学生用户端也能够发起一对一辅导预约，然后讲师能够对此进行接单的“辅导预约”功能。<br>我们开发方也趁着本次迭代的机会，对小程序的前端界面UI进行了大范围的重写，从而能够彻底弃用原先大范围采用腾讯云一站式小程序解决方案小程序demo的配色和界面元素的旧UI。</p><p><strong>在此特别感谢Jason Gao同学以及他的“有通知”小程序对本项目UI重写提供的设计参考和技术支持！</strong></p><p>在新UI的开发过程中的技术难点在于：</p><ol><li>取消了微信小程序的顶部、底部菜单栏后，小程序界面对于不同尺寸以及刘海屏手机的适配；</li><li>取消了底部菜单栏后，自行开发的底部菜单栏的路由结构问题；</li><li>取消了顶部菜单栏后，下拉刷新、返回导航、页面标题等顶部菜单栏功能不再实用的情况下的自主开发。</li><li>tab标签式导航栏的实现</li></ol><p>同时，我们也修复了众多之前两个版本未发现的、以及在本版本开发过程中遇到的逻辑功能上的bug，例如：</p><ol><li>预约时间相对于当前时间已经过期的未采取过期处理；</li><li>未对辅导预约进行一对一绑定而造成的多个讲师抢单重复预约的情况；</li><li>对于人数上限、备注等留空项目的前端数据处理不当；</li><li>iOS系统下“我的页面”用户头像被背景图案覆盖的问题；</li><li>还有其他的一些细节小bug；</li></ol><h5 id="开发难点及笔记-2"><a href="#开发难点及笔记-2" class="headerlink" title="开发难点及笔记"></a>开发难点及笔记</h5><p>在谈UI开发之前，我首先得回答这个问题：为什么要隐藏顶部菜单栏以及底部菜单栏呢？</p><p>理由有两个：</p><ul><li>功能上的需要：主要是微信小程序自带的底部菜单栏定制性奇差，必须得每一个菜单项对应的路径、图标、颜色、文字，乃至菜单项的数量，全部都在<code>app.json</code>里写死了，而且样式清一色都是死板的文字/图标/文字+图标，无法进行更高级别的个性化定制。就像本项目这样<strong>加一个高度明显超出菜单栏本身的大大的加号按钮</strong>，或者加一点其他的特殊样式，用微信小程序自带的底部菜单栏都是无法实现的。同理，微信小程序自带的顶部菜单栏同样也无法像本项目这样<strong>放置一个可点击的刷新按钮</strong>。</li><li>设计上的需要：从本文中的小程序界面效果图可以看出，这种底色完全一致的、通透的视觉效果，明显区别于直接采用微信小程序自带方案的其他大多数小程序的界面，是十分夺人眼球的设计（虽然直接采用微信小程序自带方案也可以做得相当美观）。</li></ul><h6 id="UI难点之一：屏幕尺寸适配"><a href="#UI难点之一：屏幕尺寸适配" class="headerlink" title="UI难点之一：屏幕尺寸适配"></a>UI难点之一：屏幕尺寸适配</h6><p><strong>微信小程序事实上就是一种webview套壳应用的变体</strong>，这个是众所周知的事情了。所以不难联想到当使用微信小程序自带的顶部菜单栏时，小程序的wxml界面自上而下渲染的<strong>起点</strong>，应当是在顶部菜单栏的下方的，就像一般的带标题栏的安卓webview页面，都是顶部的元素帮助撑起了手机系统顶部的状态栏以及顶部的菜单栏在内的一个相当大的高度。<br>如果隐藏了顶部菜单栏的话，就会出现wxml界面直接从状态栏下方开始渲染的情况，而且一般状态栏都是最顶层的，也就是说状态栏会遮挡一部分wxml内容。。。大概像下面这样：</p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP9.PNG" alt="WEAPP9"></p><p><center>在iPhone X上有刘海的话就更加尴尬了。。。</center><br></p><p>所以需要的就是将这一部分的位置空出来，尤其是对iPhone X的刘海要额外进行适配（后来在开发者工具中的测试我们也发现了iPhone 4/iPhone 5这一类小尺寸屏幕的手机也需要额外适配）。所以我们的思路就是动态定义包裹所有其他元素的<code>&lt;view class=&quot;root&quot;&gt;</code>的<code>padding-top</code>wxss属性。尽管wxss无法使用JS进行动态更改，wxml还是能用JS进行动态更改的。所以就想出了动态定义<code>class</code>属性的内容就OK了，代码如下——<br>wxml代码：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;root &#123;&#123;isIpx?&#x27;root-ipx&#x27;:&#x27;&#x27;&#125;&#125; &#123;&#123;isIp4?&#x27;root-ip4&#x27;:&#x27;&#x27;&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- content --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br></pre></td></tr></table></figure><br>JS代码：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> that = <span class="variable language_">this</span>;</span><br><span class="line">wx.<span class="title function_">getSystemInfo</span>(&#123;</span><br><span class="line">    <span class="attr">success</span>: <span class="keyword">function</span>(<span class="params">res</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span>(res.<span class="property">model</span> == <span class="string">&#x27;iPhone X&#x27;</span>)&#123;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isIpx</span> = <span class="literal">true</span>;</span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">isIpx</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isIpx</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(res.<span class="property">model</span> == <span class="string">&#x27;iPhone 5&#x27;</span> || res.<span class="property">model</span> == <span class="string">&#x27;iPhone 4&#x27;</span>)&#123;</span><br><span class="line">            <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isIp4</span> = <span class="literal">true</span>;</span><br><span class="line">            that.<span class="title function_">setData</span>(&#123;</span><br><span class="line">                <span class="attr">isIp4</span>: <span class="title function_">getApp</span>().<span class="property">data</span>.<span class="property">isIp4</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><br>wxss代码：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.root-ip4</span> &#123;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">30</span>rpx; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.root-ipx</span> &#123;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">60</span>rpx; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>但是在之后的测试中发现，一旦预约课程的表单变长，可以滚动起来了以后，状态栏底下会出现本来应该被遮罩了的表单。。这是因为<code>padding-top</code>只是把顶部元素下移了，状态栏本身是透明的，所以肯定无法遮罩滚动到顶部的表单。解决方法和上面是一样的，自己再定义一个<code>&lt;view&gt;</code>元素，用来遮挡状态栏底部的其他元素就OK了，同样要对特殊尺寸的屏幕做适配，此处就不再赘述了。</p><h6 id="UI难点之二：自行开发的底部菜单栏的路由结构"><a href="#UI难点之二：自行开发的底部菜单栏的路由结构" class="headerlink" title="UI难点之二：自行开发的底部菜单栏的路由结构"></a>UI难点之二：自行开发的底部菜单栏的路由结构</h6><p>为什么要如此强调路由结构呢？因为你需要知道你当前用底部菜单栏打开的页面是哪一个。否则底部菜单栏如何将当前打开页面对应的按钮进行高亮或者其他处理，来对用户形成一种辅助的标识呢？我们在这里使用了一个<strong>相当讨巧的办法</strong>来解决这个问题：</p><p>我们并不删除底部菜单栏在<code>app.json</code>中的代码使之彻底消失，只是通过微信小程序API函数<code>wx.hideTabBar</code>对其进行隐藏，这样其基本的路由结构依然存在，无需另外写一个公共的路由代码。页面跳转可以使用<code>wx.switchTab</code>。然后由于自定义的底部菜单栏是重复出现在页面上的，准确来说应该是首页和“我的”页面上，所以我们采用了微信小程序的模板类型元素<code>&lt;template&gt;</code>来进行代码的复用：<br>wxml代码的写法是：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span> <span class="attr">name</span>=<span class="string">&quot;tabbar&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;tabbar-wrap&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;tabbar-index&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;tabbarRoute&quot;</span> <span class="attr">data-index</span>=<span class="string">&quot;0&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">image</span> <span class="attr">src</span>=<span class="string">&quot;&#123;&#123;indexActive?&#x27;/images/index-hl.png&#x27;:&#x27;/images/index.png&#x27;&#125;&#125;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">view</span> <span class="attr">style</span>=<span class="string">&quot;color: &#123;&#123;indexActive?&#x27;#17abe3&#x27;:&#x27;#bfbfbf&#x27;&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">        首页</span><br><span class="line">      <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;tabbar-reserve&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">image</span> <span class="attr">src</span>=<span class="string">&quot;/images/new-hl.png&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;tabbarRoute&quot;</span> <span class="attr">data-index</span>=<span class="string">&quot;1&quot;</span> &gt;</span><span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;tabbar-user&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;tabbarRoute&quot;</span> <span class="attr">data-index</span>=<span class="string">&quot;2&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">image</span> <span class="attr">src</span>=<span class="string">&quot;&#123;&#123;userpageActive?&#x27;/images/user-hl.png&#x27;:&#x27;/images/user.png&#x27;&#125;&#125;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">view</span> <span class="attr">style</span>=<span class="string">&quot;color: &#123;&#123;userpageActive?&#x27;#17abe3&#x27;:&#x27;#bfbfbf&#x27;&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">        我的</span><br><span class="line">      <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br></pre></td></tr></table></figure><br>在对应的页面中引用的方法也很简单<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">import</span> <span class="attr">src</span>=<span class="string">&quot;/template/tabbar&quot;</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- content --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">template</span> <span class="attr">is</span>=<span class="string">&quot;tabbar&quot;</span> <span class="attr">data</span>=<span class="string">&quot;&#123;&#123;...tabStatus&#125;&#125;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br></pre></td></tr></table></figure><br>其中，三点运算符表示传进<code>tabStatus</code>的全部子成员（这个<code>tabStatus</code>有两个成员：<code>indexActive</code>和<code>userpageActive</code>），也就意味着上面代码块里的<code>&lt;template&gt;</code>中的所有<code>indexActive</code>和<code>userpageActive</code>不用再写成<code>tabStatus.indexActive</code>和<code>tabStatus.userpageActive</code>了，很方便吧，这可是ES6的特性哦！<br>wxss的代码也贴一下，这样也可以直接套用样式：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.tabbar-wrap</span> &#123;</span><br><span class="line">  <span class="attribute">display</span>: flex;</span><br><span class="line">  <span class="attribute">flex-direction</span>: row;</span><br><span class="line">  <span class="attribute">justify-content</span>: space-around;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">position</span>: fixed;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">90</span>rpx;</span><br><span class="line">  <span class="attribute">bottom</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">padding-top</span>: <span class="number">20</span>rpx;</span><br><span class="line">  <span class="attribute">padding-bottom</span>: <span class="number">35</span>rpx;</span><br><span class="line">  <span class="attribute">border-top</span>: .<span class="number">5px</span> solid <span class="number">#cccccc</span>;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">0.9</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tabbar-wrap</span> view &#123;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">30%</span>;</span><br><span class="line">  <span class="attribute">display</span>: flex;</span><br><span class="line">  <span class="attribute">flex-direction</span>: column;</span><br><span class="line">  <span class="attribute">justify-content</span>: space-around;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tabbar-wrap</span> <span class="selector-class">.tabbar-reserve</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>:fixed;</span><br><span class="line">  <span class="attribute">bottom</span>:<span class="number">30</span>rpx;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tabbar-wrap</span> view image &#123;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">60</span>rpx;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">60</span>rpx;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">0</span> auto;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tabbar-wrap</span> <span class="selector-class">.tabbar-reserve</span> image&#123;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">115</span>rpx;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">115</span>rpx;</span><br><span class="line">  <span class="attribute">margin-bottom</span>: <span class="number">20</span>rpx;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#fff</span>;  </span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">50%</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tabbar-wrap</span> view view &#123;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">25</span>rpx;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">  <span class="attribute">margin-top</span>: <span class="number">1</span>rpx;</span><br><span class="line">  <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>以上操作的教程来源是<a href="https://blog.csdn.net/w10322331/article/details/80351713">这里</a>。</p><h6 id="UI难点之三：重写返回导航、页面标题和刷新组件"><a href="#UI难点之三：重写返回导航、页面标题和刷新组件" class="headerlink" title="UI难点之三：重写返回导航、页面标题和刷新组件"></a>UI难点之三：重写返回导航、页面标题和刷新组件</h6><p>既然隐藏了顶部菜单栏，可以说也相当于在打开新页面时也失去了微信小程序自动生成的标题和返回按钮，然后下拉刷新也别扭了很多（尤其是在iPhone X上，你下拉刷新的时候根本看不到那个刷新动画。。。），这就意味着以上功能全部都得自主开发。</p><p>我的解决方案也异常简单，返回导航直接使用微信小程序的API函数<code>wx.navigateBack</code>，刷新也不过是在图标上绑定钩子函数，这里的主要难点在于<strong>刷新动画的协调性</strong>。<br>具体怎么说呢？wxss本质上就是CSS，刷新动画的一般实现都是一个圆形刷新图标的旋转，而这个旋转一般都是CSS的效果。但是若像本项目一样使用带箭头的圆环，则会出现一个很尴尬的情况：<br>当你正在“加载数据”这一状态时，圆环是不停旋转的，而当“数据加载结束”时，圆环需要处于一个静止的状态。若将静止状态设置为一个固定的图片，例如说刷新图标的箭头处于图标的正12点方向，则你会发现，”加载数据”这一状态结束时，箭头并不一定处于正12点，而在切换到“数据加载结束”这一状态时，箭头突然就跳到了正12点方向。</p><p>可以先看看“有通知”小程序的刷新动画实现方法，基本上就是点击刷新后固定地转一圈，这样既避免了上述尴尬的情况，也可以让用户体验到类似于“转了一圈就加载了”的“快速加载”的观感。</p><p>那么我们是如何实现的呢？可以说是一次很成功的尝试吧：让“数据加载结束”这一静止状态不再是一张固定的图片，而是在下一次加载时箭头直接从之前停下的方向继续开始转动！这样给用户的体验就不再是十分突兀的，反而有一种很自然自然的流畅感和美感。</p><p>实现方法也很简单，设定好不同状态下的CSS属性即可，只不过需要JS在与后端通信的加载过程中向wxml里刷新图标的<code>style=&quot;&quot;</code>传入不同的变量，以启用或关闭不同的动画。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.line</span> <span class="selector-class">.title-wrap</span> <span class="selector-class">.refresh-button</span> &#123;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">45</span>rpx <span class="meta">!important</span>;</span><br><span class="line">  <span class="attribute">line-height</span>: <span class="number">90</span>rpx;</span><br><span class="line">  <span class="attribute">padding-left</span>: <span class="number">10</span>rpx;</span><br><span class="line">  <span class="attribute">padding-top</span>: <span class="number">15</span>rpx;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#6d6d72</span>;</span><br><span class="line">  <span class="attribute">animation</span>: spin <span class="number">800ms</span> infinite linear;  </span><br><span class="line">  <span class="attribute">animation-play-state</span>: paused;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.line</span> <span class="selector-class">.title-wrap</span> <span class="selector-class">.refresh-button</span><span class="selector-class">.active</span> &#123;</span><br><span class="line">  <span class="attribute">animation-play-state</span>: running;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">@keyframes</span> spin &#123;</span><br><span class="line">  <span class="number">0%</span> &#123;</span><br><span class="line">    <span class="attribute">transform</span>: <span class="built_in">rotate</span>(<span class="number">360deg</span>);</span><br><span class="line">    <span class="attribute">transform-origin</span>: <span class="number">60%</span> <span class="number">55%</span>;</span><br><span class="line">    -webkit-<span class="attribute">transform</span>: <span class="built_in">rotate</span>(<span class="number">360deg</span>);</span><br><span class="line">    -webkit-<span class="attribute">transform-origin</span>: <span class="number">60%</span> <span class="number">55%</span>;  </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="number">100%</span> &#123;</span><br><span class="line">    <span class="attribute">transform</span>: <span class="built_in">rotate</span>(<span class="number">0deg</span>);</span><br><span class="line">    <span class="attribute">transform-origin</span>: <span class="number">60%</span> <span class="number">55%</span>;  </span><br><span class="line">    -webkit-<span class="attribute">transform</span>: <span class="built_in">rotate</span>(<span class="number">0deg</span>);</span><br><span class="line">    -webkit-<span class="attribute">transform-origin</span>: <span class="number">60%</span> <span class="number">55%</span>;  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这个<code>animation-play-state</code>相当关键，就是这一属性支持了我们的刷新开始和结束的自然切换。</p><p>哦对了，貌似还有页面标题没讲，这个其实就是自己添加标题写在相应的位置，如果需要动态标题则往wxml中添加变量。注意给返回、刷新之类的按钮留好位置即可。</p><h6 id="UI难点之四：tab标签式导航栏的实现"><a href="#UI难点之四：tab标签式导航栏的实现" class="headerlink" title="UI难点之四：tab标签式导航栏的实现"></a>UI难点之四：tab标签式导航栏的实现</h6><p>这个说实话网络上教程相当多，但是这里仍然有一些亮点，例如在高亮标签下的“下划线”。这并不是简单的用CSS的下划线属性实现的，而是使用了CSS的伪类概念。说实话，在后来其他项目的开发过程中，我才真正开始理解并有意识地使用起了伪类，给某一页面元素的正上方或正下方添加一些附属元素。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">view</span> <span class="attr">class</span>=<span class="string">&quot;navbar&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- tabbar标签式导航栏 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">text</span> <span class="attr">wx:for</span>=<span class="string">&quot;&#123;&#123;navArrayStu&#125;&#125;&quot;</span> <span class="attr">data-index</span>=<span class="string">&quot;&#123;&#123;index&#125;&#125;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;item &#123;&#123;currentNavTab==index?&#x27;active&#x27;:&#x27;&#x27;&#125;&#125;&quot;</span> <span class="attr">wx:key</span>=<span class="string">&quot;unique&quot;</span> <span class="attr">bindtap</span>=<span class="string">&quot;bindNavbarTap&quot;</span>&gt;</span></span><br><span class="line">    &#123;&#123;item&#125;&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">text</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">view</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:if</span>=<span class="string">&quot;&#123;&#123;currentNavTab==0&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 当currentNavTab==0时显示这里的内容 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">block</span> <span class="attr">wx:if</span>=<span class="string">&quot;&#123;&#123;currentNavTab==1&#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 当currentNavTab==1时显示这里的内容 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">bindNavbarTap</span>(<span class="params">e</span>) &#123;</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">    <span class="attr">currentNavTab</span>: e.<span class="property">currentTarget</span>.<span class="property">dataset</span>.<span class="property">index</span></span><br><span class="line">  &#125;)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="selector-class">.navbar</span> <span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">  <span class="attribute">line-height</span>: <span class="number">30</span>rpx;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">40</span>rpx;</span><br><span class="line">  <span class="attribute">font-weight</span>: lighter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.navbar</span> <span class="selector-class">.item</span><span class="selector-class">.active</span> &#123;</span><br><span class="line">  <span class="attribute">font-weight</span>: bolder;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 伪类的使用 */</span></span><br><span class="line"><span class="selector-class">.navbar</span> <span class="selector-class">.item</span><span class="selector-class">.active</span><span class="selector-pseudo">::after</span> &#123;</span><br><span class="line">  <span class="attribute">content</span>: <span class="string">&quot;&quot;</span>;</span><br><span class="line">  <span class="attribute">display</span>: block;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">bottom</span>: -<span class="number">20</span>rpx;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">right</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">5</span>rpx;</span><br><span class="line">  <span class="attribute">background</span>: <span class="number">#6d6d72</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="BUG解决之一：预约时间相对于当前时间已经过期的未采取过期处理"><a href="#BUG解决之一：预约时间相对于当前时间已经过期的未采取过期处理" class="headerlink" title="BUG解决之一：预约时间相对于当前时间已经过期的未采取过期处理"></a>BUG解决之一：预约时间相对于当前时间已经过期的未采取过期处理</h6><p>过期处理说实话确实是个败笔，因为这个东西本来应该是后端完成的东西，我却非常不厚道的在小程序里面加入了这个功能（不是在批评某些“大前端”思想，但是这个确实后端来做会更好一点，毕竟数据量一大还不如后端处理好了再发给前端，某些过期数据的体积也可以适当压缩一下，况且<strong>我到现在都还没做分页</strong>，感觉药丸。。。）。而且这个过期处理确实挺重要的，在这种预约类小程序里面，所以我也在寻找更好的解决方案，希望（如果有坚持读到这里的）大佬能够联系我提供一些建议，不胜感激！</p><p>我的想法是一拿到数据就交给某个工具函数去处理数据，处理完之后再返回数据。这里我直接把过期处理添加到了时间处理函数里面，具体工具函数如下：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> curDate= utils.<span class="title function_">formatTime</span>(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line"><span class="keyword">var</span> curDateFull = <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">timeFormat</span> = (<span class="params">str, contentType</span>) =&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; str.<span class="property">length</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (contentType == <span class="string">&#x27;class&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">var</span> start = str[i].<span class="property">class_timestart</span>;</span><br><span class="line">      <span class="keyword">var</span> end = str[i].<span class="property">class_timend</span>;</span><br><span class="line">      <span class="keyword">var</span> date = <span class="keyword">new</span> <span class="title class_">Date</span>(str[i].<span class="property">class_date</span>.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">10</span>));</span><br><span class="line">      <span class="keyword">var</span> itemDate = str[i].<span class="property">class_date</span>;      </span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (contentType == <span class="string">&#x27;course&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">var</span> start = str[i].<span class="property">course_timestart</span>;</span><br><span class="line">      <span class="keyword">var</span> end = str[i].<span class="property">course_timend</span>;</span><br><span class="line">      <span class="keyword">var</span> date = <span class="keyword">new</span> <span class="title class_">Date</span>(str[i].<span class="property">course_date</span>.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">10</span>));</span><br><span class="line">      <span class="keyword">var</span> itemDate = str[i].<span class="property">course_date</span>;      </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> curTime = curDateFull.<span class="title function_">toLocaleString</span>(<span class="string">&#x27;chinese&#x27;</span>, &#123; <span class="attr">hour12</span>: <span class="literal">false</span> &#125;).<span class="title function_">slice</span>(<span class="number">10</span>, <span class="number">18</span>).<span class="title function_">replace</span>(<span class="regexp">/:/g</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">var</span> itemTime = start.<span class="title function_">replace</span>(<span class="regexp">/:/g</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 过期处理在这儿⬇️</span></span><br><span class="line">    <span class="comment">// 如果该记录的日期本身就小于当前的日期，一定过期</span></span><br><span class="line">    <span class="comment">// 如果该记录的日期与当前日期相同，但时间比当前时间要早，也一定过期</span></span><br><span class="line">    <span class="keyword">if</span>((itemDate &lt; curDate) || ((itemDate == curDate) &amp;&amp; (curTime &gt; itemTime)) )&#123;</span><br><span class="line">      str[i].<span class="property">overtime</span> = <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      str[i].<span class="property">overtime</span> = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    date = date.<span class="title function_">getFullYear</span>() + <span class="string">&quot;年&quot;</span> +</span><br><span class="line">      (<span class="built_in">parseInt</span>(date.<span class="title function_">getMonth</span>()) + <span class="number">1</span>).<span class="title function_">toString</span>() + <span class="string">&quot;月&quot;</span> +</span><br><span class="line">      date.<span class="title function_">getDate</span>() + <span class="string">&quot;日&quot;</span>;</span><br><span class="line">    start = start.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (start.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">1</span>) == <span class="string">&quot;0&quot;</span>) &#123;</span><br><span class="line">      start = start.<span class="title function_">slice</span>(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    end = end.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (end.<span class="title function_">slice</span>(<span class="number">0</span>, <span class="number">1</span>) == <span class="string">&quot;0&quot;</span>) &#123;</span><br><span class="line">      end = end.<span class="title function_">slice</span>(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (contentType == <span class="string">&#x27;class&#x27;</span>) &#123;</span><br><span class="line">      str[i].<span class="property">class_date</span> = date;</span><br><span class="line">      str[i].<span class="property">class_timestart</span> = start;</span><br><span class="line">      str[i].<span class="property">class_timend</span> = end</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (contentType == <span class="string">&#x27;course&#x27;</span>) &#123;</span><br><span class="line">      str[i].<span class="property">course_date</span> = date;</span><br><span class="line">      str[i].<span class="property">course_timestart</span> = start;</span><br><span class="line">      str[i].<span class="property">course_timend</span> = end</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;时间处理后：&quot;</span>, str);</span><br><span class="line">  <span class="keyword">return</span> str;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h6 id="BUG解决之二：未对辅导预约进行一对一绑定而造成的多个讲师抢单重复预约的情况"><a href="#BUG解决之二：未对辅导预约进行一对一绑定而造成的多个讲师抢单重复预约的情况" class="headerlink" title="BUG解决之二：未对辅导预约进行一对一绑定而造成的多个讲师抢单重复预约的情况"></a>BUG解决之二：未对辅导预约进行一对一绑定而造成的多个讲师抢单重复预约的情况</h6><p>“辅导预约”这个功能事实上也就是用户“课程预约”功能的一个翻转：讲师自由发布课程，多个用户预约一个讲师的课程，人数上限可以有也可以不设置。反之，用户自由发布辅导需求，多个讲师预约一个用户的课程，但是是一对一的课程，所以人数上限其实是1。但我这里没有再使用人数上限的功能了，而是采用了一个很清奇的绑定思路：多表左联合查询。</p><p>这个说实话也是个败笔😂（没错，包括上面那个在内，你在本文看到的所有bug解决的思路，都是些让你觉得很滑稽的解决方式，因为我当时是真的没办法快速找到一些最佳实践的。。。）<br>正常情况下的思路应该是要去维护一个新的数据库字段，就是“是否已经有讲师预约”这样的一个标志字段。<br>但是我这里的处理思路就很清奇，既然已经被讲师预约了的话，那是不是可以让用户的预约数据库表和讲师的接单数据库表进行一个左联合查询，然后如果某个字段联合查询后查询不到讲师的信息（例如昵称nickname之类的）就可以认为是未被讲师接单呢？反之是不是就可以被认为是已经被接单呢？<br>这个清奇的思路事实上是很差劲的，因为这个涉及到一个查询效率的问题，联合查询总的来说肯定要比单表查询要慢很多，数据一多肯定影响性能，而且这样返回前台数据不可避免地泄露了讲师的信息。</p><p>当然，还是那句老话，安全起见，后端数据库表结构以及相应的SQL查询语句我是不可能公开的。所以这里就只有描述，没有代码了。</p><h6 id="BUG解决之三：对于人数上限、备注等留空项目的前端数据处理不当"><a href="#BUG解决之三：对于人数上限、备注等留空项目的前端数据处理不当" class="headerlink" title="BUG解决之三：对于人数上限、备注等留空项目的前端数据处理不当"></a>BUG解决之三：对于人数上限、备注等留空项目的前端数据处理不当</h6><p>这是个相当玄学的问题，什么叫“处理不当”呢？这涉及到用户体验与数据库管理之间的矛盾。用户当然希望这样的功能实现：在填写的时候，“人数上限”一栏留空，就代表人数上限为无上限，填入数字再表示有一个确定的上限，“备注”留空，就代表没有备注，填入备注就代表有一段备注。但是数据库管理的时候，一个字段的格式一般是固定的，我不可能为了存储“无上限”这一信息就让一个人数上限的字段同时支持整型数和字符或者别的什么，所以我只能无奈地让数字0代表无上限。同时，备注也可以存储为一个“NULL”来代表无备注。但是问题来了，当上传到后端时，前端至少需要对数据做一个预处理：把人数上限从<code>undefined</code>改成0，把备注从<code>undefined</code>改成NULL。我当时就考虑到这里，但是后来才发现：等等，那后端返回到前端呢？不是也得再经历一次相反的转换吗？</p><p>大概就是这样一个逻辑：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (classItem.<span class="property">student_limit</span> == <span class="string">&#x27;0&#x27;</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">        <span class="attr">studentLimit</span>: <span class="string">&#x27;无上限&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">        <span class="attr">studentLimit</span>: classItem.<span class="property">student_limit</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (classItem.<span class="property">student_sum</span> == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">        <span class="attr">studentSum</span>: <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setData</span>(&#123;</span><br><span class="line">        <span class="attr">studentSum</span>: classItem.<span class="property">student_sum</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (classItem.<span class="property">class_intro</span> == <span class="string">&quot;undefined&quot;</span>) &#123;</span><br><span class="line">    classItem.<span class="property">class_intro</span> = <span class="string">&quot;无&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h6 id="BUG解决之四：iOS系统下“我的页面”用户头像被背景图案覆盖的问题"><a href="#BUG解决之四：iOS系统下“我的页面”用户头像被背景图案覆盖的问题" class="headerlink" title="BUG解决之四：iOS系统下“我的页面”用户头像被背景图案覆盖的问题"></a>BUG解决之四：iOS系统下“我的页面”用户头像被背景图案覆盖的问题</h6><p>这个确实是个意想不到的BUG，在正式上线之后才发现Safari浏览器的渲染引擎存在着这样的bug：当一个具有<code>transform</code>的CSS属性的元素作为背景，而另外一个图片元素在其上方时，将不能够通过<code>z-index</code>属性来控制它们的层级关系。</p><p>之后的解决方案是从网上搜索得出的<strong>“以毒攻毒”法</strong>。是的，你没有看错，这个方法就是用<code>transform</code>来解决<code>transform</code>带来的问题的。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="selector-class">.avatar-img</span>&#123;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">140</span>rpx;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">140</span>rpx;</span><br><span class="line">  <span class="attribute">margin</span>:<span class="number">50</span>rpx auto <span class="number">30</span>rpx;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#bfbfbf</span>;</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">50%</span>;</span><br><span class="line">  <span class="attribute">z-index</span>: <span class="number">99</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">2px</span> solid <span class="number">#fff</span>;</span><br><span class="line">  <span class="attribute">transform</span>: <span class="built_in">translateZ</span>(<span class="number">100</span>rpx) <span class="comment">/* 这个就是解决办法，“以毒攻毒”，简单粗暴 */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.colored-top</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: fixed;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">left</span>: -<span class="number">35</span>rpx;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">300%</span>;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#17abe3</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">40%</span>;</span><br><span class="line">  <span class="attribute">z-index</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">transform</span>: <span class="built_in">rotate</span>(<span class="number">8deg</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="其他小BUG"><a href="#其他小BUG" class="headerlink" title="其他小BUG"></a>其他小BUG</h6><p>这里将会根据项目当前进度，及时更新一些其他的小BUG以及处理方式，也就相当于一些后续了~</p><h5 id="小程序最终界面-1"><a href="#小程序最终界面-1" class="headerlink" title="小程序最终界面"></a>小程序最终界面</h5><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP1.PNG" alt="WEAPP1"></p><p><center>小程序第三版主界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP10.jpeg" alt="WEAPP1"></p><p><center>用户课程预约界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP11.jpeg" alt="WEAPP1"></p><p><center>用户辅导预约界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP12.jpeg" alt="WEAPP1"></p><p><center>讲师辅导接单界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP13.jpeg" alt="WEAPP1"></p><p><center>讲师辅导接单界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP14.jpeg" alt="WEAPP1"></p><p><center>讲师发布课程界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP15.jpeg" alt="WEAPP1"></p><p><center>“我的”界面</center><br></p><p><img src="/2018/06/28/Notes-About-Recent-Projects-3/WEAPP16.jpeg" alt="WEAPP1"></p><p><center>“关于”界面</center><br></p><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><blockquote><p>先。。。先容我吐槽一下吧。<br>讲了挺多的，确实，一看发现上千行了😂（至少在markdown里面是这样，1.3k），我打算以后有机会的话拆成两篇文章发布。<br>写的时间跨度一个月吧，因为各种事情，写写停停，甚至在某几次提笔重新开始继续写下去的时候，都发现自己都不知道之前到底写了什么，现在该写什么，写的初心是什么。都快被各种事情给搞忘了。<br>所以说，要想系统性的总结一个东西，很难。<br>况且我这个小程序至少前端代码是必须要放到GitHub上去的，要想再系统性地整理并分享一个东西，更难。</p></blockquote><p>首要的，我还是非常感谢明导和郑导、感谢搭档王云程同学（@fafnir）、感谢提供过帮助的高亦非同学（Jason Gao）以及感谢计通学院学生讲师团，给予了我这次项目实战的宝贵机会。如果没有这次实战机会的话，估计我也很难得出如此系统的经验，并写出内容如此（冗长而）丰富的文章了吧。这是一次从零开始、至少是从需求开始的一次系统性的开发，虽然过程不免因为个人水平仍处于成长期、个人其他事务的干扰等各种原因有着种种波折起伏，但是所有的过程都是在从宏观到微观、从代码开发到客户沟通再到界面设计，几乎是全方位地锻炼我的各种能力。</p><p>所以，再次感谢在开发过程中给予了我各种帮助和指导的所有人，谢谢大家！</p><blockquote><p>最后，这是本站的第七篇正式发文，感谢阅读。<br>如有意见和建议，欢迎通过首页的联系方式联系作者。<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Environment Configuration for Yolo-darknet</title>
      <link href="/2018/02/20/Environment-Configuration-for-Yolo-darknet/"/>
      <url>/2018/02/20/Environment-Configuration-for-Yolo-darknet/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Just do it.<br>Just do something new and do it yourself.</p></blockquote><p>记录一些关于yolo-darknet环境配置踩过的坑。<br>能力有限，但求指点，欢迎交流。</p><span id="more"></span><h2 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h2><ul><li>OS: Ubuntu 16.04 LTS</li><li>PC: ASUS K550J (EFI enable)</li><li>GPU: GTX950M</li><li>CPU: i5-4200H</li><li>RAM: 4G</li><li>DISK: 1T HDD (no SSD) </li></ul><h2 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h2><h3 id="安装Ubuntu"><a href="#安装Ubuntu" class="headerlink" title="安装Ubuntu"></a>安装Ubuntu</h3><ol><li>用UltraISO把iso文件烧到你的U盘，<strong>进BIOS打开EFI引导，并选择EFI模式下的U盘为第一引导项</strong></li><li>安装Ubuntu到一个空白分区（可以通过分区压缩获得，如果是全新电脑就直接开始分区了）：<ul><li><strong>注意根据提示划分那块bios efi的小分区，几十K即可</strong>；</li><li><strong>划分swap交换分区，一般是你内存大小的3倍大，划在主分区后面</strong>；</li><li>剩下的划给主分区；</li><li>选择安装启动器到<strong>Windows使用的那个EFI启动分区</strong>。</li></ul></li><li>进入分区界面前有几个选项要注意：<ul><li>让你顺带安装更新的那个，<strong>不要勾选</strong>，更新的源大多自动匹配到了国外的，网速你懂的；</li><li>让你安装第三方闭源驱动和软件的，<strong>必须勾选</strong>，能解决很多开源驱动带来的问题。</li></ul></li><li>安装，然后回到BIOS里面你会惊奇的发现出现了Ubuntu的EFI模式引导项（准确来说是两个，估计是那次我多搞了一个/boot）选择它为第一个。</li><li>成功进入Ubuntu</li></ol><h3 id="安装OpenCV"><a href="#安装OpenCV" class="headerlink" title="安装OpenCV"></a>安装OpenCV</h3><p>安装OpenCV主要是为了使用外置摄像头进行图像采集。</p><p>GitHub上有自动安装版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo su </span><br><span class="line">git <span class="built_in">clone</span> https://github.com/jayrambhia/Install-OpenCV/tree/master/Ubuntu</span><br></pre></td></tr></table></figure><p>进入安装目录下的/2.4，提升*.sh文件的权限并执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line"><span class="built_in">chmod</span> a+x *.sh</span><br><span class="line">./opencv2_4_10.sh</span><br></pre></td></tr></table></figure><p>然后就会开始<strong>极其漫长</strong>的安装过程。</p><blockquote><p>第一次安装到某个阶段的时候卡死，<br>硬盘灯不闪，鼠标键盘没反应，我还以为安装失败强行重启了。<br>然后又开始一遍，又卡死。<br>我绝望了，但是冷静了下来，想了想<br>——怕是自己电脑配置太渣。<br>然后在安装前关闭了所有无关程序，<br>唯独打开了系统监视器（即Windows下的任务管理器）。<br>之后就非常惊奇地看到卡死的时候：<br>内存+CPU，全部占用100%<br>然后过了大概一个多小时，又全部降回去了，<br>没过三分钟，又是内存飙到100%，CPU反倒正常了<br>目测过了三个多小时，还是这个样子，倒是命令行每隔十几分钟跳一次字，<br>系统时钟已经卡到了和实际时间存在了十分钟到半小时不等的时差，<br>只有某几次命令行跳字的时候，内存占用下来了一点，系统时间一秒刷新了十几分钟<br>最后一脸无奈地睡了。<br>第二天打开笔记本盖子一看，<br>装好了，老大一个success。</p></blockquote><h3 id="安装darknet"><a href="#安装darknet" class="headerlink" title="安装darknet"></a>安装darknet</h3><p>打开终端<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line">git <span class="built_in">clone</span> http://github.com/pjreddie/darknet.git</span><br><span class="line"><span class="built_in">cd</span> darknet</span><br></pre></td></tr></table></figure><br>用gedit修改makefile文件<br><strong>令OPENCV=1</strong><br>然后在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure><h3 id="安装NVIDIA官方GPU驱动"><a href="#安装NVIDIA官方GPU驱动" class="headerlink" title="安装NVIDIA官方GPU驱动"></a>安装NVIDIA官方GPU驱动</h3><p>首先<strong>禁用开源驱动</strong></p><p>新建一个.conf文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure><p>写入以下内容<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">blacklist lbm-nouveau</span><br><span class="line">options nouveau modeset=0</span><br><span class="line">alias nouveau off</span><br><span class="line">alias lbm-nouveau off</span><br></pre></td></tr></table></figure><br>保存，重启后再打开终端，输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure><br>无输出即禁用成功</p><p>正式开始安装NVIDIA官方驱动了<br>我这里选择的是<strong>直接到系统的“软件和更新”里的“附加驱动”选择安装NVIDIA的专有驱动</strong><br>（不要管他是否显示tested，安装就是了）</p><p>等待安装成功后，重启打开终端，输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><br>正确显示你当前GPU的状况就OK了</p><h3 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h3><p>CUDA下载地址：<a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a><br>选项顺序是Linux-x86_64-Ubuntu-16.04-deb(local)<br>1点多G，然后找个下载速度快的地方下了它，推荐<strong>迅雷等下载工具</strong>，<br>虽然并没有加速，但毕竟服务器在境外，<strong>浏览器没法断点续传</strong>，连接一断就得重新下载。</p><p>然后把下载好的文件包拷到“/home/用户名/”目录下，在终端里面输入<br><strong>（注意你的deb文件名不一定是这个，这个是旧版的了）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb</span><br><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install cuda</span><br></pre></td></tr></table></figure><p>安装完成后输入<br><strong>（注意你的cuda文件夹不一定是这个7.5的，这个是旧版的了）</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda-7.5/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p><h3 id="再次安装darknet"><a href="#再次安装darknet" class="headerlink" title="再次安装darknet"></a>再次安装darknet</h3><p>再次用gedit打开makefile<br><strong>（注意你的cuda文件夹不一定是这个7.5的，这个是旧版的了）</strong><br>令开头GPU=1，同时令NVCC = /usr/local/cuda-7.5/bin/nvcc后保存退出<br>然后在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure><h2 id="测试darknet"><a href="#测试darknet" class="headerlink" title="测试darknet"></a>测试darknet</h2><h3 id="下载模型-测试模型"><a href="#下载模型-测试模型" class="headerlink" title="下载模型+测试模型"></a>下载模型+测试模型</h3><p>到这儿下载*.weight格式的模型：<a href="http://pjreddie.com/darknet/yolo/">http://pjreddie.com/darknet/yolo/</a></p><p>终端切换到darknet的安装目录下<br>示例命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./darknet detect cfg/yolo.cfg yolo.weight data/horses.jpg</span><br><span class="line">./darknet yolo <span class="built_in">test</span> cfg/yolo-tiny.cfg yolo-tiny.weight</span><br></pre></td></tr></table></figure></p><h3 id="使用电脑-手机摄像头采集图像"><a href="#使用电脑-手机摄像头采集图像" class="headerlink" title="使用电脑/手机摄像头采集图像"></a>使用电脑/手机摄像头采集图像</h3><p>电脑摄像头：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector demo cfg/voc.data cfg/tiny-yolo-voc.cfg weights/tiny-yolo-voc.weights</span><br></pre></td></tr></table></figure></p><p>手机摄像头：</p><p>先在手机上安装好<strong>IP摄像头</strong>APP，配置好地址后，先用浏览器访问以确定视频源的路径<br><strong>(因此这里的地址是你配置并确定好视频源的地址)</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector demo data/coco.data yolo.cfg yolo.weights http://192.168.191.2:8080/video</span><br></pre></td></tr></table></figure></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://blog.csdn.net/samylee/article/details/51684856">http://blog.csdn.net/samylee/article/details/51684856</a></li><li><a href="http://blog.csdn.net/wjbwjbwjbwjb/article/details/52125475">http://blog.csdn.net/wjbwjbwjbwjb/article/details/52125475</a></li><li><a href="http://blog.csdn.net/u014696921/article/details/65626751">http://blog.csdn.net/u014696921/article/details/65626751</a></li><li><a href="http://blog.csdn.net/wuzuyu365/article/details/52469131">http://blog.csdn.net/wuzuyu365/article/details/52469131</a></li><li><a href="http://blog.csdn.net/zafir_410/article/details/73188228">http://blog.csdn.net/zafir_410/article/details/73188228</a></li><li><a href="http://blog.csdn.net/u013832707/article/details/53438574">http://blog.csdn.net/u013832707/article/details/53438574</a></li><li><a href="https://www.cnblogs.com/jackchen-Net/p/7954138.html">https://www.cnblogs.com/jackchen-Net/p/7954138.html</a></li></ol><blockquote><p>最后，这是本站的第六篇正式发文，感谢阅读。<br>如有意见和建议，欢迎通过首页的联系方式联系作者，<br>本文参考资料均来源于网络，作者保留相关权利，转载请注明出处。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> experience </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>First to NeXT</title>
      <link href="/2018/02/14/First-to-NeXT/"/>
      <url>/2018/02/14/First-to-NeXT/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Maybe it is the first.<br>But in my view, that may be the NeXT.</p></blockquote><p>名字不重要，形式也不重要，重要的是内容。<br>这里将会陆续发布一些技术工作的经验谈，然而仅仅是经验谈而已。</p><span id="more"></span><p>更多的都是需要读者自己去探索，<br>这一方天地下，比我们的视野更远的地方。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new <span class="string">&quot;First to NeXT&quot;</span></span><br><span class="line">hexo d -g</span><br></pre></td></tr></table></figure><blockquote><p>这是本站第一篇正式发文，感谢阅读！</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> intro </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
