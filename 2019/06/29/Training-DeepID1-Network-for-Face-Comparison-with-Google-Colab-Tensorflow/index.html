<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.4">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.4" color="#222">







<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.0.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  
  <meta name="keywords" content="experience," />


<meta name="description" content="本文由2019年6月《软件工程》必修课的课程设计报告的AI部分改编 主要介绍了“员工考勤管理系统”课程设计中的员工人脸打卡子系统该系统使用了Google CoLab提供的在线Tensorflow GPU平台训练得到的DeepID人脸特征提取比对模型，以及基于该模型搭建的Tensorflow+OpenCV+Flask人脸比对Python服务器">
<meta name="keywords" content="experience">
<meta property="og:type" content="article">
<meta property="og:title" content="Training DeepID1 Network for Face Comparison with Google Colab+Tensorflow">
<meta property="og:url" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/index.html">
<meta property="og:site_name" content="NeXT">
<meta property="og:description" content="本文由2019年6月《软件工程》必修课的课程设计报告的AI部分改编 主要介绍了“员工考勤管理系统”课程设计中的员工人脸打卡子系统该系统使用了Google CoLab提供的在线Tensorflow GPU平台训练得到的DeepID人脸特征提取比对模型，以及基于该模型搭建的Tensorflow+OpenCV+Flask人脸比对Python服务器">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/deepid.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-1.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-2.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-3.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc-1.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss-1.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc-1.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss-1.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/nvidia-smi.png">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-1.jpeg">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-2.jpeg">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-3.jpeg">
<meta property="og:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-4.jpeg">
<meta property="og:updated_time" content="2019-06-29T16:56:06.266Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Training DeepID1 Network for Face Comparison with Google Colab+Tensorflow">
<meta name="twitter:description" content="本文由2019年6月《软件工程》必修课的课程设计报告的AI部分改编 主要介绍了“员工考勤管理系统”课程设计中的员工人脸打卡子系统该系统使用了Google CoLab提供的在线Tensorflow GPU平台训练得到的DeepID人脸特征提取比对模型，以及基于该模型搭建的Tensorflow+OpenCV+Flask人脸比对Python服务器">
<meta name="twitter:image" content="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/deepid.png">



  <link rel="alternate" href="/atom.xml" title="NeXT" type="application/atom+xml" />




  <link rel="canonical" href="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>Training DeepID1 Network for Face Comparison with Google Colab+Tensorflow | NeXT</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">NeXT</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lmy98129.github.io/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mengyin Liu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NeXT">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Training DeepID1 Network for Face Comparison with Google Colab+Tensorflow</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-29T20:53:43+08:00">2019-06-29</time>
            

            
            
              
                
              
            

            
              
              <span class="post-meta-divider">|</span>
              

              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-06-30T00:56:06+08:00">2019-06-30</time>
            
          </span>

          

          
            
          

          
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文由2019年6月《软件工程》必修课的课程设计报告的AI部分改编</p>
<p>主要介绍了“员工考勤管理系统”课程设计中的员工人脸打卡子系统<br>该系统使用了Google CoLab提供的在线Tensorflow GPU平台训练得到的DeepID人脸特征提取比对模型，<br>以及基于该模型搭建的Tensorflow+OpenCV+Flask人脸比对Python服务器</p>
<a id="more"></a>
<blockquote>
<p>中文标题：使用Google CoLab+Tensorflow训练DeepID1人脸比对模型</p>
</blockquote>
<h3 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h3><ol>
<li><a href="https://colab.research.google.com/drive/1BKcLNYjffhhQEWQErclZMojsjBpTViSq" target="_blank" rel="noopener">Google CoLab</a>（需要访问国外网站的能力）</li>
<li>GitHub（待发布）</li>
</ol>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/deepid.png" alt="deepid"></p>
<center>图1.1 DeepID的网络结构<br>其中DeepID层能够提取出160维特征向量<br><br></center>

<p>DeepID是香港中文大学王晓刚教授团队在CVPR2014上发表的论文《Deep Learning Face Representation from Predicting 10,000 Classes》提出的方法，全称为Deep hidden IDentity feature（DeepID）。</p>
<p>该方法是一种特征提取的算法，对于一个多层卷积-池化网络进行多分类任务训练后，在其中一层中间层DeepID层能够提取出输入的任意人脸图片的160维深层次特征向量（实际上是160x2x60维的特征向量）。</p>
<p>而这种特征提取的能力是面向任意的（需要经过预先裁剪和对齐后的）人脸图像的，因此作者做出了一个形象的比喻：即使是分10000个类，网络也能够有效区分出每个类别的人脸的显著特征（从而通过特征之间的距离，识别出两张人脸是否为同一人）。</p>
<p>因此，这一方法体现出的以下特性，使得我们最终在众多人脸特征提取方法中选取了DeepId:</p>
<ol>
<li>方法实现的<strong>仅需一次训练即可获得的人脸特征提取能力</strong>，十分适合企业员工人脸考勤环境下员工人脸库经常性变动、待对比人脸图像来源较为复杂的应用场景。</li>
<li>方法的<strong>网络结构简单，易于理解和实现。同时，网络层数较少，</strong>相应地也能够减少训练所消耗的时间和硬件资源，便于我们在短周期（8周，AI子系统开发仅一周）的软件工程课程设计开发过程中安排进度。最终，该算法的训练时长在Google CoLab上为50000次/2小时。</li>
<li>方法的<strong>准确率较高</strong>，在Tensorflow的实现+YouTube Aligned Faces数据集上的测试集人脸比对识别准确率能够达到96%。</li>
</ol>
<p>当然，这一方法作为一个2014年提出的方法，（也是DeepID三代中的第一个版本）也存在着一定的缺陷：</p>
<ol>
<li><strong>仅适用于提取图像中的正脸</strong>，也就是通过摄像头正对人脸拍摄的、或者是通过一定图像处理算法重新对齐的人脸。对于侧脸、带有一定歪斜的人脸等日常生活中常见的人脸图像，识别能力大打折扣。<strong>也正因如此，GitHub上DeepID的Tensorflow实现采用了Youtube Aligned Faces数据集，已经做过了人脸对齐的预处理</strong>，用来训练DeepID较为方便。</li>
<li>在实际使用的过程中，笔者发现这一模型对于裁剪得出的人脸图像的<strong>光线明暗、是否佩戴眼镜</strong>等变化是敏感的，只有在光照条件、脸部配饰等状况近似于人脸图像采集时的情况下，才能够被识别为同一人。</li>
</ol>
<p>因此，目前主流的人脸特征比对方法都聚焦在人脸检测阶段的多特征点提取、侧脸特征点的重新对齐、人脸3D模型识别（一个最著名的案例，就是Apple在iPhone上用于FaceID的3D结构光特征点识别方案）等研究方向。<br>至于Google Colab，是谷歌打造的的一个在线深度学习平台，基于Jupyter Notebook+Tensorflow，能够通过简单的配置，使用Google免费提供的云端GPU资源，从而无需本地硬件资源地轻松训练自己的神经网络。在很久之前的一次计设校赛上曾经使用过这一平台，因此本项目也继续使用这个平台对DeepID网络进行训练。</p>
<h3 id="训练环境搭建"><a href="#训练环境搭建" class="headerlink" title="训练环境搭建"></a>训练环境搭建</h3><p>访问 <a href="https://colab.research.google.com，如果没有谷歌账号可以先去注册一个，列表中是已有的Jupyter" target="_blank" rel="noopener">https://colab.research.google.com，如果没有谷歌账号可以先去注册一个，列表中是已有的Jupyter</a> Notebook文件，创建的文件一般会放在Google 云端硬盘的<code>/colab notebook</code>文件夹下。一般是创建Python 3笔记本，</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-1.png" alt="colab"></p>
<center>图2.1 Google Colab的初始界面</center>

<p>Colab的环境初始化结束后，呈现的是经典的jupyter notebook界面，先点击“代码执行程序-更改运行时类型”，将“硬件加速器”从“None”修改为“GPU”，这样就可以<strong>免费使用基于谷歌提供的云端Nvidia GTX Tesla T4 GPU的Tensorflow GPU版本，显存15GB</strong>，比自己笔记本的4G独显性能高多了。</p>
<p><strong>注意！千万不要选择TPU！</strong> </p>
<p>虽然TPU是Google推出的号称Tensorflow专用的GPU平台，但是其训练速度真的难以接受，在下文我会附上GPU和TPU训练DeepID网络时的Tensorboard检测到的数据，足以体现两者之间的性能差异。</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-2.png" alt="colab"></p>
<center>图2.2 在Colab选取GPU<br></center>

<p>之后可以在左侧边栏中，查看文件目录，会发现一个“挂在Google云端硬盘”的选项，点击之后就会生成一个cell。内容大致为<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行此单元格即可装载您的 Google 云端硬盘。</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">'/content/drive'</span>)</span><br></pre></td></tr></table></figure></p>
<p>运行之后，会生成一个链接拿到Google 云端硬盘生成的授权码，输入到这个cell中，即可成功挂在你的Google 云硬盘。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Go to this URL <span class="keyword">in</span> a browser: https://accounts.google.com/o/oauth2/auth?....</span><br><span class="line"></span><br><span class="line">Enter your authorization code:</span><br><span class="line">··········</span><br><span class="line">Mounted at /content/drive</span><br></pre></td></tr></table></figure></p>
<p>之所以需要挂载Google云硬盘，是基于这样的考虑：</p>
<p>Google Colab有一个“防挖矿”机制，为了防止自己免费开放的GPU资源被矿工拿来挂机挖矿，Colab会自动回收那些运行了很久或者和网页端断线很久的项目的<strong>所有资源：包括GPU和所有文件</strong>。</p>
<p>因此尽量不要尝试在训练的过程中关闭浏览器，然后等时间到了再次打开浏览器查看结果，很有可能早已训练结束，模型文件已经生成，但是由于Colab的这个机制导致文件被删除。</p>
<p>所以在训练过程中，需要挂载Google 云端硬盘，<strong>将模型文件和训练生成的Tensorboard日志的路径放在云端硬盘里</strong>，就算谷歌回收了资源也能够及时保存。</p>
<p>但是，需要注意的是，<strong>数据集最好不要放在Google 云端硬盘里</strong>，因为网上有人试过了，Colab从Google云端硬盘上获取文件时不是直接读取文件系统，而是发送请求进行文件分块下载的，这个网络IO带来的延迟会极大地拖慢训练的速度。</p>
<p>此外，这个数据集直接上传到Google Colab上的速度也是堪忧。但是，值得称赞的是，<strong>在Colab里直接用Shell命令下载在线的数据集</strong>，速度极快，能够达到15M/s。以下是下载YouTube Aligned Faces数据集的输出，30秒完成~</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/colab-3.png" alt="数据集下载"></p>
<center>图2.3 下载YouTube Aligned Faces数据集的输出</center>

<p>还有一个需要注意的地方，就是Colab上已经装好了Tensorflow 2.0Beta、OpenCV以及matplot、numpy、PIL等深度学习常用的python库，若需要其他库也是直接执行shell命令pip install即可。<strong>这里的Tensorflow2.0Beta与目前常用的1.x版本相比，在API上有着许多区别</strong>，如果直接复制他人的代码，会出现许多的问题。</p>
<p>笔者也因此几乎是把GitHub上的DeepID实现从头开始添加中文注释和改写API，学到了很多搭建Tensorflow训练框架的相关API用法（例如session、variable和namescope），也算是继续了之前《人工智能》大作业的“注释阅读法”的个人习惯。</p>
<p>以上就是一些搭建Colab环境的注意事项，如果你已经看懂了这些，而且熟悉Jupyter Notebook，就可以开始着手编写训练代码了。</p>
<h3 id="编写训练代码"><a href="#编写训练代码" class="headerlink" title="编写训练代码"></a>编写训练代码</h3><h4 id="下载YouTube-Aligned-Faces数据集"><a href="#下载YouTube-Aligned-Faces数据集" class="headerlink" title="下载YouTube Aligned Faces数据集"></a>下载YouTube Aligned Faces数据集</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载youtube aligned face数据集</span></span><br><span class="line">!wget --http-user=wolftau --http-password=wtal997 http://www.cslab.openu.ac.il/download/wolftau/aligned_images_DB.tar.gz</span><br><span class="line"><span class="comment"># 解压下载的数据集</span></span><br><span class="line">!mkdir -p data</span><br><span class="line">!tar -zxf aligned_images_DB.tar.gz -C Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/data</span><br></pre></td></tr></table></figure>
<h4 id="裁剪数据集图片"><a href="#裁剪数据集图片" class="headerlink" title="裁剪数据集图片"></a>裁剪数据集图片</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  此处开始为DeepID人脸特征提取、比对代码</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  来源为：https://github.com/jinze1994/DeepID1</span></span><br><span class="line"><span class="string">  主要工作：增加了详细中文注释、更新了部分tensorflow2.0的新API</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  crop.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  裁剪训练数据集图片，图片已经经过了对齐预处理</span></span><br><span class="line"><span class="string">  所谓对齐就是裁剪到只剩下人脸，且已经事先将带有倾斜的人脸对齐过了</span></span><br><span class="line"><span class="string">  因此此处只需裁剪并缩放到 (55,47) 的像素即可</span></span><br><span class="line"><span class="string">  这样的处理适合被检测对象配合、也就是主动进行识别的场景</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  crop_img_by_half_center</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  从1/4处开始裁剪1/2尺寸的图像并缩放</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crop_img_by_half_center</span><span class="params">(src_file_path, dest_file_path)</span>:</span></span><br><span class="line">    <span class="comment"># 打开图像</span></span><br><span class="line">    im = Image.open(src_file_path)</span><br><span class="line">    <span class="comment"># 获取图像尺寸</span></span><br><span class="line">    x_size, y_size = im.size</span><br><span class="line">    <span class="comment"># 开始裁剪的坐标</span></span><br><span class="line">    start_point_xy = x_size / <span class="number">4</span></span><br><span class="line">    <span class="comment"># 裁剪结束时的坐标</span></span><br><span class="line">    end_point_xy   = x_size / <span class="number">4</span> + x_size / <span class="number">2</span></span><br><span class="line">    <span class="comment"># 生成方形框</span></span><br><span class="line">    box = (start_point_xy, start_point_xy, end_point_xy, end_point_xy)</span><br><span class="line">    <span class="comment"># 裁剪</span></span><br><span class="line">    new_im = im.crop(box)</span><br><span class="line">    <span class="comment"># 缩放为（55，47）</span></span><br><span class="line">    new_new_im = new_im.resize((<span class="number">47</span>,<span class="number">55</span>))</span><br><span class="line">    <span class="comment"># 保存</span></span><br><span class="line">    new_new_im.save(dest_file_path)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  walk_through_the_folder_for_crop</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  遍历数据集文件夹，进行图像的处理，生成目标文件夹</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">walk_through_the_folder_for_crop</span><span class="params">(aligned_db_folder, result_folder)</span>:</span></span><br><span class="line">    <span class="comment"># 若不存在目标文件夹，新建一个</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(result_folder):</span><br><span class="line">        os.mkdir(result_folder)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开每一个youtube人物文件夹</span></span><br><span class="line">    <span class="keyword">for</span> people_folder <span class="keyword">in</span> os.listdir(aligned_db_folder):</span><br><span class="line">        src_people_path = aligned_db_folder + people_folder + <span class="string">'/'</span></span><br><span class="line">        dest_people_path = result_folder + people_folder + <span class="string">'/'</span></span><br><span class="line">        <span class="comment"># 创建每一个人物文件夹对应的目标文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest_people_path):</span><br><span class="line">            os.mkdir(dest_people_path)</span><br><span class="line">        <span class="comment"># 打开每一个人物文件夹下的视频文件夹</span></span><br><span class="line">        <span class="keyword">for</span> video_folder <span class="keyword">in</span> os.listdir(src_people_path):</span><br><span class="line">            src_video_path = src_people_path + video_folder + <span class="string">'/'</span></span><br><span class="line">            dest_video_path = dest_people_path + video_folder + <span class="string">'/'</span></span><br><span class="line">            <span class="comment"># 创建每一个视频文件夹对应的目标文件夹 </span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest_video_path):</span><br><span class="line">                os.mkdir(dest_video_path)</span><br><span class="line">            <span class="comment"># 对于每一个视频文件夹下的图片文件，进行处理</span></span><br><span class="line">            <span class="keyword">for</span> img_file <span class="keyword">in</span> os.listdir(src_video_path):</span><br><span class="line">                src_img_path = src_video_path + img_file</span><br><span class="line">                dest_img_path = dest_video_path + img_file</span><br><span class="line">                crop_img_by_half_center(src_img_path, dest_img_path)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  裁剪模块的主程序</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 数据集路径和目标文件夹路径</span></span><br><span class="line">    aligned_db_folder = <span class="string">"data/aligned_images_DB"</span></span><br><span class="line">    result_folder = <span class="string">"data/crop_images_DB"</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> aligned_db_folder.endswith(<span class="string">'/'</span>):</span><br><span class="line">        aligned_db_folder += <span class="string">'/'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result_folder.endswith(<span class="string">'/'</span>):</span><br><span class="line">        result_folder += <span class="string">'/'</span></span><br><span class="line">    <span class="comment"># 开始处理</span></span><br><span class="line">    walk_through_the_folder_for_crop(aligned_db_folder, result_folder)</span><br></pre></td></tr></table></figure>
<h4 id="分割数据集为训练集、验证集和测试集"><a href="#分割数据集为训练集、验证集和测试集" class="headerlink" title="分割数据集为训练集、验证集和测试集"></a>分割数据集为训练集、验证集和测试集</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  split.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">   对剪裁后的数据集文件按照 8:1:1 的规模进行切分，分别作为训练集、验证集和测试集。</span></span><br><span class="line"><span class="string">   每个人保留固定数目的图片（100张）进行训练。</span></span><br><span class="line"><span class="string">   为生成测试集，对每个人构造 5 对同一个人的图片 pair，再构造 5 对不同人的图片 pair，作为测试集。</span></span><br><span class="line"><span class="string">   一个pair作为每次测试时输入的组合，用来测试同一个人是否能正确匹配、不同人是否能够分出不同的人脸比对效果</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  fatch_pics_for_one_user</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  获取一个youtube用户的所有图片</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fatch_pics_for_one_user</span><span class="params">(people_path)</span>:</span></span><br><span class="line">    people_imgs = []</span><br><span class="line">    <span class="comment"># 从文件夹中遍历</span></span><br><span class="line">    <span class="keyword">for</span> video_folder <span class="keyword">in</span> os.listdir(people_path):</span><br><span class="line">        <span class="keyword">for</span> video_file_name <span class="keyword">in</span> os.listdir(os.path.join(people_path, video_folder)):</span><br><span class="line">            people_imgs.append(os.path.join(people_path, video_folder, video_file_name))</span><br><span class="line">    random.shuffle(people_imgs)</span><br><span class="line">    <span class="keyword">return</span> people_imgs</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  build_dataset</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  创建训练集、验证集和测试集</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">(src_folder)</span>:</span></span><br><span class="line">    <span class="comment"># 总人数，总图片张数</span></span><br><span class="line">    total_people, total_picture = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment"># 测试用户列表、验证集、训练集</span></span><br><span class="line">    test_people, valid_set, train_set = [], [], []</span><br><span class="line">    <span class="comment"># 标签数量</span></span><br><span class="line">    label = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用户文件夹遍历</span></span><br><span class="line">    <span class="keyword">for</span> people_folder <span class="keyword">in</span> os.listdir(src_folder):</span><br><span class="line">        <span class="comment"># 获取一个youtube用户的所有图片</span></span><br><span class="line">        people_imgs = fatch_pics_for_one_user(os.path.join(src_folder, people_folder))</span><br><span class="line">        total_people += <span class="number">1</span></span><br><span class="line">        total_picture += len(people_imgs)</span><br><span class="line">        <span class="comment"># 若数量在100张以内，则全部放入测试用户列表</span></span><br><span class="line">        <span class="comment"># 保证测试集中的用户不会出现在训练集和验证集中</span></span><br><span class="line">        <span class="keyword">if</span> len(people_imgs) &lt; <span class="number">100</span>:</span><br><span class="line">            test_people.append(people_imgs)</span><br><span class="line">        <span class="comment"># 否则分割到验证集和训练集中，1:9</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_set += zip(people_imgs[:<span class="number">10</span>], [label]*<span class="number">10</span>)</span><br><span class="line">            train_set += zip(people_imgs[<span class="number">10</span>:<span class="number">100</span>], [label]*<span class="number">90</span>)</span><br><span class="line">            label += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 测试集</span></span><br><span class="line">    test_set = []</span><br><span class="line">    <span class="comment"># 从测试用户列表中，构造5对同一个人的照片、5对不同人的照片</span></span><br><span class="line">    <span class="keyword">for</span> i, people_imgs <span class="keyword">in</span> enumerate(test_people):</span><br><span class="line">        <span class="comment"># 5对同一个人的照片</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            same_pair = random.sample(people_imgs, <span class="number">2</span>)</span><br><span class="line">            test_set.append((same_pair[<span class="number">0</span>], same_pair[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 5对不同人的照片</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            j = i;</span><br><span class="line">            <span class="keyword">while</span> j == i:</span><br><span class="line">                j = random.randint(<span class="number">0</span>, len(test_people)<span class="number">-1</span>)</span><br><span class="line">            test_set.append((random.choice(test_people[i]), random.choice(test_people[j]), <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打乱各个数据集的顺序</span></span><br><span class="line">    random.shuffle(test_set)</span><br><span class="line">    random.shuffle(valid_set)</span><br><span class="line">    random.shuffle(train_set)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出各数据集的统计信息</span></span><br><span class="line">    print(<span class="string">'\tpeople\tpicture'</span>)</span><br><span class="line">    print(<span class="string">'total:\t%6d\t%7d'</span> % (total_people, total_picture))</span><br><span class="line">    print(<span class="string">'test:\t%6d\t%7d'</span> % (len(test_people), len(test_set)))</span><br><span class="line">    print(<span class="string">'valid:\t%6d\t%7d'</span> % (label, len(valid_set)))</span><br><span class="line">    print(<span class="string">'train:\t%6d\t%7d'</span> % (label, len(train_set)))</span><br><span class="line">    <span class="keyword">return</span> test_set, valid_set, train_set</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  set_to_csv_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  保存到csv文件中</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_to_csv_file</span><span class="params">(data_set, file_name)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(file_name, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data_set:</span><br><span class="line">            print(<span class="string">" "</span>.join(map(str, item)), file=f)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  数据集切分模块的主程序</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    random.seed(<span class="number">7</span>)</span><br><span class="line">    <span class="comment"># 原始数据集路径以及各数据集保存列表文件</span></span><br><span class="line">    src_folder     = <span class="string">"data/crop_images_DB"</span></span><br><span class="line">    test_set_file  = <span class="string">"data/test_set.csv"</span></span><br><span class="line">    valid_set_file = <span class="string">"data/valid_set.csv"</span></span><br><span class="line">    train_set_file = <span class="string">"data/train_set.csv"</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> src_folder.endswith(<span class="string">'/'</span>):</span><br><span class="line">        src_folder += <span class="string">'/'</span></span><br><span class="line">    </span><br><span class="line">    test_set, valid_set, train_set = build_dataset(src_folder)</span><br><span class="line">    set_to_csv_file(test_set,  test_set_file)</span><br><span class="line">    set_to_csv_file(valid_set, valid_set_file)</span><br><span class="line">    set_to_csv_file(train_set, train_set_file)</span><br></pre></td></tr></table></figure>
<h4 id="向量化数据集，便于读取"><a href="#向量化数据集，便于读取" class="headerlink" title="向量化数据集，便于读取"></a>向量化数据集，便于读取</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  vec.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  将数据格式化为向量形式，存入 data/dataset.pkl。便于训练时直接从该文件读取数据。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  vectorize_imgs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">  将图像向量化，事实上就是将图像转化为浮点数格式的数组</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_imgs</span><span class="params">(img_path)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> Image.open(img_path) <span class="keyword">as</span> img:</span><br><span class="line">        arr_img = np.asarray(img, dtype=<span class="string">'float32'</span>)</span><br><span class="line">        <span class="keyword">return</span> arr_img</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  read_csv_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  读取csv文件</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv_file</span><span class="params">(csv_file)</span>:</span></span><br><span class="line">    x, y = [], []</span><br><span class="line">    <span class="keyword">with</span> open(csv_file, <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            path, label = line.strip().split()</span><br><span class="line">            x.append(vectorize_imgs(path))</span><br><span class="line">            y.append(int(label))</span><br><span class="line">    <span class="keyword">return</span> np.asarray(x, dtype=<span class="string">'float32'</span>), np.asarray(y, dtype=<span class="string">'int32'</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  read_csv_pair_file</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  读取成对数据（也就是一个label对应两张图）的csv文件</span></span><br><span class="line"><span class="string">  事实上就是读取测试集数据</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv_pair_file</span><span class="params">(csv_file)</span>:</span></span><br><span class="line">    x1, x2, y = [], [], []</span><br><span class="line">    <span class="keyword">with</span> open(csv_file, <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            p1, p2, label = line.strip().split()</span><br><span class="line">            x1.append(vectorize_imgs(p1))</span><br><span class="line">            x2.append(vectorize_imgs(p2))</span><br><span class="line">            y.append(int(label))</span><br><span class="line">    <span class="keyword">return</span> np.asarray(x1, dtype=<span class="string">'float32'</span>), np.asarray(x2, dtype=<span class="string">'float32'</span>), np.asarray(y, dtype=<span class="string">'int32'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  向量化主程序，将csv文件转换为pkl文件</span></span><br><span class="line"><span class="string">'''</span>      </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    testX1, testX2, testY = read_csv_pair_file(<span class="string">'data/test_set.csv'</span>)</span><br><span class="line">    validX, validY = read_csv_file(<span class="string">'data/valid_set.csv'</span>)</span><br><span class="line">    trainX, trainY = read_csv_file(<span class="string">'data/train_set.csv'</span>)</span><br><span class="line"></span><br><span class="line">    print(testX1.shape, testX2.shape, testY.shape)</span><br><span class="line">    print(validX.shape, validY.shape)</span><br><span class="line">    print(trainX.shape, trainY.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 导入向量化的数据到pkl文件中</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'data/dataset.pkl'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(testX1, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(testX2, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(testY , f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(validX, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(validY, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(trainX, f, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">        pickle.dump(trainY, f, pickle.HIGHEST_PROTOCOL)</span><br></pre></td></tr></table></figure>
<h4 id="运行tensorboard监视训练过程"><a href="#运行tensorboard监视训练过程" class="headerlink" title="运行tensorboard监视训练过程"></a>运行tensorboard监视训练过程</h4><p>在经过了以上漫长的数据集裁剪、分割和向量化过程（第1、2步各需要20分钟）之后，就开始了训练。这里可以选用Colab内置的Tensorboard进行训练过程的监视。首先需要升级，否则无法读取训练过程中生成的日志文件。</p>
<p>在实际使用过程中，<strong>若训练生成的日志放在了Colab的文件目录中</strong>，Tensorboard在训练开始后过一段时间会与训练程序断开连接，<br>因此同样需要将训练程序代码中的日志文件路径设为Google 云端硬盘的路径。这样就算掉线了也能够在本地运行一个Tensorboard，手动下载Google 云端硬盘上不断更新的日志文件进行监视（或者有下载Google云端硬盘的客户端，可以使用文件夹同步功能实时更新本地的日志文件）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  训练之前，运行tensorboard监视训练过程</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  尝试了无数次，读不到日志文件，无论是绝对路径还是相对路径</span></span><br><span class="line"><span class="string">  在mac上本地查看日志文件，是能用的，</span></span><br><span class="line"><span class="string">  后来发现升级一下tensorboard就好了，</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级，升级后首次使用会报错，清除一下报错里面提示的info文件即可</span></span><br><span class="line"><span class="comment"># !pip install --upgrade tensorboard</span></span><br><span class="line"><span class="comment"># !rm /tmp/.tensorboard-info/pid-*.info</span></span><br><span class="line"></span><br><span class="line">%reload_ext tensorboard</span><br><span class="line">%tensorboard --logdir <span class="string">"/content/drive/My Drive/Colab Notebooks/deepid/log"</span></span><br></pre></td></tr></table></figure>
<h4 id="训练DeepID网络"><a href="#训练DeepID网络" class="headerlink" title="训练DeepID网络"></a>训练DeepID网络</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  deepid1.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  DeepID网络训练主程序</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  load_data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  从pkl向量文件中导出数据</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'data/dataset.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        testX1 = pickle.load(f)</span><br><span class="line">        testX2 = pickle.load(f)</span><br><span class="line">        testY  = pickle.load(f)</span><br><span class="line">        validX = pickle.load(f)</span><br><span class="line">        validY = pickle.load(f)</span><br><span class="line">        trainX = pickle.load(f)</span><br><span class="line">        trainY = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> testX1, testX2, testY, validX, validY, trainX, trainY</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入向量数据</span></span><br><span class="line">testX1, testX2, testY, validX, validY, trainX, trainY = load_data()</span><br><span class="line"><span class="comment"># 类型数量=训练集数量，也就是认为每一个训练集数据均为一类</span></span><br><span class="line"><span class="comment"># 因为本网络只负责特征提取而非分类，所以可以这么做</span></span><br><span class="line">class_num = np.max(trainY) + <span class="number">1</span></span><br><span class="line"><span class="comment"># 清除一下当前的作用域</span></span><br><span class="line">tf.reset_default_graph();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  weight_variable</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  初始化权重，shape事实上是卷积核尺寸</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'weights'</span>):</span><br><span class="line">        <span class="comment"># 从截断的正态分布中输出随机值，以初始化权重。</span></span><br><span class="line">        <span class="keyword">return</span> tf.Variable(tf.truncated_normal(shape, stddev=<span class="number">0.1</span>))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  bias_variable</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  初始化偏置，也就是wx+b中的b，bias</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'biases'</span>):</span><br><span class="line">        <span class="comment"># 使用全零向量初始化偏置</span></span><br><span class="line">        <span class="keyword">return</span> tf.Variable(tf.zeros(shape))</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  Wx_plus_b</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  求wx+b</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Wx_plus_b</span><span class="params">(weights, x, biases)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'Wx_plus_b'</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.matmul(x, weights) + biases</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  nn_layer</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  n*n的全连接层，可选激活函数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_layer</span><span class="params">(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu)</span>:</span></span><br><span class="line">    <span class="comment"># 进入对应层的命名空间</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">        <span class="comment"># 权重</span></span><br><span class="line">        weights = weight_variable([input_dim, output_dim])</span><br><span class="line">        <span class="comment"># 偏置</span></span><br><span class="line">        biases = bias_variable([output_dim])</span><br><span class="line">        <span class="comment"># 预激活</span></span><br><span class="line">        <span class="comment"># 可以这么翻译，个人认为是激活前的预处理</span></span><br><span class="line">        preactivate = Wx_plus_b(weights, input_tensor, biases)</span><br><span class="line">        <span class="comment"># 若传入了激活函数，则让它激活</span></span><br><span class="line">        <span class="keyword">if</span> act != <span class="keyword">None</span>:</span><br><span class="line">            activations = act(preactivate, name=<span class="string">'activation'</span>)</span><br><span class="line">            <span class="keyword">return</span> activations</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则就输出预激活量</span></span><br><span class="line">            <span class="keyword">return</span> preactivate</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  conv_pool_layer</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  卷积+池化层，在deepid中一共有3层</span></span><br><span class="line"><span class="string">  也可以定制only_conv=True来满足deepid第四层只有卷积</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  卷积：局部感知，基于相邻部分的相关性原理；权值共享、因此可以设计多核卷积</span></span><br><span class="line"><span class="string">  池化：这里使用最大池化，则说明是提取显著特征</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_pool_layer</span><span class="params">(x, w_shape, b_shape, layer_name, act=tf.nn.relu, only_conv=False)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">        W = weight_variable(w_shape)</span><br><span class="line">        b = bias_variable(b_shape)</span><br><span class="line">        <span class="comment"># 输入到卷积层</span></span><br><span class="line">        conv = tf.nn.conv2d(</span><br><span class="line">            <span class="comment"># 输入x和卷积核W的大小、权重</span></span><br><span class="line">            x, W, </span><br><span class="line">            <span class="comment"># 卷积步长，tf中前后两个1不能改，中间两个为水平滑动和垂直滑动步长</span></span><br><span class="line">            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], </span><br><span class="line">            <span class="comment"># VALID方式丢弃小于窗口大小的</span></span><br><span class="line">            <span class="comment"># SAME方式相反会填充到窗口大小</span></span><br><span class="line">            padding=<span class="string">'VALID'</span>, </span><br><span class="line">            name=<span class="string">'conv2d'</span></span><br><span class="line">        )</span><br><span class="line">        h = conv + b</span><br><span class="line">        <span class="comment"># 加入偏置，激活</span></span><br><span class="line">        relu = act(h, name=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="keyword">if</span> only_conv == <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">return</span> relu</span><br><span class="line">        <span class="comment"># 若存在池化层则再进行池化</span></span><br><span class="line">        <span class="comment"># ksize参数确定了池化窗口大小</span></span><br><span class="line">        <span class="comment"># 值得注意的是这里的最大池化没有使用激活函数，也就是仅仅提取线性的显著特征</span></span><br><span class="line">        pool = tf.nn.max_pool(relu, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>, name=<span class="string">'max-pooling'</span>)</span><br><span class="line">        <span class="keyword">return</span> pool</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  accuracy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  在验证集上测试阶段的准确度计算，由模型预测值和实际值计算得出</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(y_estimate, y_real)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'correct_prediction'</span>):</span><br><span class="line">            <span class="comment"># 在测试阶段的准确度计算</span></span><br><span class="line">            correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>): </span><br><span class="line">            <span class="comment"># 对每个批次计算总的准确度均值</span></span><br><span class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        <span class="comment"># 记录准确度信息</span></span><br><span class="line">        tf.summary.scalar(<span class="string">'accuracy'</span>, accuracy)  </span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  train_step</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  训练梯度，也就是需要计算梯度下降了</span></span><br><span class="line"><span class="string">  这里采用了ADAM优化器，其他优化器的特征：</span></span><br><span class="line"><span class="string">  Momentum冲量算法增加冲量、</span></span><br><span class="line"><span class="string">  Adagrad对低频变化的参数以更大步长更新、</span></span><br><span class="line"><span class="string">  RMSProp更新时只更新梯度平方的期望（移动的均值）</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  ADAM优化器对梯度的一阶矩估计（均值）和二阶矩估计（方差）两个方面适应性调节</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(loss)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">        <span class="comment"># 初始学习率1e-4，之后同样会动态调整，一般是逐步衰减，减少趋近最优时的震荡</span></span><br><span class="line">        <span class="comment"># minimize才是更新梯度，之前是计算梯度</span></span><br><span class="line">        <span class="keyword">return</span> tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入，tf.placeholder为形参，在执行时再赋具体的值</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    h0 = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">55</span>, <span class="number">47</span>, <span class="number">3</span>], name=<span class="string">'x'</span>)</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, class_num], name=<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第1个卷积-池化层，4x4，当前通道数3，卷积核数量（下一层通道数）20，偏置大小20</span></span><br><span class="line">h1 = conv_pool_layer(h0, [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">20</span>], [<span class="number">20</span>], <span class="string">'Conv_layer_1'</span>)</span><br><span class="line"><span class="comment"># 第2个卷积-池化层，3x3，当前通道数20，卷积核数量40，偏置大小40</span></span><br><span class="line">h2 = conv_pool_layer(h1, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">40</span>], [<span class="number">40</span>], <span class="string">'Conv_layer_2'</span>)</span><br><span class="line"><span class="comment"># 第3个卷积-池化层，3x3，当前通道数40，卷积核数量60，偏置大小60</span></span><br><span class="line">h3 = conv_pool_layer(h2, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">40</span>, <span class="number">60</span>], [<span class="number">60</span>], <span class="string">'Conv_layer_3'</span>)</span><br><span class="line"><span class="comment"># 第4个卷积层，2x2，当前通道数60，卷积核数量80，偏置大小80</span></span><br><span class="line">h4 = conv_pool_layer(h3, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">60</span>, <span class="number">80</span>], [<span class="number">80</span>], <span class="string">'Conv_layer_4'</span>, only_conv=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后一个deepid层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'DeepID1'</span>):</span><br><span class="line">    <span class="comment"># deepid层直接与第3层相连，</span></span><br><span class="line">    <span class="comment"># 使用reshape能够拉平这两层的输出为1维数组</span></span><br><span class="line">    <span class="comment"># -1即为任意维，后跟的是每一维度实际尺寸大小，</span></span><br><span class="line">    <span class="comment"># 该大小即为整个层所有神经元个数（比实际还偏大一点），因此是拉平了的</span></span><br><span class="line">    h3r = tf.reshape(h3, [<span class="number">-1</span>, <span class="number">5</span>*<span class="number">4</span>*<span class="number">60</span>])</span><br><span class="line">    <span class="comment"># deepid层与第4层相连</span></span><br><span class="line">    h4r = tf.reshape(h4, [<span class="number">-1</span>, <span class="number">4</span>*<span class="number">3</span>*<span class="number">80</span>])</span><br><span class="line">    <span class="comment"># 初始化两次相连的权重</span></span><br><span class="line">    W1 = weight_variable([<span class="number">5</span>*<span class="number">4</span>*<span class="number">60</span>, <span class="number">160</span>])</span><br><span class="line">    W2 = weight_variable([<span class="number">4</span>*<span class="number">3</span>*<span class="number">80</span>, <span class="number">160</span>])</span><br><span class="line">    b = bias_variable([<span class="number">160</span>])</span><br><span class="line">    <span class="comment"># 直接带权重一起相加</span></span><br><span class="line">    h = tf.matmul(h3r, W1) + tf.matmul(h4r, W2) + b</span><br><span class="line">    <span class="comment"># relu激活</span></span><br><span class="line">    h5 = tf.nn.relu(h)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失函数</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    <span class="comment"># n*n的全连接层，将拉平的第3、4层全连接到一个160个神经元的全连接层上</span></span><br><span class="line">    y = nn_layer(h5, <span class="number">160</span>, class_num, <span class="string">'nn_layer'</span>, act=<span class="keyword">None</span>)</span><br><span class="line">    <span class="comment"># softmax层</span></span><br><span class="line">    <span class="comment"># 1. 将logits（也就是输入y），计算为（0，1）范围的概率值</span></span><br><span class="line">    <span class="comment"># 2. 计算损失loss，这里计算的是交叉熵损失，y_认为是对应的标签</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">      增加Soft-max layer的输出数量（即分类数，或识别的个体数）可以提升人脸验证的准确率。</span></span><br><span class="line"><span class="string">      即分类的类别数越多，DeepConv-Net学到的DeepID特征（160维）越有效。</span></span><br><span class="line"><span class="string">      此外，作者强调用于人脸验证的一定是160维长度的DeepID特征，而不是Softmax Layer的输出。</span></span><br><span class="line"><span class="string">      如果用SoftmaxLayer输出的结果（例如用4348个不同人的数据训练DeepID,Softmax输出是4348维）</span></span><br><span class="line"><span class="string">      进行人脸验证特征，采用联合贝叶斯人脸验证方法得到的准确率约为66%，而神经网络人脸验证方法则完全失效</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">      摘录自：https://www.cnblogs.com/venus024/p/5632243.html</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">      笔者（本人）注：可以说这个神经网络只是利用了多分类训练（可以在代码中看出同一个人的类别标签还是相同的）的形式，</span></span><br><span class="line"><span class="string">      训练神经网络在提取特征时的权重参数，从而达到提取特征、加以比对的目的</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = y, labels = y_))</span><br><span class="line">    <span class="comment"># 记录当前损失</span></span><br><span class="line">    tf.summary.scalar(<span class="string">'loss'</span>, loss)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化精确度</span></span><br><span class="line">accuracy = accuracy(y, y_)</span><br><span class="line"><span class="comment"># 初始化优化器</span></span><br><span class="line">optimizer = train_step(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并所有的记录，给session用来回调运行</span></span><br><span class="line">merged = tf.summary.merge_all()  </span><br><span class="line"><span class="comment"># 保存模型的回调</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  训练主函数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取一个batch的输入</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(data_x, data_y, start)</span>:</span></span><br><span class="line">        end = (start + <span class="number">1024</span>) % data_x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> start &lt; end:</span><br><span class="line">            <span class="keyword">return</span> data_x[start:end], data_y[start:end], end</span><br><span class="line">        <span class="keyword">return</span> np.vstack([data_x[start:], data_x[:end]]), np.vstack([data_y[start:], data_y[:end]]), end</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># 注意，trainX和trainY为具体数据和标签</span></span><br><span class="line">        data_x = trainX</span><br><span class="line">        data_y = (np.arange(class_num) == trainY[:,<span class="keyword">None</span>]).astype(np.float32)</span><br><span class="line">        validY = (np.arange(class_num) == validY[:,<span class="keyword">None</span>]).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 日志文件目录</span></span><br><span class="line">        logdir = <span class="string">'/content/drive/My Drive/Colab Notebooks/deepid/log'</span></span><br><span class="line">        <span class="keyword">if</span> tf.gfile.Exists(logdir):</span><br><span class="line">            tf.gfile.DeleteRecursively(logdir)</span><br><span class="line">        tf.gfile.MakeDirs(logdir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建训练线程</span></span><br><span class="line">        sess = tf.Session()</span><br><span class="line">        <span class="comment"># 初始化所有参数，开始训练</span></span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="comment"># 写入训练日志和测试日志</span></span><br><span class="line">        train_writer = tf.summary.FileWriter(logdir + <span class="string">'/train'</span>, sess.graph)</span><br><span class="line">        test_writer = tf.summary.FileWriter(logdir + <span class="string">'/test'</span>, sess.graph)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始训练，训练次数50000次</span></span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">50001</span>):</span><br><span class="line">            <span class="comment"># 获取一个batch的输入</span></span><br><span class="line">            batch_x, batch_y, idx = get_batch(data_x, data_y, idx)</span><br><span class="line">            <span class="comment"># 优化器</span></span><br><span class="line">            _ = sess.run(optimizer, &#123;h0: batch_x, y_: batch_y&#125;)</span><br><span class="line">            <span class="comment"># 运行，h0赋值为batchX，也就是图像，y_赋值为batch_y，也就是标签</span></span><br><span class="line">            summary = sess.run(merged, &#123;h0: batch_x, y_: batch_y&#125;)</span><br><span class="line"></span><br><span class="line">            train_writer.add_summary(summary, i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 每100次进行验证集测试</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                summary = sess.run(merged, &#123;h0: validX, y_: validY&#125;)</span><br><span class="line">                test_writer.add_summary(summary, i)</span><br><span class="line">            <span class="comment"># 每5000次保存一次模型</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">5000</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                saver.save(sess, <span class="string">'/content/drive/My Drive/Colab Notebooks/deepid/checkpoint/%05d.ckpt'</span> % i)</span><br></pre></td></tr></table></figure>
<p>这里展示一下tensorboard采集的使用TPU（由于速度过慢，未训练完）和Tesla T4 GPU（2小时训练结束）的进行50000次训练的准确率和损失率图表：</p>
<p>对于TPU：</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc.png" alt="TPU-acc"></p>
<center>图2.4 TPU训练时的准确度统计图</center>

<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-acc-1.png" alt="TPU-acc-1"></p>
<center>图2.5 TPU训练时的准确度与耗时（放大后）</center>

<p>可以看出TPU训练时的准确度上升缓慢，而且过了3个小时后，准确度仍然在0.6，而且才训练了不到4k次。</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss.png" alt="TPU-loss"></p>
<center>图2.6 TPU训练时的损失率统计图</center>

<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/TPU-loss-1.png" alt="TPU-loss-1"></p>
<center>图2.7 TPU训练时的损失率与耗时（放大后）</center>

<p>同样地，TPU训练时损失率下降也十分缓慢。</p>
<p>对于GPU：</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc.png" alt="GPU-acc"></p>
<center>图2.8 GPU训练时的准确度统计图</center>

<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-acc-1.png" alt="GPU-acc-1"></p>
<center>图2.9 GPU训练时的准确度与耗时（放大后）</center>

<p>可以看出TPU训练时的准确度上升呈对数曲线，在训练次数到15k~30k时就已经趋于稳定，在1小时27分时就已经结束了训练。</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss.png" alt="GPU-loss"></p>
<center>图2.10 GPU训练时的损失率统计图</center>

<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/GPU-loss-1.png" alt="GPU-loss"></p>
<center>图2.10 GPU训练时的损失率与耗时（放大后）</center>

<p>同样地，GPU训练时损失率下降也十分迅速。</p>
<p>综上，可以看出Google Colab提供的免费GPU性能十分地强劲，能够满足快速训练简单的深度学习模型的需求。这款GPU通过nvidia-smi命令查询的情况如下所示，据查，该款显卡的价格约两万元人民币，可以看出谷歌为了推广深度学习付出了巨大的成本。</p>
<p><img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/nvidia-smi.png" alt="nvidia-smi"></p>
<center>图2.11 nvidia-smi命令得到的GPU信息：Tesla T4</center>

<h4 id="在测试集上使用模型文件预测，获取余弦距离阈值"><a href="#在测试集上使用模型文件预测，获取余弦距离阈值" class="headerlink" title="在测试集上使用模型文件预测，获取余弦距离阈值"></a>在测试集上使用模型文件预测，获取余弦距离阈值</h4><p>这里运行测试集除了检验模型的预测效果，更重要的是获取余弦距离的阈值，也就是<code>(true_mean + false_mean)/2</code>，意思是：小于同类组+不同类组的平均组内距离的两者平均（有点拗口，但是确实是以此为阈值）。根据这个阈值，就能判断任意两个人脸之间的距离代表的是同一个人还是不同的人。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  predict.py</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  预测模块，训练结束后即可使用模型文件预测</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine, euclidean</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  predict</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  预测</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(ckpt)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver.restore(sess, ckpt)</span><br><span class="line">        <span class="comment"># 计算测试集的两对数据特征值列表</span></span><br><span class="line">        h1 = sess.run(h5, &#123;h0: testX1&#125;)</span><br><span class="line">        h2 = sess.run(h5, &#123;h0: testX2&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算两个特征值列表对应两项的余弦距离</span></span><br><span class="line">    <span class="comment"># 事实上是1-余弦距离，距离越近，数值越小，符合直觉</span></span><br><span class="line">    <span class="comment"># 因此范围也从-1~1变为了0~2</span></span><br><span class="line">    pre_y = np.array([cosine(x, y) <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(h1, h2)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 求余弦距离阈值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">part_mean</span><span class="params">(x, mask)</span>:</span></span><br><span class="line">        <span class="comment"># mask事实上是测试集的标签，若是testY，1就代表对应的两张图为同类，0为不同类，1-testY反之</span></span><br><span class="line">        <span class="comment"># 以testY为例，在这一乘法下，留下的非零项目即为同类项</span></span><br><span class="line">        z = x * mask</span><br><span class="line">        <span class="comment"># 同类组余弦距离总和/同类组数量</span></span><br><span class="line">        <span class="comment"># 对所有非零项目求和=同类组距离总和</span></span><br><span class="line">        <span class="comment"># 非零项目个数=同类组数量</span></span><br><span class="line">        <span class="comment"># 两者相除则为同类组的平均组内距离</span></span><br><span class="line">        <span class="comment"># 1-testY时则为不同类组的平均组内距离</span></span><br><span class="line">        <span class="keyword">return</span> float(np.sum(z) / np.count_nonzero(z))</span><br><span class="line">    </span><br><span class="line">    true_mean = part_mean(pre_y, testY)</span><br><span class="line">    false_mean = part_mean(pre_y, <span class="number">1</span>-testY)</span><br><span class="line">    print(true_mean, false_mean)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 筛选出pre_y也就是余弦距离结果中，符合小于同类组+不同类组的平均组内距离的两者平均这一条件的项目，与testY中的对应项目进行比对</span></span><br><span class="line">    <span class="comment"># 由于testY中对应项目为1也就是True的元素代表两张图为同类，因此当pre_y中元素小于这一条件时，也代表为同类</span></span><br><span class="line">    <span class="comment"># 反之，pre_y中的元素大于这一条件时，代表非同类</span></span><br><span class="line">    <span class="comment"># 所以最终得到的矩阵是一个同类、非同类的预测值与测试集标签之间的对应关系，只有正确的才能留下来</span></span><br><span class="line">    <span class="comment"># 对此计算均值，即可获取模型在测试集上的准确率</span></span><br><span class="line">    print(np.mean((pre_y &lt; (true_mean + false_mean)/<span class="number">2</span>) == testY.astype(bool)))</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    预测主函数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 输入模型路径</span></span><br><span class="line">    predict(<span class="string">'/content/drive/My Drive/Colab Notebooks/deepid/checkpoint/30000.ckpt'</span>);</span><br></pre></td></tr></table></figure>
<h3 id="预测服务搭建"><a href="#预测服务搭建" class="headerlink" title="预测服务搭建"></a>预测服务搭建</h3><p>对于已经训练好的Tensorflow模型的预测服务搭建，在网络上有许多的方法，事实上最好的方法是使用frozen_graph工具对checkpoint进行固化处理，笔者这里是直接调用了checkpoint来恢复现场，事实上效果类似。<br>笔者在这里使用的是docker进行预测服务搭建，具体使用的镜像是<code>yoanlin/opencv-python3-tensorflow</code>，自带python3、opencv和tensorflow1.x。由于tensorflow仅仅是使用2.0beta生成的模型，所以不存在兼容性问题。<br>具体命令如下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">docker pull yoanlin/opencv-python3-tensorflow</span><br><span class="line"><span class="comment"># 生成容器，配置端口映射和文件夹映射</span></span><br><span class="line"><span class="comment"># 8888端口是tensorboard，8080是flask</span></span><br><span class="line"><span class="comment"># faces文件夹映射为人脸图像路径，我是使用软工项目中的Spring boot来接收图像的，所以flask就没写接收代码，直接从文件路径里面取，server文件夹映射为flask的程序文件</span></span><br><span class="line">docker run -itd --name=tf-cv -p 7777:8888 -p 8081:8080 -v /tf-cv/faces:/faces -v /tf-cv/server/:/server yoanlin/opencv-python3-tensorflow</span><br><span class="line"><span class="comment"># 若需要进入镜像内部安装flask等其他python库</span></span><br><span class="line">docker <span class="built_in">exec</span> -it tf-cv bash</span><br></pre></td></tr></table></figure>
<p>若需要部署到服务器，可以使用以下命令<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将容器提交为新的镜像</span></span><br><span class="line">docker commit tf-cv tf-cv:server</span><br><span class="line"><span class="comment"># 将新的镜像打包为tar压缩文件，之后用scp命令传到服务器上</span></span><br><span class="line">docker save &gt; tf-cv.tar tf-cv:server</span><br><span class="line"><span class="comment"># 在服务器上解压镜像</span></span><br><span class="line">docker load &lt; tf-cv.tar</span><br><span class="line"><span class="comment"># 再次run，参见以上命令</span></span><br></pre></td></tr></table></figure></p>
<h3 id="编写预测代码"><a href="#编写预测代码" class="headerlink" title="编写预测代码"></a>编写预测代码</h3><h4 id="OpenCV人脸检测"><a href="#OpenCV人脸检测" class="headerlink" title="OpenCV人脸检测"></a>OpenCV人脸检测</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  HAAR特征检测人脸</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  用opencv的方式（HAAR特征）检测人脸，效果不是很好。</span></span><br><span class="line"><span class="string">  最优方案是MTCNN，需要人脸特征点数据集多次训练，比较繁琐</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_face</span><span class="params">(img_path)</span>:</span></span><br><span class="line">    <span class="comment"># 获取训练好的人脸参数数据，此处引用GitHub上的opencv库中的默认值</span></span><br><span class="line">    face_cascade = cv2.CascadeClassifier(<span class="string">r'/root/haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取图片，并处理成灰度图</span></span><br><span class="line">    image = cv2.imread(img_path)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 未读取到图片，返回</span></span><br><span class="line">    <span class="keyword">if</span> image <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"提示：未读取到图片"</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换为灰度图像</span></span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># haar模型检测人脸</span></span><br><span class="line">    faces = face_cascade.detectMultiScale(</span><br><span class="line">        gray,</span><br><span class="line">        scaleFactor = <span class="number">1.15</span>,</span><br><span class="line">        minNeighbors = <span class="number">5</span>,</span><br><span class="line">        minSize = (<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">        flags = cv2.CASCADE_SCALE_IMAGE</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 未检测到人脸，返回</span></span><br><span class="line">    <span class="keyword">if</span> len(faces) &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"提示：未检测到人脸"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 裁剪人脸图像</span></span><br><span class="line">    face_images = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">        face_img = image[y:y+h, x:x+w]</span><br><span class="line">        face_images.append(face_img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若有多个人脸，则选出面积最大（也就是最靠前）的人脸</span></span><br><span class="line">    face_images = sorted(face_images, key=<span class="keyword">lambda</span> img:img.size, reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换图像</span></span><br><span class="line">    face = Image.fromarray(face_images[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 缩放为（55，47）</span></span><br><span class="line">    resize_face = face.resize((<span class="number">47</span>,<span class="number">55</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换为array</span></span><br><span class="line">    <span class="keyword">return</span> np.asarray(resize_face)</span><br></pre></td></tr></table></figure>
<h4 id="Tensorflow人脸特征比对"><a href="#Tensorflow人脸特征比对" class="headerlink" title="Tensorflow人脸特征比对"></a>Tensorflow人脸特征比对</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> detector <span class="keyword">as</span> dt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  预测</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(src_img_path, dst_img_path)</span>:</span></span><br><span class="line">    <span class="comment"># 对输入的图像分别检测人脸</span></span><br><span class="line">    src_image = dt.detect_face(src_img_path)</span><br><span class="line">    dst_image = dt.detect_face(dst_img_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若返回了错误信息，不再检测</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(src_image, str):</span><br><span class="line">        <span class="keyword">return</span> src_image</span><br><span class="line">    <span class="keyword">elif</span> isinstance(dst_image, str):</span><br><span class="line">        <span class="keyword">return</span> dst_image</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 载入tensorflow模型，开始检测</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver=tf.train.import_meta_graph(<span class="string">'/root/50000.ckpt.meta'</span>)</span><br><span class="line">        saver.restore(sess,<span class="string">"/root/50000.ckpt"</span>)</span><br><span class="line">        graph = tf.get_default_graph()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算160维的人脸特征</span></span><br><span class="line">        h1 = sess.run(<span class="string">"DeepID1/Relu:0"</span>, feed_dict=&#123;<span class="string">"input/x:0"</span>: [src_image]&#125;)</span><br><span class="line">        h2 = sess.run(<span class="string">"DeepID1/Relu:0"</span>, feed_dict=&#123;<span class="string">"input/x:0"</span>: [dst_image]&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算人脸之间的余弦距离（事实上是1-余弦），范围0~1，越小越接近</span></span><br><span class="line">        pre_y = np.array([cosine(x, y) <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(h1, h2)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在测试集上测试模型的过程中，得到了余弦距离的阈值为0.47189</span></span><br><span class="line">        <span class="comment"># 因此，比该阈值小的即为同一个人，大的则不是同一个人</span></span><br><span class="line">        <span class="keyword">return</span> &#123; <span class="string">'msg'</span>: &#123; <span class="string">'isSame'</span>: bool((pre_y &lt; <span class="number">0.47189</span>)[<span class="number">0</span>]), <span class="string">'predict'</span>: pre_y[<span class="number">0</span>] &#125; &#125;</span><br></pre></td></tr></table></figure>
<h4 id="Flask后端服务器主程序"><a href="#Flask后端服务器主程序" class="headerlink" title="Flask后端服务器主程序"></a>Flask后端服务器主程序</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> predict.main <span class="keyword">import</span> predict</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/face', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    data = json.loads(request.get_data(as_text=<span class="keyword">True</span>))</span><br><span class="line">    src_face = data[<span class="string">'src_face'</span>]</span><br><span class="line">    dst_face = data[<span class="string">'dst_face'</span>]</span><br><span class="line">    res = predict(src_face, dst_face)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回一下两个人脸图像的路径，便于验证是否正确</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(res, str):</span><br><span class="line">      <span class="keyword">return</span> jsonify(&#123; <span class="string">'success'</span>: <span class="keyword">False</span>, <span class="string">'msg'</span>: res, <span class="string">'src_face'</span>: src_face, <span class="string">'dst_face'</span>: dst_face &#125;)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> jsonify(&#123; <span class="string">'success'</span>: <span class="keyword">True</span>, <span class="string">'msg'</span>: res[<span class="string">'msg'</span>], <span class="string">'src_face'</span>: src_face, <span class="string">'dst_face'</span>: dst_face &#125;)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(debug=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>以上的flask服务器的业务流程是：</p>
<ul>
<li>在主程序中路由<code>/face</code>上接收POST请求，收到待比对的两张人脸图片的文件路径。</li>
<li>在detect_face函数中，使用OpenCV的HAAR模型，检测图片中的人脸，并且裁剪成当时训练时使用的(55,47)尺寸输入。若检测不到人脸，或者图片文件无法找到，直接返回错误信息。</li>
<li>在predict函数中，调用tensorflow恢复（restore）模型的参数，输入这两张人脸，获取每张人脸的特征值，计算两者特征值的余弦距离，与之前在测试集上获取的余弦距离阈值进行比对，判断出是否为同一个人，返回结果。</li>
</ul>
<p>最终，在前端小程序的手机前置摄像头调用和用户界面的配合下，该系统的最终效果如下所示：</p>
<p>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-1.jpeg" alt="weapp-1"><br>  <center>图2.12 地图定位界面</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-2.jpeg" alt="weapp-2"><br>  <center>图2.13 人脸识别成功，正在比对人脸</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-3.jpeg" alt="weapp-3"><br>  <center>图2.14 未检测到人脸</center><br>  <img src="/2019/06/29/Training-DeepID1-Network-for-Face-Comparison-with-Google-Colab-Tensorflow/weapp-4.jpeg" alt="weapp-4"><br>  <center>图2.15 比对人脸为同一人后，打卡成功的结果</center></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本次项目实践了使用OpenCV、Tensorflow、Tensorboard以及docker、Jupyter Notebook等深度学习模型训练的常用工具，并尝试将训练得出的模型进行Python flask后端+小程序前端应用落地。在这一过程中，笔者不但熟悉了从数据集预处理、模型训练框架搭建、模型训练过程监控再到模型实际应用的全过程，也通过编写中文注释、以及对Tensorflow不同版本API的移植重写，进一步熟悉深度学习的常用术语和内在含义，可以说是一次收获颇丰的实践案例。</p>
<p>在此，特别感谢Google Colab免费提供的Nvidia GTX Tesla T4高性能GPU硬件资源以及在线训练平台，感谢他们为深度学习的推广和应用做出的无数努力和贡献。最后，感谢USTB的《机器学习》（自动化学院）、《人工智能》、《模式识别》等相关专选课老师的辛勤教学，是各位老师传授的宝贵知识和设置的一系列大作业帮助着我进一步理解、学习AI各个方向的知识并加以实践，为未来的研究和工作打下了知识基础。感谢大家！</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol>
<li>GitHub上DeepID的Tensorflow实现（本文在此基础上修改了调用的TensorflowAPI到2.0bata，并添加中文注释）：<br><a href="https://github.com/jinze1994/DeepID1" target="_blank" rel="noopener">https://github.com/jinze1994/DeepID1</a></li>
<li>DeepID1论文《Deep Learning Face Representation from Predicting 10,000 Classes》：<br><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf</a></li>
<li>Google Colab官网：<a href="https://colab.research.google.com" target="_blank" rel="noopener">https://colab.research.google.com</a></li>
<li>DeepID1、2算法解读：<a href="https://www.cnblogs.com/venus024/p/5632243.html" target="_blank" rel="noopener">https://www.cnblogs.com/venus024/p/5632243.html</a></li>
<li>人脸特征提取DeepID 1.0深度网络解读：<br><a href="https://blog.csdn.net/jiajinrang93/article/details/72566130/" target="_blank" rel="noopener">https://blog.csdn.net/jiajinrang93/article/details/72566130/</a></li>
</ol>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/experience/" rel="tag"><i class="fa fa-tag"></i> experience</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/29/Different-Deep-Learning-Methods-for-Image-Classification-on-CIFAR-10/" rel="next" title="Different Deep Learning Methods for Image Classification on CIFAR 10">
                <i class="fa fa-chevron-left"></i> Different Deep Learning Methods for Image Classification on CIFAR 10
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Mengyin Liu" />
            
              <p class="site-author-name" itemprop="name">Mengyin Liu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/lmy98129" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:lmy98129@163.com" target="_blank" title="Mail"><i class="fa fa-fw fa-envelope"></i>Mail</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://blog.csdn.net/lmy98129" target="_blank" title="CSDN"><i class="fa fa-fw fa-crosshairs"></i>CSDN</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/liu-meng-yin-68/" target="_blank" title="知乎"><i class="fa fa-fw fa-comment"></i>知乎</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目地址"><span class="nav-number">1.</span> <span class="nav-text">项目地址</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简介"><span class="nav-number">2.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练环境搭建"><span class="nav-number">3.</span> <span class="nav-text">训练环境搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编写训练代码"><span class="nav-number">4.</span> <span class="nav-text">编写训练代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#下载YouTube-Aligned-Faces数据集"><span class="nav-number">4.1.</span> <span class="nav-text">下载YouTube Aligned Faces数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#裁剪数据集图片"><span class="nav-number">4.2.</span> <span class="nav-text">裁剪数据集图片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分割数据集为训练集、验证集和测试集"><span class="nav-number">4.3.</span> <span class="nav-text">分割数据集为训练集、验证集和测试集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#向量化数据集，便于读取"><span class="nav-number">4.4.</span> <span class="nav-text">向量化数据集，便于读取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#运行tensorboard监视训练过程"><span class="nav-number">4.5.</span> <span class="nav-text">运行tensorboard监视训练过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练DeepID网络"><span class="nav-number">4.6.</span> <span class="nav-text">训练DeepID网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在测试集上使用模型文件预测，获取余弦距离阈值"><span class="nav-number">4.7.</span> <span class="nav-text">在测试集上使用模型文件预测，获取余弦距离阈值</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测服务搭建"><span class="nav-number">5.</span> <span class="nav-text">预测服务搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编写预测代码"><span class="nav-number">6.</span> <span class="nav-text">编写预测代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV人脸检测"><span class="nav-number">6.1.</span> <span class="nav-text">OpenCV人脸检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensorflow人脸特征比对"><span class="nav-number">6.2.</span> <span class="nav-text">Tensorflow人脸特征比对</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flask后端服务器主程序"><span class="nav-number">6.3.</span> <span class="nav-text">Flask后端服务器主程序</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考资料"><span class="nav-number">8.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mengyin Liu</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>








<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共56.4k字</span>
</div>

        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.4"></script>



  



	





  





  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  

  

  
  <script type="text/javascript" src="/js/src/exturl.js?v=6.0.4"></script>


  

</body>
</html>
